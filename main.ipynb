{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f155de1-dbd8-4040-896d-ab5a61d52cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031813e9-2b70-4201-9b75-954bdf701c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     uint32\n",
       "behav       uint8\n",
       "itemCat    uint32\n",
       "timestp    uint32\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据库\n",
    "df = pd.read_csv('./data/tianchi_ali/tianchi_mobile_recommend_train_user.csv', usecols=[0, 2, 4, 5])\n",
    "df.columns = ['userId', 'behav', 'itemCat', 'timestp']\n",
    "df['userId'] = df['userId'].astype('uint32')\n",
    "df['behav'] = df['behav'].astype('uint8')\n",
    "df['itemCat'] = df['itemCat'].astype('uint32')\n",
    "df['timestp'] = df['timestp'].str.replace('-','').str.replace(' ', '').astype(int).astype('uint32') // 100\n",
    "\n",
    "clone = df.copy()\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d398e21-08dc-4e91-990a-0ea4c224ffc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index          0\n",
       "userId     47878\n",
       "behav      11969\n",
       "itemCat    47878\n",
       "timestp    47878\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算内存占用，单位KB\n",
    "df = clone.copy()\n",
    "\n",
    "df.memory_usage() // 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2d2e9a-7562-47b3-af52-3f2a65e1819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>behav</th>\n",
       "      <th>itemCat</th>\n",
       "      <th>timestp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98047837</td>\n",
       "      <td>1</td>\n",
       "      <td>4245</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97726136</td>\n",
       "      <td>1</td>\n",
       "      <td>5894</td>\n",
       "      <td>20141209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98607707</td>\n",
       "      <td>1</td>\n",
       "      <td>2883</td>\n",
       "      <td>20141218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98662432</td>\n",
       "      <td>1</td>\n",
       "      <td>6562</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98145908</td>\n",
       "      <td>1</td>\n",
       "      <td>13926</td>\n",
       "      <td>20141216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256901</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20141213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256902</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>12311</td>\n",
       "      <td>20141214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256903</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>8765</td>\n",
       "      <td>20141211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256904</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>7951</td>\n",
       "      <td>20141208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256905</th>\n",
       "      <td>108404535</td>\n",
       "      <td>1</td>\n",
       "      <td>9847</td>\n",
       "      <td>20141203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12256906 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId  behav  itemCat   timestp\n",
       "0          98047837      1     4245  20141206\n",
       "1          97726136      1     5894  20141209\n",
       "2          98607707      1     2883  20141218\n",
       "3          98662432      1     6562  20141206\n",
       "4          98145908      1    13926  20141216\n",
       "...             ...    ...      ...       ...\n",
       "12256901   93812622      1       11  20141213\n",
       "12256902   93812622      1    12311  20141214\n",
       "12256903   93812622      1     8765  20141211\n",
       "12256904   93812622      1     7951  20141208\n",
       "12256905  108404535      1     9847  20141203\n",
       "\n",
       "[12256906 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# behav包含四种行为 \n",
    "# 1--浏览 \n",
    "# 2--收藏 \n",
    "# 3--加购物车 \n",
    "# 4--购买\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1492a428-f84d-4dd1-8fd8-16b7188ad81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId:  [10000]\n",
      "itemCat: [8916]\n",
      "timestp: [31]\n"
     ]
    }
   ],
   "source": [
    "# 提取数据各类别全集，同时也作为后续数据的索引列表\n",
    "userId = list(df['userId'].unique())\n",
    "itemCat = list(df['itemCat'].unique())\n",
    "timestp = sorted(list(df['timestp'].unique()))\n",
    "print(f'userId:  [{len(userId)}]\\nitemCat: [{len(itemCat)}]\\ntimestp: [{len(timestp)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c07393-478c-40b7-b71e-d0682faebe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input array storage: 11055840000 B = 10796718 KB = 10543 MB = 10 GB\n"
     ]
    }
   ],
   "source": [
    "# 构建三维数组\n",
    "shape = (len(userId), len(itemCat), len(timestp))\n",
    "input = np.zeros(shape, dtype=np.float32)\n",
    "size = input.nbytes\n",
    "print(f'input array storage: {size} B = {size // 1024} KB = {size // 1024 // 1024} MB = {size // 1024 // 1024 // 1024} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b94b2a-6ac6-4c84-b337-5d33253e9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义时间衰减函数\n",
    "alpha = 0.23 # 超参数，衰减因子，控制每一天的衰减程度，0.23大约是3日便会衰减一半\n",
    "def decay_func(x):\n",
    "    return np.exp(-x * alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e325ac04-692e-419f-a81b-a7da93a17da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>behav</th>\n",
       "      <th>itemCat</th>\n",
       "      <th>timestp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98047837</td>\n",
       "      <td>1</td>\n",
       "      <td>4245</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97726136</td>\n",
       "      <td>1</td>\n",
       "      <td>5894</td>\n",
       "      <td>20141209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98662432</td>\n",
       "      <td>1</td>\n",
       "      <td>6562</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98145908</td>\n",
       "      <td>1</td>\n",
       "      <td>13926</td>\n",
       "      <td>20141216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93784494</td>\n",
       "      <td>1</td>\n",
       "      <td>3979</td>\n",
       "      <td>20141203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256901</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20141213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256902</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>12311</td>\n",
       "      <td>20141214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256903</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>8765</td>\n",
       "      <td>20141211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256904</th>\n",
       "      <td>93812622</td>\n",
       "      <td>1</td>\n",
       "      <td>7951</td>\n",
       "      <td>20141208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256905</th>\n",
       "      <td>108404535</td>\n",
       "      <td>1</td>\n",
       "      <td>9847</td>\n",
       "      <td>20141203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11881309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId  behav  itemCat   timestp\n",
       "0          98047837      1     4245  20141206\n",
       "1          97726136      1     5894  20141209\n",
       "3          98662432      1     6562  20141206\n",
       "4          98145908      1    13926  20141216\n",
       "5          93784494      1     3979  20141203\n",
       "...             ...    ...      ...       ...\n",
       "12256901   93812622      1       11  20141213\n",
       "12256902   93812622      1    12311  20141214\n",
       "12256903   93812622      1     8765  20141211\n",
       "12256904   93812622      1     7951  20141208\n",
       "12256905  108404535      1     9847  20141203\n",
       "\n",
       "[11881309 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取最后一天的交互\n",
    "last_day = timestp[-1]\n",
    "\n",
    "interact = df[df['timestp'] == last_day] # 提取df中最后一天的所有交互\n",
    "interact = interact.drop(columns=['behav', 'timestp']).drop_duplicates() # 删除behav，timestp列\n",
    "\n",
    "# 在df中剔除最后一天的交互\n",
    "df = df[df['timestp'] != last_day]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60608606-c430-4562-b814-415dfa7a166a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemCat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98607707</td>\n",
       "      <td>2883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>103802946</td>\n",
       "      <td>11406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>101781721</td>\n",
       "      <td>9829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>104221274</td>\n",
       "      <td>5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>101260672</td>\n",
       "      <td>3424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255140</th>\n",
       "      <td>26920547</td>\n",
       "      <td>6054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255679</th>\n",
       "      <td>56708793</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255946</th>\n",
       "      <td>56708793</td>\n",
       "      <td>4254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256403</th>\n",
       "      <td>66961542</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256486</th>\n",
       "      <td>72214388</td>\n",
       "      <td>2284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId  itemCat\n",
       "2          98607707     2883\n",
       "33        103802946    11406\n",
       "38        101781721     9829\n",
       "79        104221274     5399\n",
       "130       101260672     3424\n",
       "...             ...      ...\n",
       "12255140   26920547     6054\n",
       "12255679   56708793     4370\n",
       "12255946   56708793     4254\n",
       "12256403   66961542     1083\n",
       "12256486   72214388     2284\n",
       "\n",
       "[57123 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b147f140-40fd-4f7d-8e69-c6922f6b1b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每个用户的总交互次数\n",
    "N = list() # 记录用户总交互次数\n",
    "for i in range(len(userId)):\n",
    "    N.append(0)\n",
    "len(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5949325c-2863-4f6c-a480-ebfc35f6298a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemCat</th>\n",
       "      <th>timestp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98047837</td>\n",
       "      <td>4245</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97726136</td>\n",
       "      <td>5894</td>\n",
       "      <td>20141209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98662432</td>\n",
       "      <td>6562</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98145908</td>\n",
       "      <td>13926</td>\n",
       "      <td>20141216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93784494</td>\n",
       "      <td>3979</td>\n",
       "      <td>20141203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805124</th>\n",
       "      <td>76314785</td>\n",
       "      <td>9291</td>\n",
       "      <td>20141203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805125</th>\n",
       "      <td>76314785</td>\n",
       "      <td>7582</td>\n",
       "      <td>20141203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805126</th>\n",
       "      <td>76314785</td>\n",
       "      <td>9720</td>\n",
       "      <td>20141209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805127</th>\n",
       "      <td>76314785</td>\n",
       "      <td>8095</td>\n",
       "      <td>20141206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805128</th>\n",
       "      <td>79359253</td>\n",
       "      <td>14079</td>\n",
       "      <td>20141210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1805129 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId  itemCat   timestp\n",
       "0        98047837     4245  20141206\n",
       "1        97726136     5894  20141209\n",
       "2        98662432     6562  20141206\n",
       "3        98145908    13926  20141216\n",
       "4        93784494     3979  20141203\n",
       "...           ...      ...       ...\n",
       "1805124  76314785     9291  20141203\n",
       "1805125  76314785     7582  20141203\n",
       "1805126  76314785     9720  20141209\n",
       "1805127  76314785     8095  20141206\n",
       "1805128  79359253    14079  20141210\n",
       "\n",
       "[1805129 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 复制一个df,日期，用户，商品均为一致的行保留一个\n",
    "no_behav = df.copy().drop(columns=['behav']).drop_duplicates().reset_index().drop(columns=['index'])\n",
    "no_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba7a409-786a-4dd8-98ef-a47de7415702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing [0/1805129]\n",
      "processing [100000/1805129]\n",
      "processing [200000/1805129]\n",
      "processing [300000/1805129]\n",
      "processing [400000/1805129]\n",
      "processing [500000/1805129]\n",
      "processing [600000/1805129]\n",
      "processing [700000/1805129]\n",
      "processing [800000/1805129]\n",
      "processing [900000/1805129]\n",
      "processing [1000000/1805129]\n",
      "processing [1100000/1805129]\n",
      "processing [1200000/1805129]\n",
      "processing [1300000/1805129]\n",
      "processing [1400000/1805129]\n",
      "processing [1500000/1805129]\n",
      "processing [1600000/1805129]\n",
      "processing [1700000/1805129]\n",
      "processing [1800000/1805129]\n"
     ]
    }
   ],
   "source": [
    "# 计算总交互次数\n",
    "for index, row in no_behav.iterrows():\n",
    "    if (index % 100000 == 0):\n",
    "        print(f'processing [{index}/{len(no_behav)}]')\n",
    "    id = row.userId\n",
    "    idx = userId.index(id)\n",
    "    N[idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "706bb90f-c5ee-43bd-9d02-a5f5ed047f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算用户平均每日交互次数\n",
    "for i in range(len(userId)):\n",
    "    N[i] /= len(timestp)-1\n",
    "    N[i] += 1\n",
    "    N[i] = int(N[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6a525c-2738-4a8e-878c-e7dbf77b5edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0/11881309 || time_spent: [0s]\n",
      "loop 100000/11881309 || time_spent: [10s]\n",
      "loop 200000/11881309 || time_spent: [12s]\n",
      "loop 300000/11881309 || time_spent: [13s]\n",
      "loop 400000/11881309 || time_spent: [13s]\n",
      "loop 500000/11881309 || time_spent: [15s]\n",
      "loop 600000/11881309 || time_spent: [16s]\n",
      "loop 800000/11881309 || time_spent: [35s]\n",
      "loop 900000/11881309 || time_spent: [19s]\n",
      "loop 1000000/11881309 || time_spent: [21s]\n",
      "loop 1100000/11881309 || time_spent: [22s]\n",
      "loop 1200000/11881309 || time_spent: [22s]\n",
      "loop 1300000/11881309 || time_spent: [19s]\n",
      "loop 1400000/11881309 || time_spent: [17s]\n",
      "loop 1500000/11881309 || time_spent: [17s]\n",
      "loop 1600000/11881309 || time_spent: [16s]\n",
      "loop 1700000/11881309 || time_spent: [15s]\n",
      "loop 1800000/11881309 || time_spent: [17s]\n",
      "loop 1900000/11881309 || time_spent: [16s]\n",
      "loop 2000000/11881309 || time_spent: [17s]\n",
      "loop 2100000/11881309 || time_spent: [17s]\n",
      "loop 2200000/11881309 || time_spent: [17s]\n",
      "loop 2300000/11881309 || time_spent: [16s]\n",
      "loop 2400000/11881309 || time_spent: [17s]\n",
      "loop 2500000/11881309 || time_spent: [17s]\n",
      "loop 2600000/11881309 || time_spent: [17s]\n",
      "loop 2700000/11881309 || time_spent: [15s]\n",
      "loop 2800000/11881309 || time_spent: [18s]\n",
      "loop 2900000/11881309 || time_spent: [17s]\n",
      "loop 3000000/11881309 || time_spent: [16s]\n",
      "loop 3100000/11881309 || time_spent: [16s]\n",
      "loop 3200000/11881309 || time_spent: [17s]\n",
      "loop 3300000/11881309 || time_spent: [17s]\n",
      "loop 3400000/11881309 || time_spent: [14s]\n",
      "loop 3500000/11881309 || time_spent: [16s]\n",
      "loop 3600000/11881309 || time_spent: [17s]\n",
      "loop 3700000/11881309 || time_spent: [18s]\n",
      "loop 3800000/11881309 || time_spent: [16s]\n",
      "loop 3900000/11881309 || time_spent: [16s]\n",
      "loop 4000000/11881309 || time_spent: [17s]\n",
      "loop 4100000/11881309 || time_spent: [15s]\n",
      "loop 4200000/11881309 || time_spent: [17s]\n",
      "loop 4300000/11881309 || time_spent: [18s]\n",
      "loop 4400000/11881309 || time_spent: [17s]\n",
      "loop 4500000/11881309 || time_spent: [16s]\n",
      "loop 4600000/11881309 || time_spent: [16s]\n",
      "loop 4700000/11881309 || time_spent: [16s]\n",
      "loop 4800000/11881309 || time_spent: [17s]\n",
      "loop 4900000/11881309 || time_spent: [18s]\n",
      "loop 5000000/11881309 || time_spent: [17s]\n",
      "loop 5100000/11881309 || time_spent: [16s]\n",
      "loop 5200000/11881309 || time_spent: [16s]\n",
      "loop 5300000/11881309 || time_spent: [14s]\n",
      "loop 5400000/11881309 || time_spent: [17s]\n",
      "loop 5500000/11881309 || time_spent: [16s]\n",
      "loop 5600000/11881309 || time_spent: [16s]\n",
      "loop 5700000/11881309 || time_spent: [16s]\n",
      "loop 5800000/11881309 || time_spent: [17s]\n",
      "loop 5900000/11881309 || time_spent: [18s]\n",
      "loop 6000000/11881309 || time_spent: [16s]\n",
      "loop 6100000/11881309 || time_spent: [19s]\n",
      "loop 6200000/11881309 || time_spent: [16s]\n",
      "loop 6300000/11881309 || time_spent: [16s]\n",
      "loop 6400000/11881309 || time_spent: [17s]\n",
      "loop 6500000/11881309 || time_spent: [17s]\n",
      "loop 6600000/11881309 || time_spent: [17s]\n",
      "loop 6700000/11881309 || time_spent: [17s]\n",
      "loop 6800000/11881309 || time_spent: [16s]\n",
      "loop 6900000/11881309 || time_spent: [17s]\n",
      "loop 7000000/11881309 || time_spent: [16s]\n",
      "loop 7100000/11881309 || time_spent: [17s]\n",
      "loop 7300000/11881309 || time_spent: [33s]\n",
      "loop 7400000/11881309 || time_spent: [16s]\n",
      "loop 7500000/11881309 || time_spent: [17s]\n",
      "loop 7600000/11881309 || time_spent: [15s]\n",
      "loop 7700000/11881309 || time_spent: [18s]\n",
      "loop 7800000/11881309 || time_spent: [15s]\n",
      "loop 7900000/11881309 || time_spent: [16s]\n",
      "loop 8000000/11881309 || time_spent: [17s]\n",
      "loop 8100000/11881309 || time_spent: [17s]\n",
      "loop 8200000/11881309 || time_spent: [16s]\n",
      "loop 8300000/11881309 || time_spent: [16s]\n",
      "loop 8500000/11881309 || time_spent: [33s]\n",
      "loop 8600000/11881309 || time_spent: [18s]\n",
      "loop 8700000/11881309 || time_spent: [16s]\n",
      "loop 8800000/11881309 || time_spent: [16s]\n",
      "loop 8900000/11881309 || time_spent: [17s]\n",
      "loop 9000000/11881309 || time_spent: [17s]\n",
      "loop 9100000/11881309 || time_spent: [17s]\n",
      "loop 9200000/11881309 || time_spent: [18s]\n",
      "loop 9300000/11881309 || time_spent: [17s]\n",
      "loop 9400000/11881309 || time_spent: [15s]\n",
      "loop 9500000/11881309 || time_spent: [17s]\n",
      "loop 9600000/11881309 || time_spent: [17s]\n",
      "loop 9700000/11881309 || time_spent: [15s]\n",
      "loop 9800000/11881309 || time_spent: [17s]\n",
      "loop 9900000/11881309 || time_spent: [16s]\n",
      "loop 10000000/11881309 || time_spent: [17s]\n",
      "loop 10100000/11881309 || time_spent: [16s]\n",
      "loop 10200000/11881309 || time_spent: [17s]\n",
      "loop 10300000/11881309 || time_spent: [15s]\n",
      "loop 10400000/11881309 || time_spent: [17s]\n",
      "loop 10500000/11881309 || time_spent: [18s]\n",
      "loop 10600000/11881309 || time_spent: [16s]\n",
      "loop 10700000/11881309 || time_spent: [17s]\n",
      "loop 10800000/11881309 || time_spent: [15s]\n",
      "loop 10900000/11881309 || time_spent: [17s]\n",
      "loop 11000000/11881309 || time_spent: [17s]\n",
      "loop 11100000/11881309 || time_spent: [16s]\n",
      "loop 11200000/11881309 || time_spent: [16s]\n",
      "loop 11300000/11881309 || time_spent: [18s]\n",
      "loop 11400000/11881309 || time_spent: [16s]\n",
      "loop 11500000/11881309 || time_spent: [18s]\n",
      "loop 11600000/11881309 || time_spent: [17s]\n",
      "loop 11700000/11881309 || time_spent: [17s]\n",
      "loop 11800000/11881309 || time_spent: [17s]\n",
      "loop 11900000/11881309 || time_spent: [15s]\n",
      "loop 12000000/11881309 || time_spent: [15s]\n",
      "loop 12100000/11881309 || time_spent: [17s]\n",
      "loop 12200000/11881309 || time_spent: [16s]\n"
     ]
    }
   ],
   "source": [
    "# 填充input数组\n",
    "# 记录开始前的时间\n",
    "import time\n",
    "\n",
    "last_time = int(time.time())\n",
    "# 填充input数组\n",
    "for index, row in df.iterrows():\n",
    "    # 进度输出\n",
    "    if index % 100000 == 0:\n",
    "        this_time = int(time.time())\n",
    "        print(f'loop {index}/{len(df)} || time_spent: [{this_time-last_time}s]')\n",
    "        last_time = this_time\n",
    "        \n",
    "    # input[u][c][t]\n",
    "    u = userId.index(row.userId)\n",
    "    c = itemCat.index(row.itemCat)\n",
    "    t = timestp.index(row.timestp)\n",
    "    behav = row.behav\n",
    "    if behav == 3:\n",
    "        score = 2\n",
    "    else:\n",
    "        score = behav\n",
    "    # print(f'user: {u}, cata: {c}, time: {t}, score: {score}')\n",
    "\n",
    "    # 将数据填入数组\n",
    "    input[u, c, t] = input[u, c, t] + score\n",
    "\n",
    "    # 计算时间衰减\n",
    "    for day in range(t+1, len(timestp)):\n",
    "        input[u, c, day] = input[u, c, day] + score * decay_func(day-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ec4c73-f2de-4d07-85eb-8f8e08bbb348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.918005</td>\n",
       "      <td>9.469255</td>\n",
       "      <td>7.523642</td>\n",
       "      <td>5.977786</td>\n",
       "      <td>4.749552</td>\n",
       "      <td>3.773678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.589067</td>\n",
       "      <td>1.262567</td>\n",
       "      <td>1.003152</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.633274</td>\n",
       "      <td>0.503157</td>\n",
       "      <td>0.399775</td>\n",
       "      <td>...</td>\n",
       "      <td>1.601485</td>\n",
       "      <td>1.272434</td>\n",
       "      <td>1.010992</td>\n",
       "      <td>0.803267</td>\n",
       "      <td>0.638222</td>\n",
       "      <td>0.507089</td>\n",
       "      <td>0.402899</td>\n",
       "      <td>0.320117</td>\n",
       "      <td>0.254344</td>\n",
       "      <td>0.202085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.918005</td>\n",
       "      <td>9.469255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599326</td>\n",
       "      <td>0.476185</td>\n",
       "      <td>0.378345</td>\n",
       "      <td>0.300608</td>\n",
       "      <td>0.238843</td>\n",
       "      <td>0.189769</td>\n",
       "      <td>0.150778</td>\n",
       "      <td>0.119798</td>\n",
       "      <td>0.095183</td>\n",
       "      <td>0.075626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794534</td>\n",
       "      <td>2.631284</td>\n",
       "      <td>2.090643</td>\n",
       "      <td>1.661086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105133</td>\n",
       "      <td>0.083532</td>\n",
       "      <td>0.066369</td>\n",
       "      <td>0.052732</td>\n",
       "      <td>0.041898</td>\n",
       "      <td>0.033289</td>\n",
       "      <td>0.026449</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.016697</td>\n",
       "      <td>0.013266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.722688</td>\n",
       "      <td>12.492207</td>\n",
       "      <td>42.925461</td>\n",
       "      <td>34.105736</td>\n",
       "      <td>27.098148</td>\n",
       "      <td>21.530386</td>\n",
       "      <td>17.106619</td>\n",
       "      <td>13.591784</td>\n",
       "      <td>10.799129</td>\n",
       "      <td>8.580267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794534</td>\n",
       "      <td>0.631284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039955</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.025223</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>0.005042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.589067</td>\n",
       "      <td>1.262567</td>\n",
       "      <td>1.003152</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.633274</td>\n",
       "      <td>0.503157</td>\n",
       "      <td>0.399775</td>\n",
       "      <td>0.317635</td>\n",
       "      <td>0.252372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.589067</td>\n",
       "      <td>1.262567</td>\n",
       "      <td>1.003152</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.633274</td>\n",
       "      <td>0.503157</td>\n",
       "      <td>0.399775</td>\n",
       "      <td>0.317635</td>\n",
       "      <td>0.252372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.356268</td>\n",
       "      <td>5.050270</td>\n",
       "      <td>4.012609</td>\n",
       "      <td>3.188152</td>\n",
       "      <td>2.533094</td>\n",
       "      <td>2.012628</td>\n",
       "      <td>1.599101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.383601</td>\n",
       "      <td>1.893851</td>\n",
       "      <td>1.504728</td>\n",
       "      <td>1.195557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6   \\\n",
       "0     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.0  0.000000  2.000000  1.589067  1.262567  1.003152  0.797038   \n",
       "2     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6     0.0  0.000000  0.000000  0.000000  0.000000  1.000000  0.794534   \n",
       "11    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "2825  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2842  2.0  1.589067  1.262567  1.003152  0.797038  0.633274  0.503157   \n",
       "3141  2.0  1.589067  1.262567  1.003152  0.797038  0.633274  0.503157   \n",
       "3287  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3299  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             7          8         9   ...         21         22         23  \\\n",
       "0      0.000000   0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "1      0.633274   0.503157  0.399775  ...   1.601485   1.272434   1.010992   \n",
       "2     15.000000  11.918005  9.469255  ...   0.599326   0.476185   0.378345   \n",
       "6      2.631284   2.090643  1.661086  ...   0.105133   0.083532   0.066369   \n",
       "11     0.000000   0.000000  0.000000  ...  15.722688  12.492207  42.925461   \n",
       "...         ...        ...       ...  ...        ...        ...        ...   \n",
       "2825   1.000000   0.794534  0.631284  ...   0.039955   0.031746   0.025223   \n",
       "2842   0.399775   0.317635  0.252372  ...   0.015973   0.012691   0.010084   \n",
       "3141   0.399775   0.317635  0.252372  ...   0.015973   0.012691   0.010084   \n",
       "3287   0.000000   0.000000  0.000000  ...   0.000000   0.000000   8.000000   \n",
       "3299   0.000000   0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "\n",
       "             24         25         26         27         28         29  \\\n",
       "0     15.000000  11.918005   9.469255   7.523642   5.977786   4.749552   \n",
       "1      0.803267   0.638222   0.507089   0.402899   0.320117   0.254344   \n",
       "2      0.300608   0.238843   0.189769   0.150778   0.119798   0.095183   \n",
       "6      0.052732   0.041898   0.033289   0.026449   0.021015   0.016697   \n",
       "11    34.105736  27.098148  21.530386  17.106619  13.591784  10.799129   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2825   0.020041   0.015923   0.012651   0.010052   0.007987   0.006346   \n",
       "2842   0.008012   0.006366   0.005058   0.004018   0.003193   0.002537   \n",
       "3141   0.008012   0.006366   0.005058   0.004018   0.003193   0.002537   \n",
       "3287   6.356268   5.050270   4.012609   3.188152   2.533094   2.012628   \n",
       "3299   0.000000   0.000000   3.000000   2.383601   1.893851   1.504728   \n",
       "\n",
       "            30  \n",
       "0     3.773678  \n",
       "1     0.202085  \n",
       "2     0.075626  \n",
       "6     0.013266  \n",
       "11    8.580267  \n",
       "...        ...  \n",
       "2825  0.005042  \n",
       "2842  0.002016  \n",
       "3141  0.002016  \n",
       "3287  1.599101  \n",
       "3299  1.195557  \n",
       "\n",
       "[128 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出评价分数据（测试用）\n",
    "slice = pd.DataFrame(input[430, :, :]) # 输出user的切片\n",
    "slice = slice.loc[~(slice == 0).all(axis=1)] # 输出除了全为0的行\n",
    "slice.T.to_csv('./data/test_data.csv', index=False)\n",
    "\n",
    "slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "38db5b94-6487-4a96-8e1c-e6d2b9fec679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8916, 31)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "30df2a1d-97a6-489b-b94a-80754ffa0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "class Para():\n",
    "    input_size = 1\n",
    "    hidden_size = 64\n",
    "    output_size = 1\n",
    "    num_layers = 1\n",
    "    lr = 0.001\n",
    "    epochs = 50\n",
    "    threshold = 0.2\n",
    "    step = 0.05\n",
    "    batch = 9900 # 调整一次训练的用户数,经过观察，9900后的用户行为是异常数据，因而忽略\n",
    "\n",
    "para = Para()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d188a465-61a1-4e7c-8d46-f76ff6a5b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义迭代器\n",
    "class InputIterator():\n",
    "    def __init__(self, C):\n",
    "        self.C = C\n",
    "        self.u, self.c, self.t = C.shape\n",
    "        self.cur = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.cur < self.u:\n",
    "            ret = self.C[self.cur]\n",
    "            self.cur += 1\n",
    "            return ret\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "iterator = InputIterator(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bf833a8b-fd11-4eed-b79a-5ae515bbdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__() # 调用父类nn.Module中的init方法\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, h0=None):\n",
    "        # 输入x的形状为（batch_size，seq_len，input_size）\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "\n",
    "        # h0默认为全0，否则取h0输入模型的值\n",
    "\n",
    "        # 输入rnn的形状为（1，seq_len，input_size）\n",
    "        # 输出rnn的形状为（1，seq_len，hidden_size）\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # 输入fc的形状为（1，1，hidden_size）（只取最后一个时间步）\n",
    "        # 输出fc的形状为（1，1，output_size）\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(GRU, self).__init__() # 调用父类nn.Module中的init方法\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, h0=None):\n",
    "        # 输入x的形状为（batch_size，seq_len，input_size）\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "\n",
    "        # h0默认为全0，否则取h0输入模型的值\n",
    "\n",
    "        # 输入rnn的形状为（1，seq_len，input_size）\n",
    "        # 输出rnn的形状为（1，seq_len，hidden_size）\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # 输入fc的形状为（1，1，hidden_size）（只取最后一个时间步）\n",
    "        # 输出fc的形状为（1，1，output_size）\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTM, self).__init__() # 调用父类nn.Module中的init方法\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True) # LSTM考虑计算复杂度只使用1层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, h0=None):\n",
    "        # 输入x的形状为（batch_size，seq_len，input_size）\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "\n",
    "        # h0默认为全0，否则取h0输入模型的值\n",
    "\n",
    "        # 输入rnn的形状为（1，seq_len，input_size）\n",
    "        # 输出rnn的形状为（1，seq_len，hidden_size）\n",
    "        out, _ = self.lstm(x, h0)\n",
    "        # 输入fc的形状为（1，1，hidden_size）（只取最后一个时间步）\n",
    "        # 输出fc的形状为（1，1，output_size）\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "61731b30-00c3-4a14-bc56-98bd870e1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 数据处理部分\n",
    "# 输入一个dataframe\n",
    "# 返回列数cat，行数seq，商品全集item_u，模型输入input\n",
    "def preprocessing(data):\n",
    "    seq, cat = data.shape # 获取data形状\n",
    "    item_u = data.columns.values.tolist() # 获取商品全集\n",
    "    scaler = MinMaxScaler()\n",
    "    data_out = scaler.fit_transform(data.to_numpy()) # 数据归一化\n",
    "    data_out = data_out.reshape(1, seq, cat) # reshape\n",
    "    \n",
    "    return cat, seq, item_u, data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "33b4bc3c-07fd-40b7-8330-dd5431ff6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "# 输入数据部分，及分割线\n",
    "# 输出分割后的训练及测试集\n",
    "def separate(data, sep_line=20):\n",
    "    train = data[:, sep_line:, :]\n",
    "    test = data[:, :sep_line, :]\n",
    "    \n",
    "    train_x = train[:, :-1, :]\n",
    "    train_y = train[:, -1:, :]\n",
    "    test_x = test[:, :-1, :]\n",
    "    test_y = test[:, -1, :]\n",
    "\n",
    "    # 将训练集及测试集转换为tensor\n",
    "    train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "    train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "    test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "    test_y = torch.tensor(test_y, dtype=torch.float32)\n",
    "    test_y = test_y.reshape(1, 1, cat)\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8166952d-4b3e-430e-b31a-25c1babb5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "# 输入训练集和超参数\n",
    "# 输出训练后的模型\n",
    "def train(train_x, train_y, para):\n",
    "    # 定义模型\n",
    "    model = RNN(para.input_size, para.hidden_size, para.output_size, para.num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), para.lr)\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(para.epochs):\n",
    "        optimizer.zero_grad() # 优化器梯度清零\n",
    "        output = model(train_x) # model的output会是一个形状为（1，1，output_size）的一维向量\n",
    "        output = output.reshape(1, 1, para.output_size) # reshape output的形状（不reshape也行，就是会一直报警告而已）\n",
    "        loss = criterion(output, train_y) # 计算预测输出与实际输出的loss\n",
    "        loss.backward() # 计算梯度\n",
    "        optimizer.step() # 更新参数\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f4c6aab2-0821-490a-83d0-568290b38f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "# 输入测试集及与用户相关的商品类别集\n",
    "# 输出测试结果的分析值\n",
    "def test(test_x, test_y, last_day, para, item_u, N, cat):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # 模型评估\n",
    "    with torch.no_grad():\n",
    "        output = model(test_x)\n",
    "        output = output.reshape(1, 1, cat)\n",
    "        test_loss = criterion(output, test_y)\n",
    "        \n",
    "    # 调整数据结构\n",
    "    output = np.array(output).reshape(cat)\n",
    "\n",
    "    # 取得阈值\n",
    "    threshold = para.threshold\n",
    "\n",
    "    # 通过阈值与平均交易数得到可能交互的项目\n",
    "    while True:\n",
    "        count = cat\n",
    "        for i in range(len(output)):\n",
    "            if output[i] < threshold:\n",
    "                output[i] = -1\n",
    "                count -= 1\n",
    "        \n",
    "        if count <= N:\n",
    "            break;\n",
    "        else:\n",
    "            threshold += para.step\n",
    "\n",
    "    # 定义真假正负例记录数组\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for i in range(cat): \n",
    "        if output[i] > 0: # 正例\n",
    "            if int(item_u[i]) in last_day: # 真正例\n",
    "                TP += 1\n",
    "            else: # 假正例\n",
    "                FP += 1\n",
    "        else: # 负例\n",
    "            if int(item_u[i]) in last_day: # 假负例\n",
    "                FN += 1\n",
    "            else: # 真负例\n",
    "                TN += 1\n",
    "\n",
    "    # 计算各类标签\n",
    "    pos = TP + FP\n",
    "    neg = TN + FN\n",
    "    \n",
    "    accuracy = round((TP + TN) * 100 / (pos + neg), 2) # 准确率\n",
    "    try:\n",
    "        precision = round(TP * 100 / pos, 2) # 精准度\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "    try:\n",
    "        recall = round(TP * 100 / (TP + FN), 2) # 召回率\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "    try:\n",
    "        specificity = round(TN * 100 / (TN + FP), 2) # 特异度\n",
    "    except ZeroDivisionError:\n",
    "        specificity = 0\n",
    "    if (precision == 0 or recall == 0):\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = round((2 * precision * recall / 100) / (precision + recall), 2) # F1 score\n",
    "    \n",
    "    return test_loss, accuracy, precision, recall, specificity, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fe2221bc-5428-480e-9511-fbd7a3616e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录训练开始时间\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a979c92e-2bc9-4c4a-a2ee-f867aad0ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5000] final loss [0.22762928903102875] accuracy[83.7] precision[15.38] recall[15.38] specificity[90.98] F1 score[0.15]\n",
      "[2/5000] final loss [0.07588911056518555] accuracy[95.77] precision[0.0] recall[0.0] specificity[97.14] F1 score[0]\n",
      "[3/5000] final loss [0.10331607609987259] accuracy[94.4] precision[12.5] recall[100.0] specificity[94.35] F1 score[0.22]\n",
      "[4/5000] final loss [0.025702161714434624] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[5/5000] final loss [0.03648802638053894] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[6/5000] final loss [0.10856612771749496] accuracy[95.19] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[7/5000] final loss [0.04397798329591751] accuracy[80.0] precision[0.0] recall[0] specificity[80.0] F1 score[0]\n",
      "[8/5000] final loss [0.22684812545776367] accuracy[96.3] precision[50.0] recall[75.0] specificity[97.12] F1 score[0.6]\n",
      "[9/5000] final loss [0.2256808876991272] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[10/5000] final loss [0.11939433217048645] accuracy[87.04] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[11/5000] final loss [0.07221613079309464] accuracy[91.59] precision[0.0] recall[0] specificity[91.59] F1 score[0]\n",
      "[12/5000] final loss [0.10362180322408676] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[13/5000] final loss [0.1465846300125122] accuracy[93.39] precision[0.0] recall[0] specificity[93.39] F1 score[0]\n",
      "[14/5000] final loss [0.056765150278806686] accuracy[89.29] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[15/5000] final loss [0.22300386428833008] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[16/5000] final loss [0.10367502272129059] accuracy[96.05] precision[50.0] recall[66.67] specificity[97.26] F1 score[0.57]\n",
      "[17/5000] final loss [0.1848422735929489] accuracy[76.56] precision[33.33] recall[25.0] specificity[88.46] F1 score[0.29]\n",
      "[18/5000] final loss [0.1914413720369339] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[19/5000] final loss [0.11939534544944763] accuracy[88.1] precision[16.67] recall[16.67] specificity[93.59] F1 score[0.17]\n",
      "[20/5000] final loss [0.09111038595438004] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[21/5000] final loss [0.0639868825674057] accuracy[87.07] precision[28.57] recall[16.67] specificity[95.19] F1 score[0.21]\n",
      "[22/5000] final loss [0.10786706209182739] accuracy[89.8] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[23/5000] final loss [0.09935177862644196] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[24/5000] final loss [0.16441591084003448] accuracy[91.84] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[25/5000] final loss [0.14261634647846222] accuracy[87.5] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[26/5000] final loss [0.27435460686683655] accuracy[92.74] precision[5.88] recall[50.0] specificity[93.1] F1 score[0.11]\n",
      "[27/5000] final loss [0.09183454513549805] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[28/5000] final loss [0.10112311691045761] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[29/5000] final loss [0.02841913513839245] accuracy[97.83] precision[0.0] recall[0] specificity[97.83] F1 score[0]\n",
      "[30/5000] final loss [0.11135482788085938] accuracy[97.22] precision[0.0] recall[0] specificity[97.22] F1 score[0]\n",
      "[31/5000] final loss [0.01026076078414917] accuracy[97.22] precision[0.0] recall[0] specificity[97.22] F1 score[0]\n",
      "[32/5000] final loss [0.15158408880233765] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[33/5000] final loss [0.11704792827367783] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[34/5000] final loss [0.1424197554588318] accuracy[92.59] precision[0.0] recall[0.0] specificity[94.34] F1 score[0]\n",
      "[35/5000] final loss [0.031315356492996216] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[36/5000] final loss [0.16855819523334503] accuracy[88.3] precision[44.44] recall[40.0] specificity[94.05] F1 score[0.42]\n",
      "[37/5000] final loss [0.04053900018334389] accuracy[88.89] precision[33.33] recall[20.0] specificity[95.92] F1 score[0.25]\n",
      "[38/5000] final loss [0.19825011491775513] accuracy[86.3] precision[33.33] recall[25.0] specificity[93.85] F1 score[0.29]\n",
      "[39/5000] final loss [0.1712597757577896] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[40/5000] final loss [0.18965771794319153] accuracy[96.3] precision[100.0] recall[75.0] specificity[100.0] F1 score[0.86]\n",
      "[41/5000] final loss [0.13744015991687775] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[42/5000] final loss [0.15834876894950867] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[43/5000] final loss [0.14758966863155365] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[44/5000] final loss [0.0742776170372963] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[45/5000] final loss [0.14099471271038055] accuracy[93.41] precision[0.0] recall[0.0] specificity[94.88] F1 score[0]\n",
      "[46/5000] final loss [0.10253789275884628] accuracy[86.67] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[47/5000] final loss [0.1358872801065445] accuracy[97.3] precision[0.0] recall[0] specificity[97.3] F1 score[0]\n",
      "[48/5000] final loss [0.13092191517353058] accuracy[92.96] precision[0.0] recall[0.0] specificity[93.91] F1 score[0]\n",
      "[49/5000] final loss [0.42281484603881836] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[50/5000] final loss [0.0708501785993576] accuracy[93.1] precision[50.0] recall[50.0] specificity[96.3] F1 score[0.5]\n",
      "[51/5000] final loss [0.14709891378879547] accuracy[93.02] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[52/5000] final loss [0.12451330572366714] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[53/5000] final loss [0.008320784196257591] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[54/5000] final loss [0.20629137754440308] accuracy[96.92] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[55/5000] final loss [0.12328455597162247] accuracy[92.86] precision[0.0] recall[0.0] specificity[93.98] F1 score[0]\n",
      "[56/5000] final loss [0.0059613389894366264] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[57/5000] final loss [0.07317496091127396] accuracy[95.77] precision[0.0] recall[0] specificity[95.77] F1 score[0]\n",
      "[58/5000] final loss [0.0679248794913292] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[59/5000] final loss [0.21070046722888947] accuracy[92.54] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[60/5000] final loss [0.010581670328974724] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[61/5000] final loss [0.2031603306531906] accuracy[93.15] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[62/5000] final loss [0.14787273108959198] accuracy[93.2] precision[0.0] recall[0.0] specificity[93.84] F1 score[0]\n",
      "[63/5000] final loss [0.10434526205062866] accuracy[92.45] precision[0.0] recall[0] specificity[92.45] F1 score[0]\n",
      "[64/5000] final loss [0.3203946650028229] accuracy[94.72] precision[0.0] recall[0] specificity[94.72] F1 score[0]\n",
      "[65/5000] final loss [0.13236361742019653] accuracy[91.4] precision[10.0] recall[9.09] specificity[95.71] F1 score[0.1]\n",
      "[66/5000] final loss [0.03822406753897667] accuracy[92.55] precision[0.0] recall[0] specificity[92.55] F1 score[0]\n",
      "[67/5000] final loss [0.25462907552719116] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[68/5000] final loss [0.051087234169244766] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[69/5000] final loss [0.11693648248910904] accuracy[90.73] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[70/5000] final loss [0.0985291451215744] accuracy[95.09] precision[0.0] recall[0] specificity[95.09] F1 score[0]\n",
      "[71/5000] final loss [0.06687647104263306] accuracy[66.67] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[72/5000] final loss [0.11047075688838959] accuracy[90.57] precision[11.11] recall[12.5] specificity[94.7] F1 score[0.12]\n",
      "[73/5000] final loss [0.2027190625667572] accuracy[86.73] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[74/5000] final loss [0.12001770734786987] accuracy[78.12] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[75/5000] final loss [0.1727810800075531] accuracy[92.65] precision[0.0] recall[0.0] specificity[96.92] F1 score[0]\n",
      "[76/5000] final loss [0.09661120176315308] accuracy[94.92] precision[0.0] recall[0.0] specificity[95.83] F1 score[0]\n",
      "[77/5000] final loss [0.11137270927429199] accuracy[92.86] precision[60.0] recall[75.0] specificity[94.74] F1 score[0.67]\n",
      "[78/5000] final loss [0.07978323101997375] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[79/5000] final loss [0.44170546531677246] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[80/5000] final loss [0.10773742944002151] accuracy[89.45] precision[11.54] recall[33.33] specificity[91.35] F1 score[0.17]\n",
      "[81/5000] final loss [0.1428871750831604] accuracy[89.11] precision[25.0] recall[28.57] specificity[93.62] F1 score[0.27]\n",
      "[82/5000] final loss [0.13514025509357452] accuracy[92.11] precision[0.0] recall[0] specificity[92.11] F1 score[0]\n",
      "[83/5000] final loss [0.05654682591557503] accuracy[84.72] precision[0.0] recall[0.0] specificity[93.85] F1 score[0]\n",
      "[84/5000] final loss [0.057945527136325836] accuracy[82.19] precision[14.29] recall[12.5] specificity[90.77] F1 score[0.13]\n",
      "[85/5000] final loss [0.2299318164587021] accuracy[95.69] precision[0.0] recall[0] specificity[95.69] F1 score[0]\n",
      "[86/5000] final loss [0.07212469726800919] accuracy[95.14] precision[0.0] recall[0] specificity[95.14] F1 score[0]\n",
      "[87/5000] final loss [0.07279844582080841] accuracy[91.89] precision[0.0] recall[0.0] specificity[97.14] F1 score[0]\n",
      "[88/5000] final loss [0.19488930702209473] accuracy[87.93] precision[23.08] recall[21.43] specificity[93.75] F1 score[0.22]\n",
      "[89/5000] final loss [0.15506760776042938] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[90/5000] final loss [0.10814626514911652] accuracy[91.58] precision[20.0] recall[20.0] specificity[95.56] F1 score[0.2]\n",
      "[91/5000] final loss [0.5007638931274414] accuracy[89.29] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[92/5000] final loss [0.11613233387470245] accuracy[90.38] precision[12.5] recall[25.0] specificity[93.0] F1 score[0.17]\n",
      "[93/5000] final loss [0.1019117683172226] accuracy[91.94] precision[0.0] recall[0] specificity[91.94] F1 score[0]\n",
      "[94/5000] final loss [0.03737589716911316] accuracy[66.67] precision[0.0] recall[0] specificity[66.67] F1 score[0]\n",
      "[95/5000] final loss [0.06791609525680542] accuracy[86.27] precision[33.33] recall[16.67] specificity[95.56] F1 score[0.22]\n",
      "[96/5000] final loss [0.046691346913576126] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[97/5000] final loss [0.16268771886825562] accuracy[94.44] precision[0.0] recall[0.0] specificity[95.41] F1 score[0]\n",
      "[98/5000] final loss [0.16081134974956512] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[99/5000] final loss [0.06293100118637085] accuracy[83.75] precision[33.33] recall[18.18] specificity[94.2] F1 score[0.24]\n",
      "[100/5000] final loss [0.27679625153541565] accuracy[92.93] precision[0.0] recall[0.0] specificity[94.48] F1 score[0]\n",
      "[101/5000] final loss [0.09875419735908508] accuracy[76.47] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[102/5000] final loss [0.014341060072183609] accuracy[97.8] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[103/5000] final loss [0.07530168443918228] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[104/5000] final loss [0.08540839701890945] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[105/5000] final loss [0.11023316532373428] accuracy[97.56] precision[0.0] recall[0] specificity[97.56] F1 score[0]\n",
      "[106/5000] final loss [0.14305908977985382] accuracy[88.29] precision[10.0] recall[20.0] specificity[91.51] F1 score[0.13]\n",
      "[107/5000] final loss [0.042807307094335556] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[108/5000] final loss [0.17868679761886597] accuracy[95.71] precision[25.0] recall[100.0] specificity[95.65] F1 score[0.4]\n",
      "[109/5000] final loss [0.1842338889837265] accuracy[91.14] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[110/5000] final loss [0.15818221867084503] accuracy[96.19] precision[0.0] recall[0] specificity[96.19] F1 score[0]\n",
      "[111/5000] final loss [0.1282624453306198] accuracy[87.32] precision[0.0] recall[0.0] specificity[95.38] F1 score[0]\n",
      "[112/5000] final loss [0.08697108179330826] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[113/5000] final loss [0.13459986448287964] accuracy[95.33] precision[0.0] recall[0.0] specificity[98.08] F1 score[0]\n",
      "[114/5000] final loss [0.10985451191663742] accuracy[94.97] precision[0.0] recall[0] specificity[94.97] F1 score[0]\n",
      "[115/5000] final loss [0.5213731527328491] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[116/5000] final loss [0.11703188717365265] accuracy[95.78] precision[0.0] recall[0] specificity[95.78] F1 score[0]\n",
      "[117/5000] final loss [0.06572800129652023] accuracy[88.55] precision[6.67] recall[7.69] specificity[93.46] F1 score[0.07]\n",
      "[118/5000] final loss [0.02422959730029106] accuracy[88.1] precision[33.33] recall[25.0] specificity[94.74] F1 score[0.29]\n",
      "[119/5000] final loss [0.18524105846881866] accuracy[96.23] precision[50.0] recall[50.0] specificity[98.04] F1 score[0.5]\n",
      "[120/5000] final loss [0.07873062789440155] accuracy[97.83] precision[50.0] recall[100.0] specificity[97.78] F1 score[0.67]\n",
      "[121/5000] final loss [0.14123687148094177] accuracy[93.94] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[122/5000] final loss [0.019385116174817085] accuracy[94.79] precision[0.0] recall[0] specificity[94.79] F1 score[0]\n",
      "[123/5000] final loss [0.05740902200341225] accuracy[89.16] precision[16.67] recall[20.0] specificity[93.59] F1 score[0.18]\n",
      "[124/5000] final loss [0.12831461429595947] accuracy[84.0] precision[50.0] recall[25.0] specificity[95.24] F1 score[0.33]\n",
      "[125/5000] final loss [0.1379777193069458] accuracy[90.43] precision[28.57] recall[25.0] specificity[95.33] F1 score[0.27]\n",
      "[126/5000] final loss [0.03991103172302246] accuracy[98.61] precision[0.0] recall[0] specificity[98.61] F1 score[0]\n",
      "[127/5000] final loss [0.1304033249616623] accuracy[90.91] precision[0.0] recall[0.0] specificity[91.95] F1 score[0]\n",
      "[128/5000] final loss [0.24540826678276062] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[129/5000] final loss [0.03840659558773041] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[130/5000] final loss [0.023365983739495277] accuracy[94.94] precision[0.0] recall[0] specificity[94.94] F1 score[0]\n",
      "[131/5000] final loss [0.042007241398096085] accuracy[95.51] precision[0.0] recall[0.0] specificity[96.59] F1 score[0]\n",
      "[132/5000] final loss [0.15272732079029083] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[133/5000] final loss [0.23917265236377716] accuracy[87.63] precision[0.0] recall[0.0] specificity[95.51] F1 score[0]\n",
      "[134/5000] final loss [0.13794241845607758] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[135/5000] final loss [0.08864356577396393] accuracy[88.57] precision[62.5] recall[35.71] specificity[96.7] F1 score[0.45]\n",
      "[136/5000] final loss [0.044727861881256104] accuracy[95.77] precision[0.0] recall[0] specificity[95.77] F1 score[0]\n",
      "[137/5000] final loss [0.1560477316379547] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[138/5000] final loss [0.10195934772491455] accuracy[92.19] precision[0.0] recall[0.0] specificity[93.65] F1 score[0]\n",
      "[139/5000] final loss [0.03021099418401718] accuracy[96.92] precision[0.0] recall[0] specificity[96.92] F1 score[0]\n",
      "[140/5000] final loss [0.08955611288547516] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[141/5000] final loss [0.07192892581224442] accuracy[90.82] precision[0.0] recall[0.0] specificity[94.68] F1 score[0]\n",
      "[142/5000] final loss [0.12206152081489563] accuracy[92.52] precision[0.0] recall[0] specificity[92.52] F1 score[0]\n",
      "[143/5000] final loss [0.3368147611618042] accuracy[85.71] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[144/5000] final loss [0.016782497987151146] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[145/5000] final loss [0.3030746281147003] accuracy[91.86] precision[33.33] recall[40.0] specificity[95.06] F1 score[0.36]\n",
      "[146/5000] final loss [0.15730349719524384] accuracy[88.97] precision[0.0] recall[0.0] specificity[90.3] F1 score[0]\n",
      "[147/5000] final loss [0.08594503253698349] accuracy[91.95] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[148/5000] final loss [0.01639402098953724] accuracy[99.09] precision[0.0] recall[0] specificity[99.09] F1 score[0]\n",
      "[149/5000] final loss [0.32066071033477783] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[150/5000] final loss [0.13020029664039612] accuracy[93.94] precision[33.33] recall[33.33] specificity[96.83] F1 score[0.33]\n",
      "[151/5000] final loss [0.1879299432039261] accuracy[94.12] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[152/5000] final loss [0.0934455618262291] accuracy[95.08] precision[0.0] recall[0] specificity[95.08] F1 score[0]\n",
      "[153/5000] final loss [0.07722315192222595] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[154/5000] final loss [0.29765042662620544] accuracy[89.19] precision[14.29] recall[14.29] specificity[94.23] F1 score[0.14]\n",
      "[155/5000] final loss [0.16501857340335846] accuracy[79.37] precision[20.0] recall[10.0] specificity[92.45] F1 score[0.13]\n",
      "[156/5000] final loss [0.013559655286371708] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[157/5000] final loss [0.15392380952835083] accuracy[87.32] precision[57.14] recall[40.0] specificity[95.08] F1 score[0.47]\n",
      "[158/5000] final loss [0.019110826775431633] accuracy[92.21] precision[0.0] recall[0.0] specificity[93.42] F1 score[0]\n",
      "[159/5000] final loss [0.06069394573569298] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[160/5000] final loss [0.13824956119060516] accuracy[87.8] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[161/5000] final loss [0.10452200472354889] accuracy[96.49] precision[0.0] recall[0.0] specificity[98.21] F1 score[0]\n",
      "[162/5000] final loss [0.18918612599372864] accuracy[93.49] precision[0.0] recall[0.0] specificity[94.05] F1 score[0]\n",
      "[163/5000] final loss [0.1448546051979065] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[164/5000] final loss [0.10045468062162399] accuracy[88.89] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[165/5000] final loss [0.10640154778957367] accuracy[94.57] precision[20.0] recall[50.0] specificity[95.56] F1 score[0.29]\n",
      "[166/5000] final loss [0.1892009973526001] accuracy[92.74] precision[0.0] recall[0.0] specificity[94.26] F1 score[0]\n",
      "[167/5000] final loss [0.18218496441841125] accuracy[89.6] precision[8.33] recall[33.33] specificity[90.98] F1 score[0.13]\n",
      "[168/5000] final loss [0.07901113480329514] accuracy[82.22] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[169/5000] final loss [0.07736934721469879] accuracy[92.45] precision[0.0] recall[0.0] specificity[94.84] F1 score[0]\n",
      "[170/5000] final loss [0.05212707817554474] accuracy[87.25] precision[0.0] recall[0.0] specificity[94.2] F1 score[0]\n",
      "[171/5000] final loss [0.16190041601657867] accuracy[88.46] precision[33.33] recall[20.0] specificity[95.74] F1 score[0.25]\n",
      "[172/5000] final loss [0.16142979264259338] accuracy[87.23] precision[30.0] recall[15.0] specificity[95.83] F1 score[0.2]\n",
      "[173/5000] final loss [0.21998611092567444] accuracy[92.0] precision[0.0] recall[0.0] specificity[93.88] F1 score[0]\n",
      "[174/5000] final loss [0.01298473495990038] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[175/5000] final loss [0.10898900032043457] accuracy[94.02] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[176/5000] final loss [0.15213903784751892] accuracy[88.94] precision[20.0] recall[17.65] specificity[94.5] F1 score[0.19]\n",
      "[177/5000] final loss [0.06719685345888138] accuracy[88.71] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[178/5000] final loss [0.25388941168785095] accuracy[85.85] precision[7.69] recall[25.0] specificity[88.24] F1 score[0.12]\n",
      "[179/5000] final loss [0.01332054752856493] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[180/5000] final loss [0.17232052981853485] accuracy[89.29] precision[0.0] recall[0] specificity[89.29] F1 score[0]\n",
      "[181/5000] final loss [0.01843453012406826] accuracy[94.55] precision[0.0] recall[0] specificity[94.55] F1 score[0]\n",
      "[182/5000] final loss [0.25465986132621765] accuracy[93.63] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[183/5000] final loss [0.06731259822845459] accuracy[93.88] precision[20.0] recall[33.33] specificity[95.79] F1 score[0.25]\n",
      "[184/5000] final loss [0.1302964836359024] accuracy[90.91] precision[33.33] recall[25.0] specificity[96.08] F1 score[0.29]\n",
      "[185/5000] final loss [0.13548816740512848] accuracy[93.78] precision[8.33] recall[50.0] specificity[94.24] F1 score[0.14]\n",
      "[186/5000] final loss [0.1534327268600464] accuracy[88.24] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[187/5000] final loss [0.057453885674476624] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[188/5000] final loss [0.0033357716165483] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[189/5000] final loss [0.17560024559497833] accuracy[83.46] precision[7.14] recall[10.0] specificity[89.43] F1 score[0.08]\n",
      "[190/5000] final loss [0.07946208864450455] accuracy[88.71] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[191/5000] final loss [0.06512884795665741] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[192/5000] final loss [0.14077048003673553] accuracy[92.44] precision[0.0] recall[0.0] specificity[94.02] F1 score[0]\n",
      "[193/5000] final loss [0.11935495585203171] accuracy[89.57] precision[0.0] recall[0.0] specificity[92.79] F1 score[0]\n",
      "[194/5000] final loss [0.19669993221759796] accuracy[88.99] precision[0.0] recall[0.0] specificity[93.27] F1 score[0]\n",
      "[195/5000] final loss [0.10126808285713196] accuracy[92.5] precision[12.5] recall[33.33] specificity[94.02] F1 score[0.18]\n",
      "[196/5000] final loss [0.07083785533905029] accuracy[95.19] precision[40.0] recall[50.0] specificity[97.0] F1 score[0.44]\n",
      "[197/5000] final loss [0.014067564159631729] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[198/5000] final loss [0.030793016776442528] accuracy[91.49] precision[0.0] recall[0] specificity[91.49] F1 score[0]\n",
      "[199/5000] final loss [0.11472059786319733] accuracy[92.54] precision[0.0] recall[0] specificity[92.54] F1 score[0]\n",
      "[200/5000] final loss [0.08880603313446045] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[201/5000] final loss [0.08517365902662277] accuracy[88.71] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[202/5000] final loss [0.06408290565013885] accuracy[96.51] precision[0.0] recall[0] specificity[96.51] F1 score[0]\n",
      "[203/5000] final loss [0.11030948162078857] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[204/5000] final loss [0.1853579580783844] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[205/5000] final loss [0.1815345138311386] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[206/5000] final loss [0.14100588858127594] accuracy[91.82] precision[14.29] recall[25.0] specificity[94.34] F1 score[0.18]\n",
      "[207/5000] final loss [0.03658971190452576] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[208/5000] final loss [0.07984082400798798] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[209/5000] final loss [0.1533471643924713] accuracy[94.83] precision[0.0] recall[0] specificity[94.83] F1 score[0]\n",
      "[210/5000] final loss [0.19622492790222168] accuracy[80.6] precision[14.29] recall[4.76] specificity[94.69] F1 score[0.07]\n",
      "[211/5000] final loss [0.08359966427087784] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[212/5000] final loss [0.05238411948084831] accuracy[87.23] precision[0.0] recall[0.0] specificity[93.18] F1 score[0]\n",
      "[213/5000] final loss [0.019935794174671173] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[214/5000] final loss [0.026513107120990753] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[215/5000] final loss [0.046618279069662094] accuracy[93.94] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[216/5000] final loss [0.21327809989452362] accuracy[97.1] precision[0.0] recall[0] specificity[97.1] F1 score[0]\n",
      "[217/5000] final loss [0.15182632207870483] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[218/5000] final loss [0.15454749763011932] accuracy[93.69] precision[28.57] recall[50.0] specificity[95.33] F1 score[0.36]\n",
      "[219/5000] final loss [0.15971024334430695] accuracy[91.85] precision[0.0] recall[0.0] specificity[93.23] F1 score[0]\n",
      "[220/5000] final loss [0.3340381979942322] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[221/5000] final loss [0.08996143937110901] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[222/5000] final loss [0.06279020011425018] accuracy[84.68] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[223/5000] final loss [0.1851208209991455] accuracy[89.75] precision[0.0] recall[0.0] specificity[92.02] F1 score[0]\n",
      "[224/5000] final loss [0.16127629578113556] accuracy[92.34] precision[10.0] recall[12.5] specificity[95.52] F1 score[0.11]\n",
      "[225/5000] final loss [0.034875549376010895] accuracy[94.81] precision[0.0] recall[0] specificity[94.81] F1 score[0]\n",
      "[226/5000] final loss [0.16296227276325226] accuracy[78.85] precision[33.33] recall[10.0] specificity[95.24] F1 score[0.15]\n",
      "[227/5000] final loss [0.19954651594161987] accuracy[95.0] precision[20.0] recall[50.0] specificity[95.92] F1 score[0.29]\n",
      "[228/5000] final loss [0.08674609661102295] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[229/5000] final loss [0.0264759361743927] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[230/5000] final loss [0.4069667458534241] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[231/5000] final loss [0.05452970787882805] accuracy[94.39] precision[0.0] recall[0.0] specificity[95.28] F1 score[0]\n",
      "[232/5000] final loss [0.34536150097846985] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[233/5000] final loss [0.28065040707588196] accuracy[93.75] precision[50.0] recall[50.0] specificity[96.67] F1 score[0.5]\n",
      "[234/5000] final loss [0.04612191021442413] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[235/5000] final loss [0.1770530343055725] accuracy[93.81] precision[0.0] recall[0] specificity[93.81] F1 score[0]\n",
      "[236/5000] final loss [0.2043234407901764] accuracy[92.5] precision[0.0] recall[0] specificity[92.5] F1 score[0]\n",
      "[237/5000] final loss [0.03637227416038513] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[238/5000] final loss [0.19750042259693146] accuracy[77.73] precision[22.81] recall[20.0] specificity[87.98] F1 score[0.21]\n",
      "[239/5000] final loss [0.06506333500146866] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[240/5000] final loss [0.2494487762451172] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[241/5000] final loss [0.11930252611637115] accuracy[92.68] precision[0.0] recall[0.0] specificity[93.25] F1 score[0]\n",
      "[242/5000] final loss [0.12346333265304565] accuracy[90.0] precision[0.0] recall[0.0] specificity[91.14] F1 score[0]\n",
      "[243/5000] final loss [0.13868416845798492] accuracy[86.89] precision[66.67] recall[22.22] specificity[98.08] F1 score[0.33]\n",
      "[244/5000] final loss [0.11441347002983093] accuracy[90.0] precision[12.5] recall[25.0] specificity[92.71] F1 score[0.17]\n",
      "[245/5000] final loss [0.1271422654390335] accuracy[95.4] precision[20.0] recall[100.0] specificity[95.35] F1 score[0.33]\n",
      "[246/5000] final loss [0.12145009636878967] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[247/5000] final loss [0.11759290844202042] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[248/5000] final loss [0.3016645908355713] accuracy[92.45] precision[0.0] recall[0] specificity[92.45] F1 score[0]\n",
      "[249/5000] final loss [0.10135820508003235] accuracy[93.14] precision[0.0] recall[0] specificity[93.14] F1 score[0]\n",
      "[250/5000] final loss [0.03501443192362785] accuracy[95.65] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[251/5000] final loss [0.05994979292154312] accuracy[90.79] precision[0.0] recall[0.0] specificity[93.24] F1 score[0]\n",
      "[252/5000] final loss [0.1501428335905075] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[253/5000] final loss [0.06894168257713318] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[254/5000] final loss [0.15726272761821747] accuracy[95.18] precision[0.0] recall[0] specificity[95.18] F1 score[0]\n",
      "[255/5000] final loss [0.12541939318180084] accuracy[93.29] precision[0.0] recall[0] specificity[93.29] F1 score[0]\n",
      "[256/5000] final loss [0.1244245246052742] accuracy[91.36] precision[0.0] recall[0] specificity[91.36] F1 score[0]\n",
      "[257/5000] final loss [0.15175683796405792] accuracy[91.27] precision[22.22] recall[33.33] specificity[94.17] F1 score[0.27]\n",
      "[258/5000] final loss [0.3291966915130615] accuracy[93.44] precision[0.0] recall[0] specificity[93.44] F1 score[0]\n",
      "[259/5000] final loss [0.13312771916389465] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[260/5000] final loss [0.17986945807933807] accuracy[96.08] precision[0.0] recall[0] specificity[96.08] F1 score[0]\n",
      "[261/5000] final loss [0.14458434283733368] accuracy[94.56] precision[0.0] recall[0.0] specificity[95.21] F1 score[0]\n",
      "[262/5000] final loss [0.14653605222702026] accuracy[89.17] precision[0.0] recall[0.0] specificity[93.04] F1 score[0]\n",
      "[263/5000] final loss [0.1841937005519867] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[264/5000] final loss [0.0716487467288971] accuracy[94.39] precision[16.67] recall[50.0] specificity[95.24] F1 score[0.25]\n",
      "[265/5000] final loss [0.19818927347660065] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[266/5000] final loss [0.21323667466640472] accuracy[90.67] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[267/5000] final loss [0.06378645449876785] accuracy[86.36] precision[0.0] recall[0.0] specificity[90.48] F1 score[0]\n",
      "[268/5000] final loss [0.04656404256820679] accuracy[96.43] precision[0.0] recall[0.0] specificity[97.3] F1 score[0]\n",
      "[269/5000] final loss [0.03688793629407883] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[270/5000] final loss [0.1021234542131424] accuracy[89.5] precision[7.69] recall[10.0] specificity[93.68] F1 score[0.09]\n",
      "[271/5000] final loss [0.30243512988090515] accuracy[92.44] precision[0.0] recall[0] specificity[92.44] F1 score[0]\n",
      "[272/5000] final loss [0.21133336424827576] accuracy[94.52] precision[20.0] recall[100.0] specificity[94.44] F1 score[0.33]\n",
      "[273/5000] final loss [0.14648942649364471] accuracy[94.74] precision[100.0] recall[60.0] specificity[100.0] F1 score[0.75]\n",
      "[274/5000] final loss [0.05125386640429497] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[275/5000] final loss [0.21037514507770538] accuracy[87.88] precision[18.18] recall[22.22] specificity[92.68] F1 score[0.2]\n",
      "[276/5000] final loss [0.049917884171009064] accuracy[91.84] precision[0.0] recall[0] specificity[91.84] F1 score[0]\n",
      "[277/5000] final loss [0.2888135015964508] accuracy[87.3] precision[25.0] recall[16.67] specificity[94.74] F1 score[0.2]\n",
      "[278/5000] final loss [0.17307054996490479] accuracy[94.2] precision[0.0] recall[0] specificity[94.2] F1 score[0]\n",
      "[279/5000] final loss [0.13456782698631287] accuracy[88.24] precision[0.0] recall[0.0] specificity[95.07] F1 score[0]\n",
      "[280/5000] final loss [0.30917611718177795] accuracy[91.89] precision[37.5] recall[42.86] specificity[95.19] F1 score[0.4]\n",
      "[281/5000] final loss [0.12112414836883545] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[282/5000] final loss [0.06547518819570541] accuracy[94.2] precision[0.0] recall[0.0] specificity[97.01] F1 score[0]\n",
      "[283/5000] final loss [0.21714313328266144] accuracy[90.91] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[284/5000] final loss [0.0246021319180727] accuracy[89.77] precision[0.0] recall[0.0] specificity[97.53] F1 score[0]\n",
      "[285/5000] final loss [0.0657166913151741] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[286/5000] final loss [0.06981055438518524] accuracy[90.45] precision[10.0] recall[14.29] specificity[94.0] F1 score[0.12]\n",
      "[287/5000] final loss [0.14467908442020416] accuracy[90.32] precision[25.0] recall[40.0] specificity[93.18] F1 score[0.31]\n",
      "[288/5000] final loss [0.07958958297967911] accuracy[95.95] precision[0.0] recall[0] specificity[95.95] F1 score[0]\n",
      "[289/5000] final loss [0.03931615874171257] accuracy[86.27] precision[14.29] recall[11.11] specificity[93.55] F1 score[0.13]\n",
      "[290/5000] final loss [0.29542505741119385] accuracy[90.26] precision[15.0] recall[25.0] specificity[93.33] F1 score[0.19]\n",
      "[291/5000] final loss [0.19921495020389557] accuracy[84.03] precision[28.57] recall[30.77] specificity[90.57] F1 score[0.3]\n",
      "[292/5000] final loss [0.11094934493303299] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[293/5000] final loss [0.08780631422996521] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[294/5000] final loss [0.12346000224351883] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[295/5000] final loss [0.15553908050060272] accuracy[86.99] precision[0.0] recall[0.0] specificity[91.45] F1 score[0]\n",
      "[296/5000] final loss [0.10647322237491608] accuracy[92.54] precision[0.0] recall[0] specificity[92.54] F1 score[0]\n",
      "[297/5000] final loss [0.1550382524728775] accuracy[70.97] precision[0.0] recall[0.0] specificity[88.0] F1 score[0]\n",
      "[298/5000] final loss [0.038127582520246506] accuracy[96.72] precision[0.0] recall[0.0] specificity[98.33] F1 score[0]\n",
      "[299/5000] final loss [0.09966465085744858] accuracy[96.0] precision[100.0] recall[66.67] specificity[100.0] F1 score[0.8]\n",
      "[300/5000] final loss [0.19679997861385345] accuracy[93.81] precision[20.0] recall[33.33] specificity[95.74] F1 score[0.25]\n",
      "[301/5000] final loss [0.12383240461349487] accuracy[72.77] precision[21.43] recall[5.36] specificity[93.85] F1 score[0.09]\n",
      "[302/5000] final loss [0.006608997471630573] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[303/5000] final loss [0.10820998251438141] accuracy[87.3] precision[22.22] recall[19.05] specificity[93.72] F1 score[0.21]\n",
      "[304/5000] final loss [0.06438110768795013] accuracy[86.58] precision[25.0] recall[12.5] specificity[95.49] F1 score[0.17]\n",
      "[305/5000] final loss [0.05472642555832863] accuracy[91.18] precision[0.0] recall[0] specificity[91.18] F1 score[0]\n",
      "[306/5000] final loss [0.06333404034376144] accuracy[96.51] precision[0.0] recall[0] specificity[96.51] F1 score[0]\n",
      "[307/5000] final loss [0.05020541697740555] accuracy[90.2] precision[0.0] recall[0.0] specificity[93.88] F1 score[0]\n",
      "[308/5000] final loss [0.14679251611232758] accuracy[82.33] precision[9.09] recall[7.69] specificity[91.03] F1 score[0.08]\n",
      "[309/5000] final loss [0.20639029145240784] accuracy[96.23] precision[0.0] recall[0] specificity[96.23] F1 score[0]\n",
      "[310/5000] final loss [0.22704258561134338] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[311/5000] final loss [0.06481971591711044] accuracy[96.43] precision[25.0] recall[100.0] specificity[96.39] F1 score[0.4]\n",
      "[312/5000] final loss [0.03429635614156723] accuracy[98.44] precision[0.0] recall[0] specificity[98.44] F1 score[0]\n",
      "[313/5000] final loss [0.13270801305770874] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[314/5000] final loss [0.11100777238607407] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[315/5000] final loss [0.19837552309036255] accuracy[95.61] precision[0.0] recall[0] specificity[95.61] F1 score[0]\n",
      "[316/5000] final loss [0.21596229076385498] accuracy[83.87] precision[10.0] recall[14.29] specificity[89.53] F1 score[0.12]\n",
      "[317/5000] final loss [0.06460901349782944] accuracy[95.93] precision[0.0] recall[0.0] specificity[97.52] F1 score[0]\n",
      "[318/5000] final loss [0.06632836908102036] accuracy[92.41] precision[0.0] recall[0.0] specificity[96.05] F1 score[0]\n",
      "[319/5000] final loss [0.16274632513523102] accuracy[92.59] precision[66.67] recall[66.67] specificity[95.83] F1 score[0.67]\n",
      "[320/5000] final loss [0.04424413666129112] accuracy[95.38] precision[0.0] recall[0.0] specificity[97.64] F1 score[0]\n",
      "[321/5000] final loss [0.1683504283428192] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[322/5000] final loss [0.11547855287790298] accuracy[90.0] precision[0.0] recall[0.0] specificity[92.65] F1 score[0]\n",
      "[323/5000] final loss [0.10212589055299759] accuracy[95.92] precision[0.0] recall[0.0] specificity[96.58] F1 score[0]\n",
      "[324/5000] final loss [0.12858156859874725] accuracy[97.83] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[325/5000] final loss [0.14816603064537048] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[326/5000] final loss [0.14320600032806396] accuracy[78.26] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[327/5000] final loss [0.17763766646385193] accuracy[94.03] precision[0.0] recall[0] specificity[94.03] F1 score[0]\n",
      "[328/5000] final loss [0.04341801628470421] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[329/5000] final loss [0.05133843049407005] accuracy[94.12] precision[50.0] recall[100.0] specificity[93.75] F1 score[0.67]\n",
      "[330/5000] final loss [0.06586074084043503] accuracy[95.77] precision[0.0] recall[0] specificity[95.77] F1 score[0]\n",
      "[331/5000] final loss [0.09204000979661942] accuracy[97.92] precision[100.0] recall[66.67] specificity[100.0] F1 score[0.8]\n",
      "[332/5000] final loss [0.09321028739213943] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[333/5000] final loss [0.011213126592338085] accuracy[90.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[334/5000] final loss [0.15615323185920715] accuracy[87.06] precision[7.41] recall[9.52] specificity[92.16] F1 score[0.08]\n",
      "[335/5000] final loss [0.15951183438301086] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[336/5000] final loss [0.07843833416700363] accuracy[93.18] precision[33.33] recall[50.0] specificity[95.24] F1 score[0.4]\n",
      "[337/5000] final loss [0.02400602027773857] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[338/5000] final loss [0.10856452584266663] accuracy[84.11] precision[23.53] recall[26.67] specificity[90.44] F1 score[0.25]\n",
      "[339/5000] final loss [0.13900336623191833] accuracy[94.23] precision[0.0] recall[0] specificity[94.23] F1 score[0]\n",
      "[340/5000] final loss [0.017872203141450882] accuracy[96.55] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[341/5000] final loss [0.12052426487207413] accuracy[85.44] precision[37.5] recall[23.08] specificity[94.44] F1 score[0.29]\n",
      "[342/5000] final loss [0.17683354020118713] accuracy[88.89] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[343/5000] final loss [0.21005357801914215] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[344/5000] final loss [0.09702407568693161] accuracy[95.08] precision[0.0] recall[0.0] specificity[96.67] F1 score[0]\n",
      "[345/5000] final loss [0.04344968870282173] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[346/5000] final loss [0.013433864340186119] accuracy[96.47] precision[0.0] recall[0.0] specificity[97.62] F1 score[0]\n",
      "[347/5000] final loss [0.20386840403079987] accuracy[92.02] precision[8.33] recall[33.33] specificity[93.12] F1 score[0.13]\n",
      "[348/5000] final loss [0.032350052148103714] accuracy[92.73] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[349/5000] final loss [0.007606868632137775] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[350/5000] final loss [0.042591195553541183] accuracy[92.19] precision[0.0] recall[0] specificity[92.19] F1 score[0]\n",
      "[351/5000] final loss [0.13533735275268555] accuracy[83.44] precision[18.18] recall[11.11] specificity[93.23] F1 score[0.14]\n",
      "[352/5000] final loss [0.025475770235061646] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[353/5000] final loss [0.11651989072561264] accuracy[92.13] precision[13.33] recall[33.33] specificity[93.81] F1 score[0.19]\n",
      "[354/5000] final loss [0.11403423547744751] accuracy[93.94] precision[33.33] recall[100.0] specificity[93.75] F1 score[0.5]\n",
      "[355/5000] final loss [0.05512140318751335] accuracy[89.47] precision[0.0] recall[0] specificity[89.47] F1 score[0]\n",
      "[356/5000] final loss [0.13640840351581573] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[357/5000] final loss [0.08863937854766846] accuracy[91.67] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[358/5000] final loss [0.06216021999716759] accuracy[92.54] precision[25.0] recall[33.33] specificity[95.31] F1 score[0.29]\n",
      "[359/5000] final loss [0.07319727540016174] accuracy[92.59] precision[0.0] recall[0.0] specificity[96.15] F1 score[0]\n",
      "[360/5000] final loss [0.04783717170357704] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[361/5000] final loss [0.1083989292383194] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[362/5000] final loss [0.16409070789813995] accuracy[87.06] precision[42.86] recall[30.0] specificity[94.67] F1 score[0.35]\n",
      "[363/5000] final loss [0.05440995469689369] accuracy[92.98] precision[33.33] recall[33.33] specificity[96.3] F1 score[0.33]\n",
      "[364/5000] final loss [0.02533465437591076] accuracy[65.12] precision[50.0] recall[6.67] specificity[96.43] F1 score[0.12]\n",
      "[365/5000] final loss [0.05486386641860008] accuracy[92.94] precision[0.0] recall[0.0] specificity[96.34] F1 score[0]\n",
      "[366/5000] final loss [0.07584866136312485] accuracy[90.57] precision[0.0] recall[0] specificity[90.57] F1 score[0]\n",
      "[367/5000] final loss [0.07701794803142548] accuracy[92.41] precision[0.0] recall[0] specificity[92.41] F1 score[0]\n",
      "[368/5000] final loss [0.09612368792295456] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[369/5000] final loss [0.033251553773880005] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[370/5000] final loss [0.09156407415866852] accuracy[96.0] precision[25.0] recall[100.0] specificity[95.95] F1 score[0.4]\n",
      "[371/5000] final loss [0.11041867733001709] accuracy[97.06] precision[50.0] recall[100.0] specificity[96.97] F1 score[0.67]\n",
      "[372/5000] final loss [0.1122952550649643] accuracy[92.68] precision[0.0] recall[0] specificity[92.68] F1 score[0]\n",
      "[373/5000] final loss [0.1208171397447586] accuracy[95.12] precision[10.0] recall[50.0] specificity[95.57] F1 score[0.17]\n",
      "[374/5000] final loss [0.10169929265975952] accuracy[92.68] precision[11.11] recall[20.0] specificity[94.97] F1 score[0.14]\n",
      "[375/5000] final loss [0.054791178554296494] accuracy[90.08] precision[33.33] recall[9.09] specificity[98.18] F1 score[0.14]\n",
      "[376/5000] final loss [0.169768825173378] accuracy[92.66] precision[14.29] recall[33.33] specificity[94.34] F1 score[0.2]\n",
      "[377/5000] final loss [0.10422856360673904] accuracy[94.38] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[378/5000] final loss [0.1833547204732895] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[379/5000] final loss [0.03929734230041504] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[380/5000] final loss [0.09955696016550064] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[381/5000] final loss [0.08676237612962723] accuracy[94.62] precision[0.0] recall[0] specificity[94.62] F1 score[0]\n",
      "[382/5000] final loss [0.21701961755752563] accuracy[94.21] precision[0.0] recall[0] specificity[94.21] F1 score[0]\n",
      "[383/5000] final loss [0.17595824599266052] accuracy[89.8] precision[11.11] recall[33.33] specificity[91.58] F1 score[0.17]\n",
      "[384/5000] final loss [0.10105730593204498] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[385/5000] final loss [0.1417780965566635] accuracy[97.56] precision[0.0] recall[0.0] specificity[98.04] F1 score[0]\n",
      "[386/5000] final loss [0.03723197057843208] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[387/5000] final loss [0.03673671558499336] accuracy[88.24] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[388/5000] final loss [0.07125098258256912] accuracy[93.51] precision[0.0] recall[0] specificity[93.51] F1 score[0]\n",
      "[389/5000] final loss [0.11038579791784286] accuracy[92.31] precision[16.67] recall[33.33] specificity[94.32] F1 score[0.22]\n",
      "[390/5000] final loss [0.13619138300418854] accuracy[86.96] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[391/5000] final loss [0.15199077129364014] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[392/5000] final loss [0.05436220392584801] accuracy[92.91] precision[0.0] recall[0.0] specificity[93.65] F1 score[0]\n",
      "[393/5000] final loss [0.1390753835439682] accuracy[85.29] precision[8.33] recall[6.67] specificity[92.9] F1 score[0.07]\n",
      "[394/5000] final loss [0.17424164712429047] accuracy[96.24] precision[0.0] recall[0] specificity[96.24] F1 score[0]\n",
      "[395/5000] final loss [0.07419151812791824] accuracy[95.52] precision[50.0] recall[33.33] specificity[98.44] F1 score[0.4]\n",
      "[396/5000] final loss [0.16514913737773895] accuracy[90.43] precision[0.0] recall[0.0] specificity[91.4] F1 score[0]\n",
      "[397/5000] final loss [0.14371569454669952] accuracy[94.9] precision[0.0] recall[0.0] specificity[95.88] F1 score[0]\n",
      "[398/5000] final loss [0.12653659284114838] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[399/5000] final loss [0.11829827725887299] accuracy[93.06] precision[0.0] recall[0] specificity[93.06] F1 score[0]\n",
      "[400/5000] final loss [0.24224114418029785] accuracy[93.82] precision[0.0] recall[0.0] specificity[94.89] F1 score[0]\n",
      "[401/5000] final loss [0.10427361726760864] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[402/5000] final loss [0.07765009999275208] accuracy[93.96] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[403/5000] final loss [0.14504659175872803] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[404/5000] final loss [0.15684202313423157] accuracy[88.5] precision[38.46] recall[50.0] specificity[92.23] F1 score[0.43]\n",
      "[405/5000] final loss [0.12981592118740082] accuracy[91.27] precision[16.67] recall[14.29] specificity[95.8] F1 score[0.15]\n",
      "[406/5000] final loss [0.03551577776670456] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[407/5000] final loss [0.01703205145895481] accuracy[73.68] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[408/5000] final loss [0.1470704972743988] accuracy[94.96] precision[0.0] recall[0] specificity[94.96] F1 score[0]\n",
      "[409/5000] final loss [0.19409070909023285] accuracy[85.82] precision[25.0] recall[13.33] specificity[94.96] F1 score[0.17]\n",
      "[410/5000] final loss [0.01020333543419838] accuracy[96.36] precision[0.0] recall[0] specificity[96.36] F1 score[0]\n",
      "[411/5000] final loss [0.20107930898666382] accuracy[95.92] precision[0.0] recall[0] specificity[95.92] F1 score[0]\n",
      "[412/5000] final loss [0.03610420972108841] accuracy[94.05] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[413/5000] final loss [0.16489079594612122] accuracy[66.67] precision[0.0] recall[0] specificity[66.67] F1 score[0]\n",
      "[414/5000] final loss [0.15392935276031494] accuracy[96.08] precision[0.0] recall[0] specificity[96.08] F1 score[0]\n",
      "[415/5000] final loss [0.07006889581680298] accuracy[86.75] precision[0.0] recall[0.0] specificity[93.51] F1 score[0]\n",
      "[416/5000] final loss [0.04315222054719925] accuracy[85.71] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[417/5000] final loss [0.1938125342130661] accuracy[87.96] precision[0.0] recall[0.0] specificity[91.35] F1 score[0]\n",
      "[418/5000] final loss [0.013011551462113857] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[419/5000] final loss [0.32895272970199585] accuracy[95.77] precision[25.0] recall[100.0] specificity[95.71] F1 score[0.4]\n",
      "[420/5000] final loss [0.22269169986248016] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[421/5000] final loss [0.11183001846075058] accuracy[95.0] precision[16.67] recall[100.0] specificity[94.95] F1 score[0.29]\n",
      "[422/5000] final loss [0.19753307104110718] accuracy[76.92] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[423/5000] final loss [0.1512674242258072] accuracy[90.0] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[424/5000] final loss [0.16913403570652008] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[425/5000] final loss [0.13726775348186493] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[426/5000] final loss [0.0815892443060875] accuracy[87.5] precision[50.0] recall[33.33] specificity[95.24] F1 score[0.4]\n",
      "[427/5000] final loss [0.07750464230775833] accuracy[91.07] precision[20.0] recall[50.0] specificity[92.59] F1 score[0.29]\n",
      "[428/5000] final loss [0.04631941393017769] accuracy[90.0] precision[50.0] recall[50.0] specificity[94.44] F1 score[0.5]\n",
      "[429/5000] final loss [0.14704467356204987] accuracy[91.95] precision[0.0] recall[0.0] specificity[95.81] F1 score[0]\n",
      "[430/5000] final loss [0.14106117188930511] accuracy[85.86] precision[0.0] recall[0.0] specificity[93.41] F1 score[0]\n",
      "[431/5000] final loss [0.10779336839914322] accuracy[92.97] precision[0.0] recall[0.0] specificity[93.7] F1 score[0]\n",
      "[432/5000] final loss [0.05276772752404213] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[433/5000] final loss [0.17775769531726837] accuracy[90.16] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[434/5000] final loss [0.11644081026315689] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[435/5000] final loss [0.1614226996898651] accuracy[94.57] precision[40.0] recall[50.0] specificity[96.59] F1 score[0.44]\n",
      "[436/5000] final loss [0.046007078140974045] accuracy[87.8] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[437/5000] final loss [0.3223293125629425] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[438/5000] final loss [0.09333493560552597] accuracy[90.91] precision[0.0] recall[0.0] specificity[92.11] F1 score[0]\n",
      "[439/5000] final loss [0.15162357687950134] accuracy[92.31] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[440/5000] final loss [0.03597303479909897] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[441/5000] final loss [0.13352441787719727] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[442/5000] final loss [0.18049199879169464] accuracy[86.87] precision[16.67] recall[21.43] specificity[91.85] F1 score[0.19]\n",
      "[443/5000] final loss [0.04937191680073738] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[444/5000] final loss [0.030988451093435287] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[445/5000] final loss [0.04784543439745903] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[446/5000] final loss [0.13336487114429474] accuracy[92.94] precision[0.0] recall[0] specificity[92.94] F1 score[0]\n",
      "[447/5000] final loss [0.08784529566764832] accuracy[85.94] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[448/5000] final loss [0.14892223477363586] accuracy[92.06] precision[33.33] recall[25.0] specificity[96.61] F1 score[0.29]\n",
      "[449/5000] final loss [0.030980929732322693] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[450/5000] final loss [0.12863914668560028] accuracy[95.33] precision[20.0] recall[50.0] specificity[96.19] F1 score[0.29]\n",
      "[451/5000] final loss [0.029747430235147476] accuracy[93.02] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[452/5000] final loss [0.07308550179004669] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[453/5000] final loss [0.06198255345225334] accuracy[94.03] precision[20.0] recall[100.0] specificity[93.94] F1 score[0.33]\n",
      "[454/5000] final loss [0.06267928332090378] accuracy[82.18] precision[11.11] recall[9.09] specificity[91.11] F1 score[0.1]\n",
      "[455/5000] final loss [0.08434131741523743] accuracy[94.74] precision[0.0] recall[0.0] specificity[95.74] F1 score[0]\n",
      "[456/5000] final loss [0.138542041182518] accuracy[86.81] precision[0.0] recall[0.0] specificity[92.94] F1 score[0]\n",
      "[457/5000] final loss [0.021634018048644066] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[458/5000] final loss [0.01976984553039074] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[459/5000] final loss [0.035388655960559845] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[460/5000] final loss [0.015785420313477516] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[461/5000] final loss [0.12185628712177277] accuracy[95.05] precision[0.0] recall[0] specificity[95.05] F1 score[0]\n",
      "[462/5000] final loss [0.14526186883449554] accuracy[91.75] precision[21.05] recall[30.77] specificity[94.6] F1 score[0.25]\n",
      "[463/5000] final loss [0.009566204622387886] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[464/5000] final loss [0.17466741800308228] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[465/5000] final loss [0.016498988494277] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[466/5000] final loss [0.11261779069900513] accuracy[83.25] precision[5.88] recall[5.56] specificity[91.06] F1 score[0.06]\n",
      "[467/5000] final loss [0.09813438355922699] accuracy[86.84] precision[12.5] recall[25.0] specificity[90.28] F1 score[0.17]\n",
      "[468/5000] final loss [0.091085284948349] accuracy[88.89] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[469/5000] final loss [0.16959647834300995] accuracy[88.06] precision[20.0] recall[7.69] specificity[96.69] F1 score[0.11]\n",
      "[470/5000] final loss [0.2108018696308136] accuracy[94.55] precision[0.0] recall[0] specificity[94.55] F1 score[0]\n",
      "[471/5000] final loss [0.13393071293830872] accuracy[92.96] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[472/5000] final loss [0.05742340907454491] accuracy[91.24] precision[0.0] recall[0.0] specificity[93.28] F1 score[0]\n",
      "[473/5000] final loss [0.12046795338392258] accuracy[87.5] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[474/5000] final loss [0.18279705941677094] accuracy[94.69] precision[0.0] recall[0] specificity[94.69] F1 score[0]\n",
      "[475/5000] final loss [0.13894443213939667] accuracy[83.52] precision[16.67] recall[9.09] specificity[93.75] F1 score[0.12]\n",
      "[476/5000] final loss [0.12947946786880493] accuracy[83.78] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[477/5000] final loss [0.14987727999687195] accuracy[92.24] precision[33.33] recall[28.57] specificity[96.33] F1 score[0.31]\n",
      "[478/5000] final loss [0.13537687063217163] accuracy[85.44] precision[0.0] recall[0.0] specificity[94.62] F1 score[0]\n",
      "[479/5000] final loss [0.11438291519880295] accuracy[85.71] precision[50.0] recall[16.67] specificity[97.22] F1 score[0.25]\n",
      "[480/5000] final loss [0.0848768875002861] accuracy[90.91] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[481/5000] final loss [0.08943301439285278] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[482/5000] final loss [0.07763563096523285] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[483/5000] final loss [0.2544602155685425] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[484/5000] final loss [0.15118379890918732] accuracy[89.71] precision[20.0] recall[25.0] specificity[93.75] F1 score[0.22]\n",
      "[485/5000] final loss [0.08740534633398056] accuracy[89.13] precision[0.0] recall[0.0] specificity[93.18] F1 score[0]\n",
      "[486/5000] final loss [0.22584222257137299] accuracy[91.91] precision[0.0] recall[0.0] specificity[94.7] F1 score[0]\n",
      "[487/5000] final loss [0.07970175892114639] accuracy[87.5] precision[0.0] recall[0.0] specificity[91.5] F1 score[0]\n",
      "[488/5000] final loss [0.16238634288311005] accuracy[82.86] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[489/5000] final loss [0.08492860943078995] accuracy[84.47] precision[11.76] recall[16.67] specificity[89.93] F1 score[0.14]\n",
      "[490/5000] final loss [0.1656986027956009] accuracy[93.64] precision[0.0] recall[0.0] specificity[94.5] F1 score[0]\n",
      "[491/5000] final loss [0.023363744840025902] accuracy[92.45] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[492/5000] final loss [0.2398207038640976] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[493/5000] final loss [0.1702057272195816] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[494/5000] final loss [0.06467470526695251] accuracy[93.51] precision[0.0] recall[0] specificity[93.51] F1 score[0]\n",
      "[495/5000] final loss [0.09237438440322876] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[496/5000] final loss [0.003362633055076003] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[497/5000] final loss [0.020540956407785416] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[498/5000] final loss [0.14753080904483795] accuracy[83.64] precision[33.33] recall[12.5] specificity[95.74] F1 score[0.18]\n",
      "[499/5000] final loss [0.12059053778648376] accuracy[92.73] precision[0.0] recall[0] specificity[92.73] F1 score[0]\n",
      "[500/5000] final loss [0.03227655217051506] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[501/5000] final loss [0.10336939990520477] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[502/5000] final loss [0.04028419405221939] accuracy[91.84] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[503/5000] final loss [0.15546154975891113] accuracy[85.48] precision[21.43] recall[15.79] specificity[93.41] F1 score[0.18]\n",
      "[504/5000] final loss [0.10378871858119965] accuracy[92.43] precision[0.0] recall[0.0] specificity[93.96] F1 score[0]\n",
      "[505/5000] final loss [0.171901136636734] accuracy[90.77] precision[0.0] recall[0.0] specificity[93.65] F1 score[0]\n",
      "[506/5000] final loss [0.09410487860441208] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[507/5000] final loss [0.038218192756175995] accuracy[82.49] precision[18.18] recall[8.33] specificity[94.12] F1 score[0.11]\n",
      "[508/5000] final loss [0.039305679500103] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[509/5000] final loss [0.13795284926891327] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[510/5000] final loss [0.08976417779922485] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[511/5000] final loss [0.259047269821167] accuracy[89.37] precision[17.65] recall[18.75] specificity[94.12] F1 score[0.18]\n",
      "[512/5000] final loss [0.13836194574832916] accuracy[86.55] precision[8.33] recall[16.67] specificity[90.27] F1 score[0.11]\n",
      "[513/5000] final loss [0.2080601155757904] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[514/5000] final loss [0.03566891327500343] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[515/5000] final loss [0.0696646049618721] accuracy[91.23] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[516/5000] final loss [0.09586922079324722] accuracy[86.96] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[517/5000] final loss [0.0955502912402153] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[518/5000] final loss [0.06290806084871292] accuracy[92.06] precision[0.0] recall[0] specificity[92.06] F1 score[0]\n",
      "[519/5000] final loss [0.034803200513124466] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[520/5000] final loss [0.13203828036785126] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[521/5000] final loss [0.1611107736825943] accuracy[89.53] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[522/5000] final loss [0.18769685924053192] accuracy[85.62] precision[23.81] recall[50.0] specificity[88.24] F1 score[0.32]\n",
      "[523/5000] final loss [0.13326406478881836] accuracy[83.07] precision[9.38] recall[11.11] specificity[89.86] F1 score[0.1]\n",
      "[524/5000] final loss [0.08358241617679596] accuracy[92.96] precision[0.0] recall[0] specificity[92.96] F1 score[0]\n",
      "[525/5000] final loss [0.12315399944782257] accuracy[94.2] precision[0.0] recall[0.0] specificity[95.05] F1 score[0]\n",
      "[526/5000] final loss [0.09464270621538162] accuracy[92.11] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[527/5000] final loss [0.04515441507101059] accuracy[93.67] precision[25.0] recall[33.33] specificity[96.05] F1 score[0.29]\n",
      "[528/5000] final loss [0.23202979564666748] accuracy[84.5] precision[22.22] recall[13.33] specificity[93.86] F1 score[0.17]\n",
      "[529/5000] final loss [0.12192663550376892] accuracy[87.18] precision[0.0] recall[0] specificity[87.18] F1 score[0]\n",
      "[530/5000] final loss [0.041788000613451004] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[531/5000] final loss [0.052531737834215164] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[532/5000] final loss [0.5290749073028564] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[533/5000] final loss [0.19047679007053375] accuracy[87.5] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[534/5000] final loss [0.1569378823041916] accuracy[83.33] precision[40.0] recall[22.22] specificity[94.12] F1 score[0.29]\n",
      "[535/5000] final loss [0.11503321677446365] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[536/5000] final loss [0.22462013363838196] accuracy[82.12] precision[5.56] recall[6.25] specificity[89.57] F1 score[0.06]\n",
      "[537/5000] final loss [0.3201114535331726] accuracy[96.61] precision[33.33] recall[100.0] specificity[96.55] F1 score[0.5]\n",
      "[538/5000] final loss [0.05542141944169998] accuracy[92.86] precision[50.0] recall[50.0] specificity[96.15] F1 score[0.5]\n",
      "[539/5000] final loss [0.1308404803276062] accuracy[80.85] precision[50.0] recall[11.11] specificity[97.37] F1 score[0.18]\n",
      "[540/5000] final loss [0.08827385306358337] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[541/5000] final loss [0.1644563525915146] accuracy[91.86] precision[75.0] recall[54.55] specificity[97.33] F1 score[0.63]\n",
      "[542/5000] final loss [0.1581910401582718] accuracy[93.59] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[543/5000] final loss [0.1318328082561493] accuracy[91.49] precision[50.0] recall[25.0] specificity[97.67] F1 score[0.33]\n",
      "[544/5000] final loss [0.021787075325846672] accuracy[92.73] precision[0.0] recall[0] specificity[92.73] F1 score[0]\n",
      "[545/5000] final loss [0.03806377202272415] accuracy[92.75] precision[25.0] recall[33.33] specificity[95.45] F1 score[0.29]\n",
      "[546/5000] final loss [0.1546350121498108] accuracy[87.38] precision[10.0] recall[20.0] specificity[90.82] F1 score[0.13]\n",
      "[547/5000] final loss [0.16604767739772797] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[548/5000] final loss [0.34386157989501953] accuracy[87.5] precision[0.0] recall[0.0] specificity[92.65] F1 score[0]\n",
      "[549/5000] final loss [0.09313344955444336] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[550/5000] final loss [0.12708590924739838] accuracy[92.11] precision[11.11] recall[12.5] specificity[95.6] F1 score[0.12]\n",
      "[551/5000] final loss [0.13114984333515167] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[552/5000] final loss [0.052732039242982864] accuracy[91.01] precision[15.38] recall[25.0] specificity[93.92] F1 score[0.19]\n",
      "[553/5000] final loss [0.1908520758152008] accuracy[93.43] precision[18.18] recall[33.33] specificity[95.31] F1 score[0.24]\n",
      "[554/5000] final loss [0.186522975564003] accuracy[88.37] precision[0.0] recall[0.0] specificity[92.68] F1 score[0]\n",
      "[555/5000] final loss [0.1621691882610321] accuracy[96.51] precision[0.0] recall[0] specificity[96.51] F1 score[0]\n",
      "[556/5000] final loss [0.15978002548217773] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[557/5000] final loss [0.17846465110778809] accuracy[96.08] precision[0.0] recall[0.0] specificity[98.0] F1 score[0]\n",
      "[558/5000] final loss [0.1375993937253952] accuracy[94.69] precision[0.0] recall[0.0] specificity[97.27] F1 score[0]\n",
      "[559/5000] final loss [0.09491310268640518] accuracy[92.5] precision[0.0] recall[0.0] specificity[93.67] F1 score[0]\n",
      "[560/5000] final loss [0.05152975767850876] accuracy[97.78] precision[0.0] recall[0.0] specificity[98.88] F1 score[0]\n",
      "[561/5000] final loss [0.21379375457763672] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[562/5000] final loss [0.0332653783261776] accuracy[95.08] precision[0.0] recall[0] specificity[95.08] F1 score[0]\n",
      "[563/5000] final loss [0.079338438808918] accuracy[90.91] precision[0.0] recall[0.0] specificity[93.46] F1 score[0]\n",
      "[564/5000] final loss [0.1616588532924652] accuracy[90.29] precision[16.67] recall[16.67] specificity[94.85] F1 score[0.17]\n",
      "[565/5000] final loss [0.11696046590805054] accuracy[92.0] precision[11.11] recall[11.11] specificity[95.81] F1 score[0.11]\n",
      "[566/5000] final loss [0.13136129081249237] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[567/5000] final loss [0.06848783791065216] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[568/5000] final loss [0.02250850759446621] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[569/5000] final loss [0.4339004158973694] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[570/5000] final loss [0.11780480295419693] accuracy[92.98] precision[0.0] recall[0] specificity[92.98] F1 score[0]\n",
      "[571/5000] final loss [0.08810917288064957] accuracy[90.0] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[572/5000] final loss [0.07886243611574173] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[573/5000] final loss [0.16116060316562653] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[574/5000] final loss [0.019942699000239372] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[575/5000] final loss [0.10845871269702911] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[576/5000] final loss [0.055113404989242554] accuracy[89.31] precision[0.0] recall[0.0] specificity[92.13] F1 score[0]\n",
      "[577/5000] final loss [0.25578776001930237] accuracy[89.96] precision[13.33] recall[13.33] specificity[94.67] F1 score[0.13]\n",
      "[578/5000] final loss [0.17518605291843414] accuracy[92.77] precision[20.0] recall[33.33] specificity[95.0] F1 score[0.25]\n",
      "[579/5000] final loss [0.07225489616394043] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[580/5000] final loss [0.08272241801023483] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[581/5000] final loss [0.08044945448637009] accuracy[90.15] precision[10.0] recall[20.0] specificity[92.91] F1 score[0.13]\n",
      "[582/5000] final loss [0.06324400007724762] accuracy[93.59] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[583/5000] final loss [0.16107948124408722] accuracy[92.59] precision[40.0] recall[28.57] specificity[97.03] F1 score[0.33]\n",
      "[584/5000] final loss [0.21602225303649902] accuracy[86.62] precision[31.25] recall[38.46] specificity[91.47] F1 score[0.34]\n",
      "[585/5000] final loss [0.1928386241197586] accuracy[94.32] precision[0.0] recall[0] specificity[94.32] F1 score[0]\n",
      "[586/5000] final loss [0.20215336978435516] accuracy[93.65] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[587/5000] final loss [0.21573327481746674] accuracy[90.24] precision[0.0] recall[0.0] specificity[92.5] F1 score[0]\n",
      "[588/5000] final loss [0.1320783495903015] accuracy[83.21] precision[32.0] recall[21.62] specificity[92.83] F1 score[0.26]\n",
      "[589/5000] final loss [0.1547466218471527] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[590/5000] final loss [0.020522749051451683] accuracy[85.71] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[591/5000] final loss [0.1821538358926773] accuracy[94.12] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[592/5000] final loss [0.24161817133426666] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[593/5000] final loss [0.1287231296300888] accuracy[75.76] precision[60.0] recall[17.65] specificity[95.92] F1 score[0.27]\n",
      "[594/5000] final loss [0.12183452397584915] accuracy[94.17] precision[0.0] recall[0.0] specificity[97.0] F1 score[0]\n",
      "[595/5000] final loss [0.010611345991492271] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[596/5000] final loss [0.09837642312049866] accuracy[95.87] precision[0.0] recall[0] specificity[95.87] F1 score[0]\n",
      "[597/5000] final loss [0.14674517512321472] accuracy[90.7] precision[0.0] recall[0.0] specificity[93.98] F1 score[0]\n",
      "[598/5000] final loss [0.1316947042942047] accuracy[93.52] precision[0.0] recall[0] specificity[93.52] F1 score[0]\n",
      "[599/5000] final loss [0.32327160239219666] accuracy[85.98] precision[14.29] recall[10.0] specificity[93.81] F1 score[0.12]\n",
      "[600/5000] final loss [0.24574795365333557] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[601/5000] final loss [0.1582181453704834] accuracy[85.71] precision[20.0] recall[20.0] specificity[92.16] F1 score[0.2]\n",
      "[602/5000] final loss [0.09378311038017273] accuracy[89.42] precision[4.55] recall[9.09] specificity[92.55] F1 score[0.06]\n",
      "[603/5000] final loss [0.09782744199037552] accuracy[94.19] precision[0.0] recall[0] specificity[94.19] F1 score[0]\n",
      "[604/5000] final loss [0.21010173857212067] accuracy[92.06] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[605/5000] final loss [0.00968961976468563] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[606/5000] final loss [0.1342366486787796] accuracy[89.58] precision[0.0] recall[0.0] specificity[91.49] F1 score[0]\n",
      "[607/5000] final loss [0.23542340099811554] accuracy[95.18] precision[0.0] recall[0] specificity[95.18] F1 score[0]\n",
      "[608/5000] final loss [0.020604059100151062] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[609/5000] final loss [0.04228084906935692] accuracy[93.02] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[610/5000] final loss [0.07282748818397522] accuracy[83.78] precision[0.0] recall[0.0] specificity[91.18] F1 score[0]\n",
      "[611/5000] final loss [0.09966512024402618] accuracy[91.92] precision[0.0] recall[0] specificity[91.92] F1 score[0]\n",
      "[612/5000] final loss [0.19179391860961914] accuracy[94.59] precision[0.0] recall[0.0] specificity[98.59] F1 score[0]\n",
      "[613/5000] final loss [0.10787967592477798] accuracy[89.87] precision[16.67] recall[25.0] specificity[93.33] F1 score[0.2]\n",
      "[614/5000] final loss [0.1415879875421524] accuracy[91.07] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[615/5000] final loss [0.02223939076066017] accuracy[80.0] precision[0.0] recall[0] specificity[80.0] F1 score[0]\n",
      "[616/5000] final loss [0.06676220148801804] accuracy[98.39] precision[0.0] recall[0] specificity[98.39] F1 score[0]\n",
      "[617/5000] final loss [0.18445047736167908] accuracy[91.18] precision[0.0] recall[0.0] specificity[92.26] F1 score[0]\n",
      "[618/5000] final loss [0.13226574659347534] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[619/5000] final loss [0.23531833291053772] accuracy[97.11] precision[0.0] recall[0] specificity[97.11] F1 score[0]\n",
      "[620/5000] final loss [0.040890950709581375] accuracy[92.37] precision[20.0] recall[14.29] specificity[96.77] F1 score[0.17]\n",
      "[621/5000] final loss [0.09558341652154922] accuracy[95.78] precision[0.0] recall[0] specificity[95.78] F1 score[0]\n",
      "[622/5000] final loss [0.4728066921234131] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[623/5000] final loss [0.029506085440516472] accuracy[96.04] precision[0.0] recall[0] specificity[96.04] F1 score[0]\n",
      "[624/5000] final loss [0.04414238780736923] accuracy[89.92] precision[0.0] recall[0.0] specificity[93.86] F1 score[0]\n",
      "[625/5000] final loss [0.23318152129650116] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[626/5000] final loss [0.08335717767477036] accuracy[85.12] precision[0.0] recall[0.0] specificity[94.5] F1 score[0]\n",
      "[627/5000] final loss [0.06558594852685928] accuracy[90.24] precision[0.0] recall[0] specificity[90.24] F1 score[0]\n",
      "[628/5000] final loss [0.2635461390018463] accuracy[92.96] precision[0.0] recall[0] specificity[92.96] F1 score[0]\n",
      "[629/5000] final loss [0.13109536468982697] accuracy[91.49] precision[0.0] recall[0.0] specificity[92.14] F1 score[0]\n",
      "[630/5000] final loss [0.112867571413517] accuracy[75.44] precision[50.0] recall[14.29] specificity[95.35] F1 score[0.22]\n",
      "[631/5000] final loss [0.02343502826988697] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[632/5000] final loss [0.09263159334659576] accuracy[90.45] precision[25.0] recall[7.69] specificity[97.92] F1 score[0.12]\n",
      "[633/5000] final loss [0.0730530396103859] accuracy[92.16] precision[0.0] recall[0.0] specificity[94.95] F1 score[0]\n",
      "[634/5000] final loss [0.1904350221157074] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[635/5000] final loss [0.14794938266277313] accuracy[90.35] precision[0.0] recall[0.0] specificity[92.79] F1 score[0]\n",
      "[636/5000] final loss [0.1361134797334671] accuracy[88.89] precision[12.5] recall[10.0] specificity[94.78] F1 score[0.11]\n",
      "[637/5000] final loss [0.04600280895829201] accuracy[98.55] precision[0.0] recall[0] specificity[98.55] F1 score[0]\n",
      "[638/5000] final loss [0.09217359125614166] accuracy[83.42] precision[23.53] recall[17.39] specificity[92.35] F1 score[0.2]\n",
      "[639/5000] final loss [0.09012560546398163] accuracy[90.53] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[640/5000] final loss [0.19832460582256317] accuracy[96.23] precision[0.0] recall[0] specificity[96.23] F1 score[0]\n",
      "[641/5000] final loss [0.03681982681155205] accuracy[89.36] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[642/5000] final loss [0.2704879343509674] accuracy[86.89] precision[20.0] recall[20.0] specificity[92.86] F1 score[0.2]\n",
      "[643/5000] final loss [0.04715235158801079] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[644/5000] final loss [0.12366928905248642] accuracy[90.91] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[645/5000] final loss [0.11432099342346191] accuracy[96.47] precision[0.0] recall[0] specificity[96.47] F1 score[0]\n",
      "[646/5000] final loss [0.2592706084251404] accuracy[88.73] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[647/5000] final loss [0.17072941362857819] accuracy[94.25] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[648/5000] final loss [0.10036300122737885] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[649/5000] final loss [0.03387663885951042] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[650/5000] final loss [0.029435157775878906] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[651/5000] final loss [0.10999555140733719] accuracy[85.94] precision[50.0] recall[22.22] specificity[96.36] F1 score[0.31]\n",
      "[652/5000] final loss [0.028036711737513542] accuracy[91.67] precision[100.0] recall[33.33] specificity[100.0] F1 score[0.5]\n",
      "[653/5000] final loss [0.39012283086776733] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[654/5000] final loss [0.21141046285629272] accuracy[95.14] precision[0.0] recall[0] specificity[95.14] F1 score[0]\n",
      "[655/5000] final loss [0.16140037775039673] accuracy[94.34] precision[0.0] recall[0] specificity[94.34] F1 score[0]\n",
      "[656/5000] final loss [0.15915898978710175] accuracy[92.31] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[657/5000] final loss [0.24113072454929352] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[658/5000] final loss [0.11062008887529373] accuracy[72.73] precision[12.5] recall[6.67] specificity[88.71] F1 score[0.09]\n",
      "[659/5000] final loss [0.1164449006319046] accuracy[87.02] precision[9.09] recall[12.5] specificity[91.87] F1 score[0.11]\n",
      "[660/5000] final loss [0.08492612093687057] accuracy[89.09] precision[33.33] recall[20.0] specificity[96.0] F1 score[0.25]\n",
      "[661/5000] final loss [0.19645048677921295] accuracy[90.38] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[662/5000] final loss [0.20186837017536163] accuracy[95.45] precision[25.0] recall[100.0] specificity[95.38] F1 score[0.4]\n",
      "[663/5000] final loss [0.10729371756315231] accuracy[87.13] precision[0.0] recall[0.0] specificity[94.62] F1 score[0]\n",
      "[664/5000] final loss [0.06420352309942245] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[665/5000] final loss [0.19526515901088715] accuracy[91.74] precision[0.0] recall[0.0] specificity[94.07] F1 score[0]\n",
      "[666/5000] final loss [0.1389026790857315] accuracy[92.31] precision[25.0] recall[20.0] specificity[96.51] F1 score[0.22]\n",
      "[667/5000] final loss [0.0943940132856369] accuracy[95.65] precision[0.0] recall[0.0] specificity[97.78] F1 score[0]\n",
      "[668/5000] final loss [0.027822118252515793] accuracy[95.89] precision[0.0] recall[0] specificity[95.89] F1 score[0]\n",
      "[669/5000] final loss [0.1449694186449051] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[670/5000] final loss [0.08608192950487137] accuracy[91.49] precision[33.33] recall[33.33] specificity[95.45] F1 score[0.33]\n",
      "[671/5000] final loss [0.08939732611179352] accuracy[90.68] precision[0.0] recall[0] specificity[90.68] F1 score[0]\n",
      "[672/5000] final loss [0.06712055951356888] accuracy[85.48] precision[0.0] recall[0.0] specificity[94.64] F1 score[0]\n",
      "[673/5000] final loss [0.07945052534341812] accuracy[85.8] precision[20.0] recall[11.11] specificity[94.7] F1 score[0.14]\n",
      "[674/5000] final loss [0.06944263726472855] accuracy[86.96] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[675/5000] final loss [0.0939256027340889] accuracy[94.2] precision[0.0] recall[0] specificity[94.2] F1 score[0]\n",
      "[676/5000] final loss [0.13742192089557648] accuracy[90.74] precision[0.0] recall[0.0] specificity[92.45] F1 score[0]\n",
      "[677/5000] final loss [0.2794729173183441] accuracy[88.89] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[678/5000] final loss [0.25832420587539673] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[679/5000] final loss [0.2790037989616394] accuracy[90.91] precision[0.0] recall[0.0] specificity[91.74] F1 score[0]\n",
      "[680/5000] final loss [0.11470229923725128] accuracy[87.01] precision[0.0] recall[0.0] specificity[93.06] F1 score[0]\n",
      "[681/5000] final loss [0.043850548565387726] accuracy[86.67] precision[33.33] recall[20.0] specificity[95.0] F1 score[0.25]\n",
      "[682/5000] final loss [0.12129871547222137] accuracy[88.0] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[683/5000] final loss [0.09977354109287262] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[684/5000] final loss [0.3225969970226288] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[685/5000] final loss [0.0489407442510128] accuracy[94.83] precision[50.0] recall[33.33] specificity[98.18] F1 score[0.4]\n",
      "[686/5000] final loss [0.17252689599990845] accuracy[92.93] precision[0.0] recall[0] specificity[92.93] F1 score[0]\n",
      "[687/5000] final loss [0.2139567732810974] accuracy[92.05] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[688/5000] final loss [0.08413325250148773] accuracy[95.68] precision[0.0] recall[0] specificity[95.68] F1 score[0]\n",
      "[689/5000] final loss [0.1847665160894394] accuracy[98.55] precision[0.0] recall[0] specificity[98.55] F1 score[0]\n",
      "[690/5000] final loss [0.13068319857120514] accuracy[88.59] precision[27.27] recall[25.0] specificity[94.16] F1 score[0.26]\n",
      "[691/5000] final loss [0.10612182319164276] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[692/5000] final loss [0.2206929475069046] accuracy[86.55] precision[14.29] recall[15.38] specificity[92.41] F1 score[0.15]\n",
      "[693/5000] final loss [0.021664071828126907] accuracy[85.71] precision[66.67] recall[25.0] specificity[97.56] F1 score[0.36]\n",
      "[694/5000] final loss [0.07654953747987747] accuracy[93.85] precision[0.0] recall[0] specificity[93.85] F1 score[0]\n",
      "[695/5000] final loss [0.12354092299938202] accuracy[85.71] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[696/5000] final loss [0.0688028410077095] accuracy[91.49] precision[0.0] recall[0] specificity[91.49] F1 score[0]\n",
      "[697/5000] final loss [0.06482057273387909] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[698/5000] final loss [0.10733099281787872] accuracy[89.81] precision[25.0] recall[16.67] specificity[95.86] F1 score[0.2]\n",
      "[699/5000] final loss [0.04442291706800461] accuracy[91.15] precision[0.0] recall[0.0] specificity[98.1] F1 score[0]\n",
      "[700/5000] final loss [0.1302233189344406] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[701/5000] final loss [0.2822105884552002] accuracy[90.7] precision[0.0] recall[0] specificity[90.7] F1 score[0]\n",
      "[702/5000] final loss [0.14820653200149536] accuracy[95.5] precision[0.0] recall[0] specificity[95.5] F1 score[0]\n",
      "[703/5000] final loss [0.015323519706726074] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[704/5000] final loss [0.04919721931219101] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[705/5000] final loss [0.2598534822463989] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[706/5000] final loss [0.0508124977350235] accuracy[87.23] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[707/5000] final loss [0.14332638680934906] accuracy[90.74] precision[28.57] recall[28.57] specificity[95.05] F1 score[0.29]\n",
      "[708/5000] final loss [0.11254532635211945] accuracy[89.26] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[709/5000] final loss [0.1840738207101822] accuracy[94.5] precision[0.0] recall[0] specificity[94.5] F1 score[0]\n",
      "[710/5000] final loss [0.33070114254951477] accuracy[91.87] precision[0.0] recall[0.0] specificity[93.39] F1 score[0]\n",
      "[711/5000] final loss [0.07057742029428482] accuracy[98.78] precision[0.0] recall[0] specificity[98.78] F1 score[0]\n",
      "[712/5000] final loss [0.021096279844641685] accuracy[96.59] precision[0.0] recall[0] specificity[96.59] F1 score[0]\n",
      "[713/5000] final loss [0.2224186807870865] accuracy[89.53] precision[28.57] recall[33.33] specificity[93.75] F1 score[0.31]\n",
      "[714/5000] final loss [0.020139673724770546] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[715/5000] final loss [0.12398919463157654] accuracy[96.55] precision[33.33] recall[100.0] specificity[96.49] F1 score[0.5]\n",
      "[716/5000] final loss [0.1226266622543335] accuracy[96.39] precision[0.0] recall[0] specificity[96.39] F1 score[0]\n",
      "[717/5000] final loss [0.22196051478385925] accuracy[90.15] precision[0.0] recall[0.0] specificity[90.84] F1 score[0]\n",
      "[718/5000] final loss [0.30055490136146545] accuracy[90.91] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[719/5000] final loss [0.04763651639223099] accuracy[86.24] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[720/5000] final loss [0.0850418210029602] accuracy[91.26] precision[0.0] recall[0.0] specificity[92.16] F1 score[0]\n",
      "[721/5000] final loss [0.19390834867954254] accuracy[80.88] precision[15.38] recall[6.67] specificity[93.68] F1 score[0.09]\n",
      "[722/5000] final loss [0.17774763703346252] accuracy[95.41] precision[0.0] recall[0] specificity[95.41] F1 score[0]\n",
      "[723/5000] final loss [0.10328341275453568] accuracy[87.77] precision[25.0] recall[15.38] specificity[95.24] F1 score[0.19]\n",
      "[724/5000] final loss [0.107365183532238] accuracy[87.5] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[725/5000] final loss [0.0018578902818262577] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[726/5000] final loss [0.16131439805030823] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[727/5000] final loss [0.06287799775600433] accuracy[92.31] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[728/5000] final loss [0.13190312683582306] accuracy[77.12] precision[28.57] recall[19.05] specificity[89.69] F1 score[0.23]\n",
      "[729/5000] final loss [0.035908304154872894] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[730/5000] final loss [0.08579044044017792] accuracy[87.04] precision[25.0] recall[20.0] specificity[93.88] F1 score[0.22]\n",
      "[731/5000] final loss [0.18072327971458435] accuracy[86.0] precision[0.0] recall[0.0] specificity[92.47] F1 score[0]\n",
      "[732/5000] final loss [0.2121073305606842] accuracy[84.16] precision[0.0] recall[0.0] specificity[93.41] F1 score[0]\n",
      "[733/5000] final loss [0.19198308885097504] accuracy[91.94] precision[0.0] recall[0.0] specificity[93.44] F1 score[0]\n",
      "[734/5000] final loss [0.03518815338611603] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[735/5000] final loss [0.025797618553042412] accuracy[87.18] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[736/5000] final loss [0.2645932137966156] accuracy[96.49] precision[0.0] recall[0] specificity[96.49] F1 score[0]\n",
      "[737/5000] final loss [0.19690831005573273] accuracy[90.57] precision[11.11] recall[33.33] specificity[92.23] F1 score[0.17]\n",
      "[738/5000] final loss [0.008740008808672428] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[739/5000] final loss [0.022340930998325348] accuracy[79.31] precision[50.0] recall[16.67] specificity[95.65] F1 score[0.25]\n",
      "[740/5000] final loss [0.17586557567119598] accuracy[96.36] precision[33.33] recall[100.0] specificity[96.3] F1 score[0.5]\n",
      "[741/5000] final loss [0.2926384508609772] accuracy[96.77] precision[50.0] recall[100.0] specificity[96.67] F1 score[0.67]\n",
      "[742/5000] final loss [0.11451251804828644] accuracy[80.0] precision[100.0] recall[20.0] specificity[100.0] F1 score[0.33]\n",
      "[743/5000] final loss [0.004275053273886442] accuracy[97.92] precision[0.0] recall[0] specificity[97.92] F1 score[0]\n",
      "[744/5000] final loss [0.06547582894563675] accuracy[71.43] precision[0.0] recall[0.0] specificity[85.37] F1 score[0]\n",
      "[745/5000] final loss [0.14366017282009125] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[746/5000] final loss [0.34148749709129333] accuracy[98.04] precision[50.0] recall[100.0] specificity[98.0] F1 score[0.67]\n",
      "[747/5000] final loss [0.0722905620932579] accuracy[89.47] precision[0.0] recall[0.0] specificity[96.23] F1 score[0]\n",
      "[748/5000] final loss [0.14470641314983368] accuracy[93.61] precision[0.0] recall[0] specificity[93.61] F1 score[0]\n",
      "[749/5000] final loss [0.11037053912878036] accuracy[93.94] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[750/5000] final loss [0.15559987723827362] accuracy[92.71] precision[0.0] recall[0.0] specificity[93.19] F1 score[0]\n",
      "[751/5000] final loss [0.09627902507781982] accuracy[85.15] precision[12.5] recall[11.11] specificity[92.39] F1 score[0.12]\n",
      "[752/5000] final loss [0.10475822538137436] accuracy[92.77] precision[0.0] recall[0] specificity[92.77] F1 score[0]\n",
      "[753/5000] final loss [0.4192293584346771] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[754/5000] final loss [0.14194601774215698] accuracy[91.43] precision[0.0] recall[0.0] specificity[96.97] F1 score[0]\n",
      "[755/5000] final loss [0.1938895583152771] accuracy[92.31] precision[25.0] recall[25.0] specificity[95.95] F1 score[0.25]\n",
      "[756/5000] final loss [0.09338217228651047] accuracy[71.88] precision[50.0] recall[16.67] specificity[93.48] F1 score[0.25]\n",
      "[757/5000] final loss [0.04772051051259041] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[758/5000] final loss [0.09029551595449448] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[759/5000] final loss [0.1250247061252594] accuracy[96.92] precision[0.0] recall[0] specificity[96.92] F1 score[0]\n",
      "[760/5000] final loss [0.038019414991140366] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[761/5000] final loss [0.030124347656965256] accuracy[92.45] precision[0.0] recall[0.0] specificity[96.08] F1 score[0]\n",
      "[762/5000] final loss [0.17979007959365845] accuracy[93.46] precision[0.0] recall[0] specificity[93.46] F1 score[0]\n",
      "[763/5000] final loss [0.13703128695487976] accuracy[93.45] precision[0.0] recall[0] specificity[93.45] F1 score[0]\n",
      "[764/5000] final loss [0.1354321390390396] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[765/5000] final loss [0.07737844437360764] accuracy[93.83] precision[0.0] recall[0.0] specificity[96.2] F1 score[0]\n",
      "[766/5000] final loss [0.17817771434783936] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[767/5000] final loss [0.06623361259698868] accuracy[93.85] precision[0.0] recall[0] specificity[93.85] F1 score[0]\n",
      "[768/5000] final loss [0.06230847164988518] accuracy[95.06] precision[0.0] recall[0] specificity[95.06] F1 score[0]\n",
      "[769/5000] final loss [0.07677550613880157] accuracy[97.83] precision[0.0] recall[0] specificity[97.83] F1 score[0]\n",
      "[770/5000] final loss [0.21274226903915405] accuracy[87.65] precision[10.0] recall[13.33] specificity[92.37] F1 score[0.11]\n",
      "[771/5000] final loss [0.21583157777786255] accuracy[93.97] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[772/5000] final loss [0.0410369373857975] accuracy[95.12] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[773/5000] final loss [0.06512300670146942] accuracy[96.43] precision[33.33] recall[50.0] specificity[97.56] F1 score[0.4]\n",
      "[774/5000] final loss [0.10285861790180206] accuracy[95.73] precision[0.0] recall[0] specificity[95.73] F1 score[0]\n",
      "[775/5000] final loss [0.14750976860523224] accuracy[89.47] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[776/5000] final loss [0.07768098264932632] accuracy[87.42] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[777/5000] final loss [0.03792297840118408] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[778/5000] final loss [0.19008147716522217] accuracy[92.11] precision[16.67] recall[50.0] specificity[93.24] F1 score[0.25]\n",
      "[779/5000] final loss [0.12694743275642395] accuracy[88.52] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[780/5000] final loss [0.1014738380908966] accuracy[89.42] precision[0.0] recall[0.0] specificity[92.08] F1 score[0]\n",
      "[781/5000] final loss [0.09343016892671585] accuracy[88.17] precision[0.0] recall[0.0] specificity[91.11] F1 score[0]\n",
      "[782/5000] final loss [0.21203604340553284] accuracy[91.11] precision[33.33] recall[33.33] specificity[95.24] F1 score[0.33]\n",
      "[783/5000] final loss [0.18269455432891846] accuracy[82.61] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[784/5000] final loss [0.15447890758514404] accuracy[94.3] precision[0.0] recall[0.0] specificity[96.85] F1 score[0]\n",
      "[785/5000] final loss [0.1292140632867813] accuracy[94.9] precision[0.0] recall[0] specificity[94.9] F1 score[0]\n",
      "[786/5000] final loss [0.17497920989990234] accuracy[88.06] precision[25.0] recall[16.67] specificity[95.08] F1 score[0.2]\n",
      "[787/5000] final loss [0.20780351758003235] accuracy[94.0] precision[33.33] recall[50.0] specificity[95.83] F1 score[0.4]\n",
      "[788/5000] final loss [0.2045227289199829] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[789/5000] final loss [0.11899305880069733] accuracy[92.5] precision[0.0] recall[0.0] specificity[93.67] F1 score[0]\n",
      "[790/5000] final loss [0.10848779231309891] accuracy[94.95] precision[0.0] recall[0] specificity[94.95] F1 score[0]\n",
      "[791/5000] final loss [0.06686385720968246] accuracy[91.76] precision[40.0] recall[33.33] specificity[96.2] F1 score[0.36]\n",
      "[792/5000] final loss [0.12859396636486053] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[793/5000] final loss [0.0649358406662941] accuracy[93.14] precision[0.0] recall[0] specificity[93.14] F1 score[0]\n",
      "[794/5000] final loss [0.05215683579444885] accuracy[94.12] precision[0.0] recall[0.0] specificity[97.96] F1 score[0]\n",
      "[795/5000] final loss [0.09111792594194412] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[796/5000] final loss [0.10769899189472198] accuracy[95.0] precision[33.33] recall[33.33] specificity[97.4] F1 score[0.33]\n",
      "[797/5000] final loss [0.24425141513347626] accuracy[86.34] precision[23.08] recall[14.29] specificity[94.57] F1 score[0.18]\n",
      "[798/5000] final loss [0.1592545062303543] accuracy[91.36] precision[0.0] recall[0.0] specificity[96.1] F1 score[0]\n",
      "[799/5000] final loss [0.011149984784424305] accuracy[89.47] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[800/5000] final loss [0.44345855712890625] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[801/5000] final loss [0.155930757522583] accuracy[91.94] precision[0.0] recall[0.0] specificity[94.48] F1 score[0]\n",
      "[802/5000] final loss [0.0865769013762474] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[803/5000] final loss [0.13981299102306366] accuracy[89.47] precision[0.0] recall[0] specificity[89.47] F1 score[0]\n",
      "[804/5000] final loss [0.3446040153503418] accuracy[81.63] precision[0.0] recall[0] specificity[81.63] F1 score[0]\n",
      "[805/5000] final loss [0.13249742984771729] accuracy[89.19] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[806/5000] final loss [0.1679144948720932] accuracy[78.4] precision[11.11] recall[9.09] specificity[88.94] F1 score[0.1]\n",
      "[807/5000] final loss [0.0451962985098362] accuracy[92.31] precision[40.0] recall[50.0] specificity[95.08] F1 score[0.44]\n",
      "[808/5000] final loss [0.05863032117486] accuracy[89.57] precision[0.0] recall[0.0] specificity[94.5] F1 score[0]\n",
      "[809/5000] final loss [0.36198973655700684] accuracy[96.13] precision[0.0] recall[0] specificity[96.13] F1 score[0]\n",
      "[810/5000] final loss [0.05288994684815407] accuracy[93.89] precision[0.0] recall[0] specificity[93.89] F1 score[0]\n",
      "[811/5000] final loss [0.13414797186851501] accuracy[88.6] precision[16.67] recall[15.79] specificity[94.07] F1 score[0.16]\n",
      "[812/5000] final loss [0.2072668969631195] accuracy[86.84] precision[0.0] recall[0.0] specificity[89.19] F1 score[0]\n",
      "[813/5000] final loss [0.15187852084636688] accuracy[76.47] precision[25.0] recall[16.67] specificity[89.29] F1 score[0.2]\n",
      "[814/5000] final loss [0.15130378305912018] accuracy[87.24] precision[13.33] recall[44.44] specificity[88.89] F1 score[0.21]\n",
      "[815/5000] final loss [0.010206222534179688] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[816/5000] final loss [0.07348117977380753] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[817/5000] final loss [0.16428834199905396] accuracy[87.88] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[818/5000] final loss [0.09560137987136841] accuracy[76.0] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[819/5000] final loss [0.1484854817390442] accuracy[94.67] precision[0.0] recall[0.0] specificity[95.95] F1 score[0]\n",
      "[820/5000] final loss [0.235660120844841] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.59] F1 score[0]\n",
      "[821/5000] final loss [0.15998297929763794] accuracy[91.67] precision[0.0] recall[0.0] specificity[92.63] F1 score[0]\n",
      "[822/5000] final loss [0.12567970156669617] accuracy[89.86] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[823/5000] final loss [0.07250598073005676] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[824/5000] final loss [0.09442921727895737] accuracy[95.31] precision[0.0] recall[0.0] specificity[96.83] F1 score[0]\n",
      "[825/5000] final loss [0.1775328814983368] accuracy[96.15] precision[0.0] recall[0.0] specificity[98.68] F1 score[0]\n",
      "[826/5000] final loss [0.061549779027700424] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[827/5000] final loss [0.09554560482501984] accuracy[80.6] precision[33.33] recall[18.18] specificity[92.86] F1 score[0.24]\n",
      "[828/5000] final loss [0.21836146712303162] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[829/5000] final loss [0.17143067717552185] accuracy[92.54] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[830/5000] final loss [0.0439753383398056] accuracy[98.04] precision[0.0] recall[0] specificity[98.04] F1 score[0]\n",
      "[831/5000] final loss [0.09704519063234329] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[832/5000] final loss [0.19798704981803894] accuracy[95.96] precision[0.0] recall[0.0] specificity[96.94] F1 score[0]\n",
      "[833/5000] final loss [0.05621933192014694] accuracy[91.67] precision[0.0] recall[0.0] specificity[97.06] F1 score[0]\n",
      "[834/5000] final loss [0.22644013166427612] accuracy[80.68] precision[14.29] recall[8.33] specificity[92.11] F1 score[0.11]\n",
      "[835/5000] final loss [0.07121488451957703] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[836/5000] final loss [0.1033664345741272] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[837/5000] final loss [0.03488999232649803] accuracy[95.45] precision[50.0] recall[100.0] specificity[95.24] F1 score[0.67]\n",
      "[838/5000] final loss [0.014663225039839745] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[839/5000] final loss [0.2288915067911148] accuracy[91.38] precision[0.0] recall[0.0] specificity[96.36] F1 score[0]\n",
      "[840/5000] final loss [0.05361909791827202] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[841/5000] final loss [0.21293625235557556] accuracy[89.38] precision[57.14] recall[30.77] specificity[97.0] F1 score[0.4]\n",
      "[842/5000] final loss [0.19107654690742493] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[843/5000] final loss [0.08704090863466263] accuracy[83.33] precision[33.33] recall[8.33] specificity[96.97] F1 score[0.13]\n",
      "[844/5000] final loss [0.2896420955657959] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[845/5000] final loss [0.1710832715034485] accuracy[91.3] precision[0.0] recall[0.0] specificity[92.82] F1 score[0]\n",
      "[846/5000] final loss [0.037640295922756195] accuracy[86.05] precision[0.0] recall[0.0] specificity[92.5] F1 score[0]\n",
      "[847/5000] final loss [0.16782520711421967] accuracy[87.3] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[848/5000] final loss [0.07831860333681107] accuracy[82.16] precision[11.11] recall[3.23] specificity[95.6] F1 score[0.05]\n",
      "[849/5000] final loss [0.09163472056388855] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[850/5000] final loss [0.15728674829006195] accuracy[93.1] precision[0.0] recall[0.0] specificity[94.19] F1 score[0]\n",
      "[851/5000] final loss [0.0018331058090552688] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[852/5000] final loss [0.042677778750658035] accuracy[75.0] precision[23.08] recall[13.04] specificity[89.69] F1 score[0.17]\n",
      "[853/5000] final loss [0.10847257822751999] accuracy[90.38] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[854/5000] final loss [0.04377325624227524] accuracy[92.77] precision[0.0] recall[0.0] specificity[95.06] F1 score[0]\n",
      "[855/5000] final loss [0.1968342512845993] accuracy[87.11] precision[22.73] recall[15.15] specificity[94.62] F1 score[0.18]\n",
      "[856/5000] final loss [0.12929494678974152] accuracy[90.57] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[857/5000] final loss [0.06647081673145294] accuracy[93.18] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[858/5000] final loss [0.17066590487957] accuracy[90.62] precision[16.67] recall[20.0] specificity[94.51] F1 score[0.18]\n",
      "[859/5000] final loss [0.08553782850503922] accuracy[83.08] precision[14.29] recall[16.67] specificity[89.83] F1 score[0.15]\n",
      "[860/5000] final loss [0.08136484771966934] accuracy[89.47] precision[0.0] recall[0.0] specificity[92.73] F1 score[0]\n",
      "[861/5000] final loss [0.15365417301654816] accuracy[84.04] precision[13.33] recall[8.7] specificity[93.16] F1 score[0.11]\n",
      "[862/5000] final loss [0.19509200751781464] accuracy[80.19] precision[26.67] recall[28.57] specificity[88.04] F1 score[0.28]\n",
      "[863/5000] final loss [0.11466092616319656] accuracy[93.94] precision[0.0] recall[0.0] specificity[95.38] F1 score[0]\n",
      "[864/5000] final loss [0.011357794515788555] accuracy[91.49] precision[33.33] recall[33.33] specificity[95.45] F1 score[0.33]\n",
      "[865/5000] final loss [0.04724687710404396] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[866/5000] final loss [0.1666232794523239] accuracy[82.78] precision[26.67] recall[16.67] specificity[92.95] F1 score[0.21]\n",
      "[867/5000] final loss [0.15608613193035126] accuracy[93.66] precision[20.0] recall[16.67] specificity[97.06] F1 score[0.18]\n",
      "[868/5000] final loss [0.1371971070766449] accuracy[87.5] precision[0.0] recall[0.0] specificity[90.32] F1 score[0]\n",
      "[869/5000] final loss [0.1120636984705925] accuracy[96.92] precision[0.0] recall[0] specificity[96.92] F1 score[0]\n",
      "[870/5000] final loss [0.039269424974918365] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[871/5000] final loss [0.19797053933143616] accuracy[84.21] precision[0.0] recall[0.0] specificity[91.43] F1 score[0]\n",
      "[872/5000] final loss [0.02528868429362774] accuracy[98.44] precision[0.0] recall[0] specificity[98.44] F1 score[0]\n",
      "[873/5000] final loss [0.15706999599933624] accuracy[85.0] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[874/5000] final loss [0.18759483098983765] accuracy[93.75] precision[75.0] recall[60.0] specificity[97.67] F1 score[0.67]\n",
      "[875/5000] final loss [0.15624891221523285] accuracy[80.43] precision[9.68] recall[6.38] specificity[91.28] F1 score[0.08]\n",
      "[876/5000] final loss [0.02962535247206688] accuracy[88.37] precision[0.0] recall[0.0] specificity[92.68] F1 score[0]\n",
      "[877/5000] final loss [0.06463958323001862] accuracy[90.62] precision[50.0] recall[33.33] specificity[96.55] F1 score[0.4]\n",
      "[878/5000] final loss [0.05947208032011986] accuracy[96.55] precision[25.0] recall[100.0] specificity[96.51] F1 score[0.4]\n",
      "[879/5000] final loss [0.1663970798254013] accuracy[90.24] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[880/5000] final loss [0.11186757683753967] accuracy[93.59] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[881/5000] final loss [0.05117384344339371] accuracy[94.2] precision[0.0] recall[0] specificity[94.2] F1 score[0]\n",
      "[882/5000] final loss [0.14858470857143402] accuracy[94.34] precision[0.0] recall[0] specificity[94.34] F1 score[0]\n",
      "[883/5000] final loss [0.08640389889478683] accuracy[94.34] precision[0.0] recall[0] specificity[94.34] F1 score[0]\n",
      "[884/5000] final loss [0.13034723699092865] accuracy[93.75] precision[28.57] recall[40.0] specificity[95.93] F1 score[0.33]\n",
      "[885/5000] final loss [0.03100713901221752] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[886/5000] final loss [0.17854833602905273] accuracy[94.05] precision[33.33] recall[66.67] specificity[95.06] F1 score[0.44]\n",
      "[887/5000] final loss [0.21444512903690338] accuracy[88.62] precision[15.38] recall[20.0] specificity[92.99] F1 score[0.17]\n",
      "[888/5000] final loss [0.150132954120636] accuracy[93.64] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[889/5000] final loss [0.16183637082576752] accuracy[92.59] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[890/5000] final loss [0.11623609811067581] accuracy[92.98] precision[0.0] recall[0.0] specificity[94.64] F1 score[0]\n",
      "[891/5000] final loss [0.27988913655281067] accuracy[75.0] precision[0.0] recall[0] specificity[75.0] F1 score[0]\n",
      "[892/5000] final loss [0.03611978143453598] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[893/5000] final loss [0.08528929948806763] accuracy[87.68] precision[16.67] recall[7.69] specificity[96.0] F1 score[0.11]\n",
      "[894/5000] final loss [0.1570357382297516] accuracy[91.74] precision[0.0] recall[0.0] specificity[95.28] F1 score[0]\n",
      "[895/5000] final loss [0.17897571623325348] accuracy[92.56] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[896/5000] final loss [0.05483918637037277] accuracy[94.17] precision[0.0] recall[0] specificity[94.17] F1 score[0]\n",
      "[897/5000] final loss [0.1344694048166275] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[898/5000] final loss [0.1267806440591812] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[899/5000] final loss [0.11220661550760269] accuracy[94.78] precision[0.0] recall[0.0] specificity[96.95] F1 score[0]\n",
      "[900/5000] final loss [0.26884162425994873] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[901/5000] final loss [0.18295621871948242] accuracy[90.48] precision[100.0] recall[33.33] specificity[100.0] F1 score[0.5]\n",
      "[902/5000] final loss [0.09101691842079163] accuracy[95.33] precision[0.0] recall[0] specificity[95.33] F1 score[0]\n",
      "[903/5000] final loss [0.06877556443214417] accuracy[94.83] precision[0.0] recall[0] specificity[94.83] F1 score[0]\n",
      "[904/5000] final loss [0.07232481986284256] accuracy[93.26] precision[0.0] recall[0] specificity[93.26] F1 score[0]\n",
      "[905/5000] final loss [0.1053304374217987] accuracy[94.66] precision[14.29] recall[50.0] specificity[95.35] F1 score[0.22]\n",
      "[906/5000] final loss [0.06270825862884521] accuracy[85.29] precision[0.0] recall[0.0] specificity[96.67] F1 score[0]\n",
      "[907/5000] final loss [0.25620678067207336] accuracy[93.68] precision[20.0] recall[33.33] specificity[95.65] F1 score[0.25]\n",
      "[908/5000] final loss [0.21268944442272186] accuracy[85.96] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[909/5000] final loss [0.11958377808332443] accuracy[92.68] precision[9.09] recall[11.11] specificity[95.78] F1 score[0.1]\n",
      "[910/5000] final loss [0.2239837795495987] accuracy[91.32] precision[0.0] recall[0.0] specificity[94.79] F1 score[0]\n",
      "[911/5000] final loss [0.04146766662597656] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[912/5000] final loss [0.2336948812007904] accuracy[92.41] precision[7.14] recall[10.0] specificity[95.36] F1 score[0.08]\n",
      "[913/5000] final loss [0.3851129412651062] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[914/5000] final loss [0.05025097355246544] accuracy[95.92] precision[0.0] recall[0] specificity[95.92] F1 score[0]\n",
      "[915/5000] final loss [0.16097630560398102] accuracy[91.18] precision[0.0] recall[0.0] specificity[92.54] F1 score[0]\n",
      "[916/5000] final loss [0.18236522376537323] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[917/5000] final loss [0.12146139144897461] accuracy[92.36] precision[0.0] recall[0.0] specificity[94.77] F1 score[0]\n",
      "[918/5000] final loss [0.24458622932434082] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[919/5000] final loss [0.09070921689271927] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[920/5000] final loss [0.2186536192893982] accuracy[85.29] precision[16.67] recall[28.57] specificity[89.47] F1 score[0.21]\n",
      "[921/5000] final loss [0.13584575057029724] accuracy[88.0] precision[33.33] recall[28.57] specificity[94.12] F1 score[0.31]\n",
      "[922/5000] final loss [0.072896808385849] accuracy[90.91] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[923/5000] final loss [0.16333265602588654] accuracy[90.62] precision[0.0] recall[0.0] specificity[92.06] F1 score[0]\n",
      "[924/5000] final loss [0.2212187945842743] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[925/5000] final loss [0.14658865332603455] accuracy[95.33] precision[16.67] recall[100.0] specificity[95.28] F1 score[0.29]\n",
      "[926/5000] final loss [0.05477016046643257] accuracy[92.86] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[927/5000] final loss [0.10946547985076904] accuracy[86.63] precision[25.0] recall[17.65] specificity[94.19] F1 score[0.21]\n",
      "[928/5000] final loss [0.017344046384096146] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[929/5000] final loss [0.08306494355201721] accuracy[87.92] precision[18.75] recall[13.64] specificity[94.65] F1 score[0.16]\n",
      "[930/5000] final loss [0.07264353334903717] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[931/5000] final loss [0.17806671559810638] accuracy[88.79] precision[9.09] recall[25.0] specificity[91.07] F1 score[0.13]\n",
      "[932/5000] final loss [0.13631156086921692] accuracy[91.8] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[933/5000] final loss [0.1420925408601761] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[934/5000] final loss [0.21361014246940613] accuracy[96.81] precision[0.0] recall[0] specificity[96.81] F1 score[0]\n",
      "[935/5000] final loss [0.4319412112236023] accuracy[88.46] precision[20.0] recall[11.11] specificity[95.79] F1 score[0.14]\n",
      "[936/5000] final loss [0.08597691357135773] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[937/5000] final loss [0.1687268614768982] accuracy[91.23] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[938/5000] final loss [0.048530302941799164] accuracy[84.62] precision[50.0] recall[25.0] specificity[95.45] F1 score[0.33]\n",
      "[939/5000] final loss [0.16029275953769684] accuracy[92.75] precision[0.0] recall[0.0] specificity[95.52] F1 score[0]\n",
      "[940/5000] final loss [0.19016237556934357] accuracy[92.73] precision[0.0] recall[0.0] specificity[93.58] F1 score[0]\n",
      "[941/5000] final loss [0.10580606758594513] accuracy[90.54] precision[0.0] recall[0] specificity[90.54] F1 score[0]\n",
      "[942/5000] final loss [0.06689926981925964] accuracy[90.7] precision[50.0] recall[25.0] specificity[97.44] F1 score[0.33]\n",
      "[943/5000] final loss [0.06797708570957184] accuracy[94.51] precision[16.67] recall[100.0] specificity[94.44] F1 score[0.29]\n",
      "[944/5000] final loss [0.0692916139960289] accuracy[90.0] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[945/5000] final loss [0.06073042377829552] accuracy[84.62] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[946/5000] final loss [0.1581648290157318] accuracy[80.98] precision[15.79] recall[13.64] specificity[90.12] F1 score[0.15]\n",
      "[947/5000] final loss [0.20525002479553223] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[948/5000] final loss [0.12784446775913239] accuracy[95.45] precision[33.33] recall[100.0] specificity[95.35] F1 score[0.5]\n",
      "[949/5000] final loss [0.15619699656963348] accuracy[90.0] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[950/5000] final loss [0.23385746777057648] accuracy[92.98] precision[0.0] recall[0] specificity[92.98] F1 score[0]\n",
      "[951/5000] final loss [0.0814966931939125] accuracy[80.0] precision[60.0] recall[20.0] specificity[96.36] F1 score[0.3]\n",
      "[952/5000] final loss [0.14800472557544708] accuracy[83.7] precision[29.41] recall[16.67] specificity[93.91] F1 score[0.21]\n",
      "[953/5000] final loss [0.1439911276102066] accuracy[94.2] precision[0.0] recall[0.0] specificity[95.59] F1 score[0]\n",
      "[954/5000] final loss [0.032673679292201996] accuracy[98.63] precision[50.0] recall[100.0] specificity[98.61] F1 score[0.67]\n",
      "[955/5000] final loss [0.2379877120256424] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[956/5000] final loss [0.17090144753456116] accuracy[90.72] precision[16.67] recall[20.0] specificity[94.57] F1 score[0.18]\n",
      "[957/5000] final loss [0.03986359015107155] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[958/5000] final loss [0.1938837170600891] accuracy[97.59] precision[0.0] recall[0] specificity[97.59] F1 score[0]\n",
      "[959/5000] final loss [0.061452046036720276] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[960/5000] final loss [0.19916898012161255] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[961/5000] final loss [0.2979038953781128] accuracy[83.33] precision[0.0] recall[0.0] specificity[92.11] F1 score[0]\n",
      "[962/5000] final loss [0.17530930042266846] accuracy[89.04] precision[0.0] recall[0.0] specificity[94.2] F1 score[0]\n",
      "[963/5000] final loss [0.1779146045446396] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[964/5000] final loss [0.16665659844875336] accuracy[90.7] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[965/5000] final loss [0.050306983292102814] accuracy[97.65] precision[33.33] recall[100.0] specificity[97.62] F1 score[0.5]\n",
      "[966/5000] final loss [0.05554519593715668] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[967/5000] final loss [0.09833552688360214] accuracy[91.67] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[968/5000] final loss [0.04147753864526749] accuracy[80.0] precision[0.0] recall[0] specificity[80.0] F1 score[0]\n",
      "[969/5000] final loss [0.07238439470529556] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[970/5000] final loss [0.06499427556991577] accuracy[81.82] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[971/5000] final loss [0.2050723284482956] accuracy[96.72] precision[33.33] recall[100.0] specificity[96.67] F1 score[0.5]\n",
      "[972/5000] final loss [0.07179248332977295] accuracy[94.39] precision[0.0] recall[0] specificity[94.39] F1 score[0]\n",
      "[973/5000] final loss [0.09873279929161072] accuracy[84.62] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[974/5000] final loss [0.0554957315325737] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[975/5000] final loss [0.08650427311658859] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[976/5000] final loss [0.09908101707696915] accuracy[93.85] precision[0.0] recall[0] specificity[93.85] F1 score[0]\n",
      "[977/5000] final loss [0.095670185983181] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[978/5000] final loss [0.03382371366024017] accuracy[96.49] precision[0.0] recall[0] specificity[96.49] F1 score[0]\n",
      "[979/5000] final loss [0.16036507487297058] accuracy[97.5] precision[0.0] recall[0] specificity[97.5] F1 score[0]\n",
      "[980/5000] final loss [0.16552095115184784] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[981/5000] final loss [0.2055932879447937] accuracy[87.63] precision[0.0] recall[0.0] specificity[90.06] F1 score[0]\n",
      "[982/5000] final loss [0.06458210945129395] accuracy[93.48] precision[0.0] recall[0.0] specificity[95.56] F1 score[0]\n",
      "[983/5000] final loss [0.13585010170936584] accuracy[95.24] precision[0.0] recall[0.0] specificity[97.09] F1 score[0]\n",
      "[984/5000] final loss [0.13310874998569489] accuracy[94.04] precision[0.0] recall[0.0] specificity[96.7] F1 score[0]\n",
      "[985/5000] final loss [0.21421054005622864] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[986/5000] final loss [0.1517764776945114] accuracy[89.95] precision[6.25] recall[14.29] specificity[92.57] F1 score[0.09]\n",
      "[987/5000] final loss [0.08446474373340607] accuracy[91.01] precision[8.33] recall[14.29] specificity[93.96] F1 score[0.11]\n",
      "[988/5000] final loss [0.20874261856079102] accuracy[92.35] precision[17.39] recall[40.0] specificity[94.01] F1 score[0.24]\n",
      "[989/5000] final loss [0.07019553333520889] accuracy[89.29] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[990/5000] final loss [0.09716220200061798] accuracy[90.42] precision[11.11] recall[18.18] specificity[93.6] F1 score[0.14]\n",
      "[991/5000] final loss [0.11927143484354019] accuracy[0.0] precision[0.0] recall[0] specificity[0.0] F1 score[0]\n",
      "[992/5000] final loss [0.20379090309143066] accuracy[93.88] precision[33.33] recall[50.0] specificity[95.74] F1 score[0.4]\n",
      "[993/5000] final loss [0.047903016209602356] accuracy[81.82] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[994/5000] final loss [0.18014077842235565] accuracy[90.44] precision[11.11] recall[16.67] specificity[93.85] F1 score[0.13]\n",
      "[995/5000] final loss [0.15515589714050293] accuracy[93.18] precision[0.0] recall[0.0] specificity[94.25] F1 score[0]\n",
      "[996/5000] final loss [0.16457399725914001] accuracy[89.19] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[997/5000] final loss [0.10392026603221893] accuracy[93.39] precision[25.0] recall[50.0] specificity[94.87] F1 score[0.33]\n",
      "[998/5000] final loss [0.26575157046318054] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.2] F1 score[0]\n",
      "[999/5000] final loss [0.07748781889677048] accuracy[65.71] precision[0.0] recall[0.0] specificity[88.46] F1 score[0]\n",
      "[1000/5000] final loss [0.13211236894130707] accuracy[91.28] precision[6.67] recall[16.67] specificity[93.4] F1 score[0.1]\n",
      "[1001/5000] final loss [0.4168876111507416] accuracy[94.12] precision[0.0] recall[0.0] specificity[95.05] F1 score[0]\n",
      "[1002/5000] final loss [0.15002796053886414] accuracy[90.41] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[1003/5000] final loss [0.08303412795066833] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.53] F1 score[0]\n",
      "[1004/5000] final loss [0.08653797954320908] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[1005/5000] final loss [0.19391568005084991] accuracy[88.17] precision[8.33] recall[100.0] specificity[88.04] F1 score[0.15]\n",
      "[1006/5000] final loss [0.07775041460990906] accuracy[92.54] precision[0.0] recall[0.0] specificity[95.38] F1 score[0]\n",
      "[1007/5000] final loss [0.14893582463264465] accuracy[93.44] precision[40.0] recall[66.67] specificity[94.83] F1 score[0.5]\n",
      "[1008/5000] final loss [0.07121032476425171] accuracy[90.91] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[1009/5000] final loss [0.2522558271884918] accuracy[87.34] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[1010/5000] final loss [0.2725645899772644] accuracy[91.67] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1011/5000] final loss [0.13200867176055908] accuracy[95.35] precision[50.0] recall[50.0] specificity[97.56] F1 score[0.5]\n",
      "[1012/5000] final loss [0.08820449560880661] accuracy[90.62] precision[0.0] recall[0] specificity[90.62] F1 score[0]\n",
      "[1013/5000] final loss [0.1739245355129242] accuracy[90.16] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[1014/5000] final loss [0.15907679498195648] accuracy[91.38] precision[0.0] recall[0.0] specificity[94.64] F1 score[0]\n",
      "[1015/5000] final loss [0.07263791561126709] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1016/5000] final loss [0.1433800309896469] accuracy[93.9] precision[20.0] recall[50.0] specificity[95.0] F1 score[0.29]\n",
      "[1017/5000] final loss [0.13854095339775085] accuracy[93.98] precision[0.0] recall[0] specificity[93.98] F1 score[0]\n",
      "[1018/5000] final loss [0.08693721890449524] accuracy[91.67] precision[33.33] recall[50.0] specificity[94.12] F1 score[0.4]\n",
      "[1019/5000] final loss [0.07506468892097473] accuracy[89.16] precision[4.55] recall[9.09] specificity[92.36] F1 score[0.06]\n",
      "[1020/5000] final loss [0.16757653653621674] accuracy[88.46] precision[12.5] recall[33.33] specificity[90.67] F1 score[0.18]\n",
      "[1021/5000] final loss [0.09037910401821136] accuracy[93.14] precision[0.0] recall[0.0] specificity[95.96] F1 score[0]\n",
      "[1022/5000] final loss [0.12897005677223206] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1023/5000] final loss [0.09918881207704544] accuracy[85.66] precision[30.0] recall[8.57] specificity[97.05] F1 score[0.13]\n",
      "[1024/5000] final loss [0.26686209440231323] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1025/5000] final loss [0.05680253729224205] accuracy[96.15] precision[20.0] recall[100.0] specificity[96.12] F1 score[0.33]\n",
      "[1026/5000] final loss [0.2250789850950241] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1027/5000] final loss [0.11853215098381042] accuracy[84.76] precision[0.0] recall[0.0] specificity[89.0] F1 score[0]\n",
      "[1028/5000] final loss [0.08468799293041229] accuracy[88.97] precision[10.0] recall[14.29] specificity[93.02] F1 score[0.12]\n",
      "[1029/5000] final loss [0.11750423163175583] accuracy[90.7] precision[33.33] recall[33.33] specificity[95.0] F1 score[0.33]\n",
      "[1030/5000] final loss [0.04273027181625366] accuracy[92.63] precision[0.0] recall[0.0] specificity[97.78] F1 score[0]\n",
      "[1031/5000] final loss [0.24001099169254303] accuracy[87.3] precision[42.86] recall[20.0] specificity[96.4] F1 score[0.27]\n",
      "[1032/5000] final loss [0.13659127056598663] accuracy[94.38] precision[11.11] recall[50.0] specificity[94.94] F1 score[0.18]\n",
      "[1033/5000] final loss [0.01957095041871071] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1034/5000] final loss [0.08478562533855438] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[1035/5000] final loss [0.18010661005973816] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[1036/5000] final loss [0.16085606813430786] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1037/5000] final loss [0.07354017347097397] accuracy[98.15] precision[0.0] recall[0] specificity[98.15] F1 score[0]\n",
      "[1038/5000] final loss [0.1332581788301468] accuracy[94.97] precision[0.0] recall[0.0] specificity[96.18] F1 score[0]\n",
      "[1039/5000] final loss [0.16232159733772278] accuracy[91.15] precision[37.5] recall[37.5] specificity[95.24] F1 score[0.38]\n",
      "[1040/5000] final loss [0.1299520879983902] accuracy[86.47] precision[50.0] recall[16.67] specificity[97.39] F1 score[0.25]\n",
      "[1041/5000] final loss [0.14052249491214752] accuracy[81.94] precision[25.0] recall[13.64] specificity[93.23] F1 score[0.18]\n",
      "[1042/5000] final loss [0.20849382877349854] accuracy[89.81] precision[0.0] recall[0.0] specificity[93.27] F1 score[0]\n",
      "[1043/5000] final loss [0.08819147199392319] accuracy[94.34] precision[0.0] recall[0] specificity[94.34] F1 score[0]\n",
      "[1044/5000] final loss [0.16176457703113556] accuracy[88.72] precision[20.0] recall[22.22] specificity[93.55] F1 score[0.21]\n",
      "[1045/5000] final loss [0.277220219373703] accuracy[93.15] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[1046/5000] final loss [0.18840354681015015] accuracy[93.75] precision[20.0] recall[33.33] specificity[95.7] F1 score[0.25]\n",
      "[1047/5000] final loss [0.16289469599723816] accuracy[93.75] precision[100.0] recall[66.67] specificity[100.0] F1 score[0.8]\n",
      "[1048/5000] final loss [0.015942320227622986] accuracy[95.65] precision[33.33] recall[50.0] specificity[97.01] F1 score[0.4]\n",
      "[1049/5000] final loss [0.13332125544548035] accuracy[83.71] precision[16.0] recall[9.76] specificity[93.33] F1 score[0.12]\n",
      "[1050/5000] final loss [0.059369031339883804] accuracy[92.25] precision[0.0] recall[0] specificity[92.25] F1 score[0]\n",
      "[1051/5000] final loss [0.06530987471342087] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1052/5000] final loss [0.35388442873954773] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1053/5000] final loss [0.10819446295499802] accuracy[87.32] precision[0.0] recall[0.0] specificity[88.57] F1 score[0]\n",
      "[1054/5000] final loss [0.11797242611646652] accuracy[93.06] precision[0.0] recall[0.0] specificity[94.37] F1 score[0]\n",
      "[1055/5000] final loss [0.06338511407375336] accuracy[93.79] precision[20.0] recall[16.67] specificity[97.12] F1 score[0.18]\n",
      "[1056/5000] final loss [0.1730145364999771] accuracy[90.91] precision[6.25] recall[16.67] specificity[92.99] F1 score[0.09]\n",
      "[1057/5000] final loss [0.10217191278934479] accuracy[93.51] precision[0.0] recall[0] specificity[93.51] F1 score[0]\n",
      "[1058/5000] final loss [0.12758521735668182] accuracy[88.36] precision[25.0] recall[18.75] specificity[94.8] F1 score[0.21]\n",
      "[1059/5000] final loss [0.11889023333787918] accuracy[93.68] precision[0.0] recall[0] specificity[93.68] F1 score[0]\n",
      "[1060/5000] final loss [0.17313791811466217] accuracy[88.99] precision[16.0] recall[19.05] specificity[93.52] F1 score[0.17]\n",
      "[1061/5000] final loss [0.2100020945072174] accuracy[91.3] precision[0.0] recall[0.0] specificity[94.03] F1 score[0]\n",
      "[1062/5000] final loss [0.31386810541152954] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[1063/5000] final loss [0.18859060108661652] accuracy[95.14] precision[12.5] recall[100.0] specificity[95.1] F1 score[0.22]\n",
      "[1064/5000] final loss [0.1678672879934311] accuracy[91.0] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1065/5000] final loss [0.029632041230797768] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1066/5000] final loss [0.18019811809062958] accuracy[92.17] precision[11.76] recall[40.0] specificity[93.33] F1 score[0.18]\n",
      "[1067/5000] final loss [0.14999306201934814] accuracy[92.99] precision[0.0] recall[0.0] specificity[96.05] F1 score[0]\n",
      "[1068/5000] final loss [0.10568029433488846] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1069/5000] final loss [0.2092740535736084] accuracy[77.64] precision[16.67] recall[12.5] specificity[89.05] F1 score[0.14]\n",
      "[1070/5000] final loss [0.2520636022090912] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[1071/5000] final loss [0.14677612483501434] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1072/5000] final loss [0.14170995354652405] accuracy[92.12] precision[38.46] recall[31.25] specificity[96.44] F1 score[0.34]\n",
      "[1073/5000] final loss [0.0846426859498024] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[1074/5000] final loss [0.03393618389964104] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1075/5000] final loss [0.20892910659313202] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[1076/5000] final loss [0.30896851420402527] accuracy[86.67] precision[66.67] recall[22.22] specificity[98.04] F1 score[0.33]\n",
      "[1077/5000] final loss [0.1233825534582138] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[1078/5000] final loss [0.13207171857357025] accuracy[88.24] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[1079/5000] final loss [0.04927719384431839] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[1080/5000] final loss [0.11965484917163849] accuracy[91.89] precision[0.0] recall[0] specificity[91.89] F1 score[0]\n",
      "[1081/5000] final loss [0.08744684606790543] accuracy[94.03] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[1082/5000] final loss [0.07364481687545776] accuracy[93.33] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[1083/5000] final loss [0.024530142545700073] accuracy[96.34] precision[0.0] recall[0] specificity[96.34] F1 score[0]\n",
      "[1084/5000] final loss [0.12151654064655304] accuracy[93.37] precision[0.0] recall[0.0] specificity[94.41] F1 score[0]\n",
      "[1085/5000] final loss [0.3210878372192383] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[1086/5000] final loss [0.20630858838558197] accuracy[81.9] precision[43.75] recall[36.84] specificity[90.72] F1 score[0.4]\n",
      "[1087/5000] final loss [0.15468822419643402] accuracy[85.11] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[1088/5000] final loss [0.03971239924430847] accuracy[96.77] precision[0.0] recall[0.0] specificity[98.36] F1 score[0]\n",
      "[1089/5000] final loss [0.1834174543619156] accuracy[95.45] precision[0.0] recall[0.0] specificity[96.33] F1 score[0]\n",
      "[1090/5000] final loss [0.10719698667526245] accuracy[88.03] precision[16.67] recall[10.0] specificity[95.33] F1 score[0.13]\n",
      "[1091/5000] final loss [0.023905538022518158] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[1092/5000] final loss [0.028387444093823433] accuracy[87.5] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[1093/5000] final loss [0.10007121413946152] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1094/5000] final loss [0.10885375738143921] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1095/5000] final loss [0.027509471401572227] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1096/5000] final loss [0.048500459641218185] accuracy[96.23] precision[0.0] recall[0] specificity[96.23] F1 score[0]\n",
      "[1097/5000] final loss [0.04781908541917801] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1098/5000] final loss [0.047155365347862244] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[1099/5000] final loss [0.19227246940135956] accuracy[82.61] precision[25.0] recall[10.0] specificity[94.92] F1 score[0.14]\n",
      "[1100/5000] final loss [0.2171328067779541] accuracy[92.16] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[1101/5000] final loss [0.1993638575077057] accuracy[83.78] precision[25.0] recall[10.0] specificity[95.31] F1 score[0.14]\n",
      "[1102/5000] final loss [0.13477873802185059] accuracy[92.59] precision[16.67] recall[50.0] specificity[93.67] F1 score[0.25]\n",
      "[1103/5000] final loss [0.13317817449569702] accuracy[87.76] precision[9.09] recall[11.76] specificity[92.57] F1 score[0.1]\n",
      "[1104/5000] final loss [0.15950310230255127] accuracy[95.0] precision[50.0] recall[50.0] specificity[97.37] F1 score[0.5]\n",
      "[1105/5000] final loss [0.015957234427332878] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[1106/5000] final loss [0.1122593805193901] accuracy[93.66] precision[0.0] recall[0] specificity[93.66] F1 score[0]\n",
      "[1107/5000] final loss [0.12272856384515762] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1108/5000] final loss [0.19898904860019684] accuracy[80.0] precision[0.0] recall[0] specificity[80.0] F1 score[0]\n",
      "[1109/5000] final loss [0.005656194407492876] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1110/5000] final loss [0.17731404304504395] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[1111/5000] final loss [0.08220324665307999] accuracy[96.36] precision[0.0] recall[0] specificity[96.36] F1 score[0]\n",
      "[1112/5000] final loss [0.10668604075908661] accuracy[92.42] precision[12.5] recall[25.0] specificity[94.53] F1 score[0.17]\n",
      "[1113/5000] final loss [0.20867159962654114] accuracy[92.99] precision[0.0] recall[0.0] specificity[95.42] F1 score[0]\n",
      "[1114/5000] final loss [0.05347074940800667] accuracy[96.4] precision[0.0] recall[0] specificity[96.4] F1 score[0]\n",
      "[1115/5000] final loss [0.13690340518951416] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1116/5000] final loss [0.12704814970493317] accuracy[88.29] precision[14.29] recall[12.5] specificity[94.17] F1 score[0.13]\n",
      "[1117/5000] final loss [0.16582785546779633] accuracy[91.86] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[1118/5000] final loss [0.08745779097080231] accuracy[91.81] precision[0.0] recall[0] specificity[91.81] F1 score[0]\n",
      "[1119/5000] final loss [0.18108750879764557] accuracy[80.0] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1120/5000] final loss [0.05127165839076042] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1121/5000] final loss [0.14682306349277496] accuracy[94.96] precision[8.33] recall[33.33] specificity[95.69] F1 score[0.13]\n",
      "[1122/5000] final loss [0.14519904553890228] accuracy[91.12] precision[7.14] recall[14.29] specificity[93.72] F1 score[0.1]\n",
      "[1123/5000] final loss [0.15502753853797913] accuracy[81.52] precision[75.0] recall[15.79] specificity[98.63] F1 score[0.26]\n",
      "[1124/5000] final loss [0.033264193683862686] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1125/5000] final loss [0.2178453654050827] accuracy[90.7] precision[16.67] recall[25.0] specificity[93.9] F1 score[0.2]\n",
      "[1126/5000] final loss [0.2513788044452667] accuracy[92.78] precision[18.18] recall[33.33] specificity[94.83] F1 score[0.24]\n",
      "[1127/5000] final loss [0.06997253000736237] accuracy[96.05] precision[0.0] recall[0.0] specificity[97.33] F1 score[0]\n",
      "[1128/5000] final loss [0.2682175636291504] accuracy[92.36] precision[0.0] recall[0] specificity[92.36] F1 score[0]\n",
      "[1129/5000] final loss [0.047803957015275955] accuracy[90.62] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[1130/5000] final loss [0.1920825093984604] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1131/5000] final loss [0.19343802332878113] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[1132/5000] final loss [0.07392914593219757] accuracy[90.0] precision[0.0] recall[0.0] specificity[97.3] F1 score[0]\n",
      "[1133/5000] final loss [0.2714647650718689] accuracy[93.97] precision[0.0] recall[0.0] specificity[95.61] F1 score[0]\n",
      "[1134/5000] final loss [0.13083599507808685] accuracy[92.98] precision[0.0] recall[0.0] specificity[94.64] F1 score[0]\n",
      "[1135/5000] final loss [0.0184868723154068] accuracy[91.49] precision[0.0] recall[0.0] specificity[97.73] F1 score[0]\n",
      "[1136/5000] final loss [0.375398188829422] accuracy[91.97] precision[14.29] recall[16.67] specificity[95.42] F1 score[0.15]\n",
      "[1137/5000] final loss [0.11800318211317062] accuracy[93.75] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[1138/5000] final loss [0.19935454428195953] accuracy[94.19] precision[0.0] recall[0] specificity[94.19] F1 score[0]\n",
      "[1139/5000] final loss [0.0666903480887413] accuracy[96.49] precision[0.0] recall[0] specificity[96.49] F1 score[0]\n",
      "[1140/5000] final loss [0.07595779746770859] accuracy[87.72] precision[13.33] recall[11.76] specificity[93.84] F1 score[0.12]\n",
      "[1141/5000] final loss [0.15631024539470673] accuracy[95.38] precision[0.0] recall[0] specificity[95.38] F1 score[0]\n",
      "[1142/5000] final loss [0.19371476769447327] accuracy[93.2] precision[0.0] recall[0.0] specificity[96.97] F1 score[0]\n",
      "[1143/5000] final loss [0.12854446470737457] accuracy[88.35] precision[15.79] recall[16.67] specificity[93.55] F1 score[0.16]\n",
      "[1144/5000] final loss [0.13398659229278564] accuracy[92.26] precision[0.0] recall[0.0] specificity[92.81] F1 score[0]\n",
      "[1145/5000] final loss [0.08763290196657181] accuracy[95.56] precision[33.33] recall[100.0] specificity[95.45] F1 score[0.5]\n",
      "[1146/5000] final loss [0.06244025379419327] accuracy[91.18] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[1147/5000] final loss [0.08622154593467712] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[1148/5000] final loss [0.27599087357521057] accuracy[92.68] precision[0.0] recall[0] specificity[92.68] F1 score[0]\n",
      "[1149/5000] final loss [0.24812854826450348] accuracy[86.79] precision[50.0] recall[42.86] specificity[93.48] F1 score[0.46]\n",
      "[1150/5000] final loss [0.026615634560585022] accuracy[95.65] precision[50.0] recall[50.0] specificity[97.73] F1 score[0.5]\n",
      "[1151/5000] final loss [0.07872296124696732] accuracy[90.7] precision[0.0] recall[0] specificity[90.7] F1 score[0]\n",
      "[[1152/10000]] loop skipped\n",
      "[1153/5001] final loss [0.07734841853380203] accuracy[69.23] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1154/5001] final loss [0.22287027537822723] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1155/5001] final loss [0.12543660402297974] accuracy[91.11] precision[0.0] recall[0.0] specificity[93.18] F1 score[0]\n",
      "[1156/5001] final loss [0.14483362436294556] accuracy[96.23] precision[25.0] recall[100.0] specificity[96.18] F1 score[0.4]\n",
      "[1157/5001] final loss [0.046401262283325195] accuracy[64.71] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[1158/5001] final loss [0.04804493859410286] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1159/5001] final loss [0.06503388285636902] accuracy[94.24] precision[0.0] recall[0] specificity[94.24] F1 score[0]\n",
      "[1160/5001] final loss [0.03791406750679016] accuracy[95.45] precision[50.0] recall[100.0] specificity[95.24] F1 score[0.67]\n",
      "[1161/5001] final loss [0.05011066049337387] accuracy[95.51] precision[0.0] recall[0] specificity[95.51] F1 score[0]\n",
      "[1162/5001] final loss [0.11754762381315231] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1163/5001] final loss [0.19785384833812714] accuracy[95.38] precision[0.0] recall[0] specificity[95.38] F1 score[0]\n",
      "[1164/5001] final loss [0.039785388857126236] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1165/5001] final loss [0.016808995977044106] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[1166/5001] final loss [0.09360058605670929] accuracy[95.24] precision[50.0] recall[66.67] specificity[96.67] F1 score[0.57]\n",
      "[1167/5001] final loss [0.0760844424366951] accuracy[89.89] precision[25.0] recall[14.29] specificity[96.34] F1 score[0.18]\n",
      "[1168/5001] final loss [0.057914361357688904] accuracy[84.07] precision[32.14] recall[18.75] specificity[93.99] F1 score[0.24]\n",
      "[1169/5001] final loss [0.08272366970777512] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1170/5001] final loss [0.15247254073619843] accuracy[91.43] precision[0.0] recall[0.0] specificity[92.75] F1 score[0]\n",
      "[1171/5001] final loss [0.03738335520029068] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[1172/5001] final loss [0.055704742670059204] accuracy[93.1] precision[0.0] recall[0.0] specificity[96.43] F1 score[0]\n",
      "[1173/5001] final loss [0.036530036479234695] accuracy[85.71] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[1174/5001] final loss [0.15334978699684143] accuracy[88.99] precision[0.0] recall[0.0] specificity[92.38] F1 score[0]\n",
      "[1175/5001] final loss [0.1744861602783203] accuracy[89.86] precision[0.0] recall[0.0] specificity[92.54] F1 score[0]\n",
      "[1176/5001] final loss [0.09033393859863281] accuracy[98.04] precision[0.0] recall[0] specificity[98.04] F1 score[0]\n",
      "[1177/5001] final loss [0.12856945395469666] accuracy[85.95] precision[20.0] recall[10.0] specificity[95.15] F1 score[0.13]\n",
      "[1178/5001] final loss [0.0871659517288208] accuracy[95.52] precision[0.0] recall[0] specificity[95.52] F1 score[0]\n",
      "[1179/5001] final loss [0.16782531142234802] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1180/5001] final loss [0.03219515085220337] accuracy[95.35] precision[0.0] recall[0.0] specificity[97.62] F1 score[0]\n",
      "[1181/5001] final loss [0.08228325098752975] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[1182/5001] final loss [0.05582461133599281] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1183/5001] final loss [0.15542785823345184] accuracy[89.32] precision[23.08] recall[20.0] specificity[94.76] F1 score[0.21]\n",
      "[1184/5001] final loss [0.07878798991441727] accuracy[89.36] precision[33.33] recall[25.0] specificity[95.35] F1 score[0.29]\n",
      "[1185/5001] final loss [0.14730629324913025] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[1186/5001] final loss [0.05510740727186203] accuracy[98.15] precision[0.0] recall[0] specificity[98.15] F1 score[0]\n",
      "[1187/5001] final loss [0.0134354829788208] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1188/5001] final loss [0.16487759351730347] accuracy[92.68] precision[12.5] recall[33.33] specificity[94.17] F1 score[0.18]\n",
      "[1189/5001] final loss [0.008515196852385998] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1190/5001] final loss [0.05790242180228233] accuracy[93.06] precision[0.0] recall[0.0] specificity[97.1] F1 score[0]\n",
      "[1191/5001] final loss [0.08492724597454071] accuracy[94.81] precision[50.0] recall[28.57] specificity[98.44] F1 score[0.36]\n",
      "[1192/5001] final loss [0.15607011318206787] accuracy[94.17] precision[0.0] recall[0] specificity[94.17] F1 score[0]\n",
      "[1193/5001] final loss [0.2398367077112198] accuracy[96.88] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1194/5001] final loss [0.05892760679125786] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1195/5001] final loss [0.22449547052383423] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[1196/5001] final loss [0.25620755553245544] accuracy[89.66] precision[12.5] recall[16.67] specificity[93.64] F1 score[0.14]\n",
      "[1197/5001] final loss [0.13386765122413635] accuracy[89.86] precision[33.33] recall[27.27] specificity[95.28] F1 score[0.3]\n",
      "[1198/5001] final loss [0.08604130148887634] accuracy[83.33] precision[66.67] recall[28.57] specificity[96.55] F1 score[0.4]\n",
      "[1199/5001] final loss [0.03759591653943062] accuracy[94.67] precision[0.0] recall[0.0] specificity[95.95] F1 score[0]\n",
      "[1200/5001] final loss [0.16010703146457672] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[1201/5001] final loss [0.27859944105148315] accuracy[72.0] precision[50.0] recall[14.29] specificity[94.44] F1 score[0.22]\n",
      "[1202/5001] final loss [0.0585135817527771] accuracy[92.92] precision[0.0] recall[0] specificity[92.92] F1 score[0]\n",
      "[1203/5001] final loss [0.09528601169586182] accuracy[92.06] precision[0.0] recall[0.0] specificity[94.05] F1 score[0]\n",
      "[1204/5001] final loss [0.056938156485557556] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1205/5001] final loss [0.0327652208507061] accuracy[94.38] precision[0.0] recall[0] specificity[94.38] F1 score[0]\n",
      "[1206/5001] final loss [0.13410131633281708] accuracy[85.28] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1207/5001] final loss [0.13609342277050018] accuracy[94.44] precision[0.0] recall[0.0] specificity[97.14] F1 score[0]\n",
      "[1208/5001] final loss [0.1596664935350418] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[1209/5001] final loss [0.022583510726690292] accuracy[96.61] precision[33.33] recall[100.0] specificity[96.55] F1 score[0.5]\n",
      "[1210/5001] final loss [0.3538894057273865] accuracy[91.18] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[1211/5001] final loss [0.12984293699264526] accuracy[89.89] precision[0.0] recall[0.0] specificity[93.02] F1 score[0]\n",
      "[1212/5001] final loss [0.1555386781692505] accuracy[94.5] precision[0.0] recall[0] specificity[94.5] F1 score[0]\n",
      "[1213/5001] final loss [0.26786211133003235] accuracy[97.67] precision[0.0] recall[0] specificity[97.67] F1 score[0]\n",
      "[1214/5001] final loss [0.2102971374988556] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[1215/5001] final loss [0.1514699012041092] accuracy[91.47] precision[0.0] recall[0.0] specificity[94.02] F1 score[0]\n",
      "[1216/5001] final loss [0.06988893449306488] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[1217/5001] final loss [0.04492638260126114] accuracy[94.63] precision[14.29] recall[16.67] specificity[96.98] F1 score[0.15]\n",
      "[1218/5001] final loss [0.21315781772136688] accuracy[78.53] precision[36.36] recall[10.53] specificity[95.42] F1 score[0.16]\n",
      "[1219/5001] final loss [0.11881046742200851] accuracy[92.56] precision[0.0] recall[0] specificity[92.56] F1 score[0]\n",
      "[1220/5001] final loss [0.04454553499817848] accuracy[82.61] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1221/5001] final loss [0.11852090805768967] accuracy[92.5] precision[0.0] recall[0] specificity[92.5] F1 score[0]\n",
      "[1222/5001] final loss [0.05363338440656662] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.59] F1 score[0]\n",
      "[1223/5001] final loss [0.24312534928321838] accuracy[76.56] precision[20.0] recall[8.33] specificity[92.31] F1 score[0.12]\n",
      "[1224/5001] final loss [0.056811459362506866] accuracy[85.79] precision[16.67] recall[33.33] specificity[89.19] F1 score[0.22]\n",
      "[1225/5001] final loss [0.08176283538341522] accuracy[95.93] precision[0.0] recall[0] specificity[95.93] F1 score[0]\n",
      "[1226/5001] final loss [0.23045659065246582] accuracy[92.45] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[1227/5001] final loss [0.050045520067214966] accuracy[94.24] precision[0.0] recall[0] specificity[94.24] F1 score[0]\n",
      "[1228/5001] final loss [0.04790225625038147] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[1229/5001] final loss [0.14143787324428558] accuracy[89.24] precision[0.0] recall[0.0] specificity[90.87] F1 score[0]\n",
      "[1230/5001] final loss [0.07942106574773788] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1231/5001] final loss [0.04984021931886673] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[1232/5001] final loss [0.11894777417182922] accuracy[79.17] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1233/5001] final loss [0.24917973577976227] accuracy[90.0] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[1234/5001] final loss [0.03804665803909302] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[1235/5001] final loss [0.29760119318962097] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[1236/5001] final loss [0.1584048569202423] accuracy[95.29] precision[8.33] recall[50.0] specificity[95.65] F1 score[0.14]\n",
      "[1237/5001] final loss [0.03178994730114937] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[1238/5001] final loss [0.09612222760915756] accuracy[92.57] precision[0.0] recall[0.0] specificity[93.84] F1 score[0]\n",
      "[1239/5001] final loss [0.108725905418396] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[1240/5001] final loss [0.12207553535699844] accuracy[91.75] precision[0.0] recall[0.0] specificity[92.71] F1 score[0]\n",
      "[1241/5001] final loss [0.24926157295703888] accuracy[98.36] precision[0.0] recall[0] specificity[98.36] F1 score[0]\n",
      "[1242/5001] final loss [0.07097792625427246] accuracy[88.37] precision[8.33] recall[20.0] specificity[91.13] F1 score[0.12]\n",
      "[1243/5001] final loss [0.20434024930000305] accuracy[93.04] precision[0.0] recall[0.0] specificity[94.69] F1 score[0]\n",
      "[1244/5001] final loss [0.09829428046941757] accuracy[92.35] precision[8.33] recall[25.0] specificity[93.85] F1 score[0.12]\n",
      "[1245/5001] final loss [0.11504311114549637] accuracy[89.36] precision[33.33] recall[25.0] specificity[95.35] F1 score[0.29]\n",
      "[1246/5001] final loss [0.16995906829833984] accuracy[94.17] precision[12.5] recall[14.29] specificity[96.76] F1 score[0.13]\n",
      "[1247/5001] final loss [0.2796211540699005] accuracy[94.64] precision[14.29] recall[100.0] specificity[94.59] F1 score[0.25]\n",
      "[1248/5001] final loss [0.08788568526506424] accuracy[82.42] precision[37.5] recall[21.43] specificity[93.51] F1 score[0.27]\n",
      "[1249/5001] final loss [0.14344410598278046] accuracy[87.75] precision[0.0] recall[0.0] specificity[92.89] F1 score[0]\n",
      "[1250/5001] final loss [0.054328400641679764] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1251/5001] final loss [0.12060759216547012] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1252/5001] final loss [0.07533132284879684] accuracy[90.91] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[1253/5001] final loss [0.13917674124240875] accuracy[87.59] precision[14.29] recall[28.57] specificity[90.77] F1 score[0.19]\n",
      "[1254/5001] final loss [0.06984319537878036] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[1255/5001] final loss [0.16009916365146637] accuracy[87.73] precision[0.0] recall[0.0] specificity[92.05] F1 score[0]\n",
      "[1256/5001] final loss [0.05693856254220009] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[1257/5001] final loss [0.17414428293704987] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.2] F1 score[0]\n",
      "[1258/5001] final loss [0.127296581864357] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1259/5001] final loss [0.12517012655735016] accuracy[94.27] precision[10.0] recall[100.0] specificity[94.23] F1 score[0.18]\n",
      "[1260/5001] final loss [0.03408511355519295] accuracy[85.25] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[1261/5001] final loss [0.039729777723550797] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1262/5001] final loss [0.10971181094646454] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1263/5001] final loss [0.08336055278778076] accuracy[92.19] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[1264/5001] final loss [0.3080686628818512] accuracy[75.0] precision[0.0] recall[0.0] specificity[91.3] F1 score[0]\n",
      "[1265/5001] final loss [0.00019083601364400238] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1266/5001] final loss [0.05063123628497124] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1267/5001] final loss [0.1882542371749878] accuracy[92.82] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1268/5001] final loss [0.023132331669330597] accuracy[89.36] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1269/5001] final loss [0.10739398747682571] accuracy[94.55] precision[0.0] recall[0] specificity[94.55] F1 score[0]\n",
      "[1270/5001] final loss [0.2380266785621643] accuracy[90.48] precision[0.0] recall[0] specificity[90.48] F1 score[0]\n",
      "[1271/5001] final loss [0.17072422802448273] accuracy[89.81] precision[10.71] recall[27.27] specificity[92.01] F1 score[0.15]\n",
      "[1272/5001] final loss [0.01013739500194788] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1273/5001] final loss [0.06484957784414291] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[1274/5001] final loss [0.3328576683998108] accuracy[95.95] precision[0.0] recall[0] specificity[95.95] F1 score[0]\n",
      "[1275/5001] final loss [0.018096139654517174] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1276/5001] final loss [0.029024146497249603] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1277/5001] final loss [0.14151844382286072] accuracy[92.42] precision[0.0] recall[0.0] specificity[93.85] F1 score[0]\n",
      "[1278/5001] final loss [0.02982921525835991] accuracy[96.43] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1279/5001] final loss [0.18315599858760834] accuracy[92.19] precision[14.29] recall[20.0] specificity[95.12] F1 score[0.17]\n",
      "[1280/5001] final loss [0.12538489699363708] accuracy[90.65] precision[14.29] recall[12.5] specificity[95.42] F1 score[0.13]\n",
      "[1281/5001] final loss [0.2518238127231598] accuracy[87.5] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1282/5001] final loss [0.16335779428482056] accuracy[93.9] precision[0.0] recall[0.0] specificity[97.47] F1 score[0]\n",
      "[1283/5001] final loss [0.1310834139585495] accuracy[86.28] precision[17.39] recall[13.33] specificity[93.62] F1 score[0.15]\n",
      "[1284/5001] final loss [0.05160776525735855] accuracy[85.71] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1285/5001] final loss [0.055133163928985596] accuracy[95.35] precision[0.0] recall[0.0] specificity[96.47] F1 score[0]\n",
      "[1286/5001] final loss [0.3206733167171478] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1287/5001] final loss [0.11858735978603363] accuracy[84.62] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[1288/5001] final loss [0.11685838550329208] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1289/5001] final loss [0.2646140456199646] accuracy[92.31] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1290/5001] final loss [0.02551090158522129] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1291/5001] final loss [0.14763496816158295] accuracy[89.66] precision[0.0] recall[0] specificity[89.66] F1 score[0]\n",
      "[1292/5001] final loss [0.11160657554864883] accuracy[97.1] precision[0.0] recall[0] specificity[97.1] F1 score[0]\n",
      "[1293/5001] final loss [0.14722628891468048] accuracy[91.5] precision[36.36] recall[40.0] specificity[95.1] F1 score[0.38]\n",
      "[1294/5001] final loss [0.15318737924098969] accuracy[82.75] precision[9.09] recall[7.69] specificity[91.27] F1 score[0.08]\n",
      "[1295/5001] final loss [0.1389704793691635] accuracy[87.3] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[1296/5001] final loss [0.03947190195322037] accuracy[86.67] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[1297/5001] final loss [0.1348601132631302] accuracy[87.71] precision[7.69] recall[9.09] specificity[92.86] F1 score[0.08]\n",
      "[1298/5001] final loss [0.08736848831176758] accuracy[94.57] precision[0.0] recall[0.0] specificity[96.67] F1 score[0]\n",
      "[1299/5001] final loss [0.08898697048425674] accuracy[92.98] precision[0.0] recall[0] specificity[92.98] F1 score[0]\n",
      "[1300/5001] final loss [0.14241653680801392] accuracy[86.99] precision[11.11] recall[11.11] specificity[92.98] F1 score[0.11]\n",
      "[1301/5001] final loss [0.1197669580578804] accuracy[91.43] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1302/5001] final loss [0.0541943795979023] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1303/5001] final loss [0.1485922783613205] accuracy[88.1] precision[14.29] recall[20.0] specificity[92.41] F1 score[0.17]\n",
      "[1304/5001] final loss [0.12735271453857422] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1305/5001] final loss [0.04835258051753044] accuracy[96.43] precision[0.0] recall[0.0] specificity[97.59] F1 score[0]\n",
      "[1306/5001] final loss [0.09573302417993546] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1307/5001] final loss [0.17867068946361542] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1308/5001] final loss [0.035702988505363464] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1309/5001] final loss [0.1378151923418045] accuracy[92.41] precision[0.0] recall[0] specificity[92.41] F1 score[0]\n",
      "[1310/5001] final loss [0.07837813347578049] accuracy[92.0] precision[0.0] recall[0.0] specificity[94.52] F1 score[0]\n",
      "[1311/5001] final loss [0.04328446835279465] accuracy[92.22] precision[0.0] recall[0.0] specificity[94.32] F1 score[0]\n",
      "[1312/5001] final loss [0.13564303517341614] accuracy[94.49] precision[0.0] recall[0] specificity[94.49] F1 score[0]\n",
      "[1313/5001] final loss [0.32759883999824524] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[1314/5001] final loss [0.15463455021381378] accuracy[95.7] precision[0.0] recall[0.0] specificity[96.74] F1 score[0]\n",
      "[1315/5001] final loss [0.11195789277553558] accuracy[92.55] precision[0.0] recall[0.0] specificity[93.71] F1 score[0]\n",
      "[1316/5001] final loss [0.09006381034851074] accuracy[91.3] precision[11.11] recall[33.33] specificity[92.86] F1 score[0.17]\n",
      "[1317/5001] final loss [0.06400047242641449] accuracy[92.25] precision[14.29] recall[16.67] specificity[95.59] F1 score[0.15]\n",
      "[1318/5001] final loss [0.040038514882326126] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1319/5001] final loss [0.055704426020383835] accuracy[85.71] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1320/5001] final loss [0.12033624947071075] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1321/5001] final loss [0.14273837208747864] accuracy[86.67] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[1322/5001] final loss [0.06807853281497955] accuracy[85.45] precision[16.67] recall[8.33] specificity[94.9] F1 score[0.11]\n",
      "[1323/5001] final loss [0.05186259001493454] accuracy[95.92] precision[0.0] recall[0] specificity[95.92] F1 score[0]\n",
      "[1324/5001] final loss [0.16629481315612793] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[1325/5001] final loss [0.33977800607681274] accuracy[89.47] precision[0.0] recall[0] specificity[89.47] F1 score[0]\n",
      "[1326/5001] final loss [0.12069489806890488] accuracy[93.75] precision[25.0] recall[25.0] specificity[96.74] F1 score[0.25]\n",
      "[1327/5001] final loss [0.20693421363830566] accuracy[88.54] precision[5.26] recall[20.0] specificity[90.37] F1 score[0.08]\n",
      "[1328/5001] final loss [0.1114465743303299] accuracy[91.3] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1329/5001] final loss [0.12216085195541382] accuracy[92.92] precision[0.0] recall[0.0] specificity[95.02] F1 score[0]\n",
      "[1330/5001] final loss [0.09399357438087463] accuracy[80.56] precision[16.67] recall[10.0] specificity[91.94] F1 score[0.13]\n",
      "[1331/5001] final loss [0.03534043952822685] accuracy[91.18] precision[0.0] recall[0] specificity[91.18] F1 score[0]\n",
      "[1332/5001] final loss [0.0362088680267334] accuracy[97.01] precision[0.0] recall[0] specificity[97.01] F1 score[0]\n",
      "[1333/5001] final loss [0.13163679838180542] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[1334/5001] final loss [0.21914324164390564] accuracy[93.15] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[1335/5001] final loss [0.10032980144023895] accuracy[89.01] precision[10.53] recall[33.33] specificity[90.81] F1 score[0.16]\n",
      "[1336/5001] final loss [0.12453193217515945] accuracy[78.86] precision[38.46] recall[21.74] specificity[92.0] F1 score[0.28]\n",
      "[1337/5001] final loss [0.1333984136581421] accuracy[90.62] precision[10.0] recall[100.0] specificity[90.53] F1 score[0.18]\n",
      "[1338/5001] final loss [0.21756680309772491] accuracy[86.61] precision[8.7] recall[15.38] specificity[90.71] F1 score[0.11]\n",
      "[1339/5001] final loss [0.19473151862621307] accuracy[89.51] precision[50.0] recall[26.67] specificity[96.88] F1 score[0.35]\n",
      "[1340/5001] final loss [0.08291992545127869] accuracy[88.0] precision[33.33] recall[12.5] specificity[97.01] F1 score[0.18]\n",
      "[1341/5001] final loss [0.23786501586437225] accuracy[87.55] precision[8.33] recall[16.67] specificity[91.02] F1 score[0.11]\n",
      "[1342/5001] final loss [0.11310624331235886] accuracy[92.31] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1343/5001] final loss [0.12715885043144226] accuracy[91.97] precision[0.0] recall[0.0] specificity[94.18] F1 score[0]\n",
      "[1344/5001] final loss [0.1874106377363205] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[1345/5001] final loss [0.2162337303161621] accuracy[88.46] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[1346/5001] final loss [0.11082685738801956] accuracy[91.6] precision[0.0] recall[0] specificity[91.6] F1 score[0]\n",
      "[1347/5001] final loss [0.16257581114768982] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1348/5001] final loss [0.13279931247234344] accuracy[90.77] precision[0.0] recall[0.0] specificity[91.47] F1 score[0]\n",
      "[1349/5001] final loss [0.16090111434459686] accuracy[92.76] precision[10.0] recall[33.33] specificity[93.96] F1 score[0.15]\n",
      "[1350/5001] final loss [0.08266118168830872] accuracy[88.41] precision[40.0] recall[28.57] specificity[95.16] F1 score[0.33]\n",
      "[1351/5001] final loss [0.05486784130334854] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1352/5001] final loss [0.18804852664470673] accuracy[93.47] precision[0.0] recall[0.0] specificity[94.42] F1 score[0]\n",
      "[1353/5001] final loss [0.09147316217422485] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[1354/5001] final loss [0.12088090181350708] accuracy[90.98] precision[0.0] recall[0.0] specificity[92.37] F1 score[0]\n",
      "[1355/5001] final loss [0.06594555824995041] accuracy[93.24] precision[0.0] recall[0.0] specificity[98.57] F1 score[0]\n",
      "[1356/5001] final loss [0.027372194454073906] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[1357/5001] final loss [0.04879341647028923] accuracy[90.62] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[1358/5001] final loss [0.0851379781961441] accuracy[92.7] precision[0.0] recall[0] specificity[92.7] F1 score[0]\n",
      "[1359/5001] final loss [0.09333480149507523] accuracy[94.25] precision[20.0] recall[50.0] specificity[95.29] F1 score[0.29]\n",
      "[1360/5001] final loss [0.07519038021564484] accuracy[95.89] precision[0.0] recall[0] specificity[95.89] F1 score[0]\n",
      "[1361/5001] final loss [0.1674952358007431] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[1362/5001] final loss [0.1393928825855255] accuracy[93.44] precision[14.29] recall[33.33] specificity[94.96] F1 score[0.2]\n",
      "[1363/5001] final loss [0.09142190963029861] accuracy[95.0] precision[0.0] recall[0.0] specificity[95.96] F1 score[0]\n",
      "[1364/5001] final loss [0.17599081993103027] accuracy[90.7] precision[7.14] recall[25.0] specificity[92.26] F1 score[0.11]\n",
      "[1365/5001] final loss [0.02327761985361576] accuracy[96.55] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1366/5001] final loss [0.1787356436252594] accuracy[93.67] precision[0.0] recall[0.0] specificity[98.67] F1 score[0]\n",
      "[1367/5001] final loss [0.11684811860322952] accuracy[92.59] precision[5.26] recall[20.0] specificity[93.84] F1 score[0.08]\n",
      "[1368/5001] final loss [0.08455938845872879] accuracy[94.92] precision[75.0] recall[60.0] specificity[98.15] F1 score[0.67]\n",
      "[1369/5001] final loss [0.08606312423944473] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1370/5001] final loss [0.08483840525150299] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1371/5001] final loss [0.017128698527812958] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1372/5001] final loss [0.08107016235589981] accuracy[94.0] precision[0.0] recall[0.0] specificity[95.92] F1 score[0]\n",
      "[1373/5001] final loss [0.1517142802476883] accuracy[90.51] precision[0.0] recall[0.0] specificity[93.23] F1 score[0]\n",
      "[1374/5001] final loss [0.1597614288330078] accuracy[92.57] precision[0.0] recall[0] specificity[92.57] F1 score[0]\n",
      "[1375/5001] final loss [0.16083620488643646] accuracy[84.1] precision[14.71] recall[14.29] specificity[91.37] F1 score[0.14]\n",
      "[1376/5001] final loss [0.08233845233917236] accuracy[92.86] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[1377/5001] final loss [0.1654127687215805] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[1378/5001] final loss [0.17132101953029633] accuracy[91.44] precision[0.0] recall[0.0] specificity[96.71] F1 score[0]\n",
      "[1379/5001] final loss [0.09896127879619598] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1380/5001] final loss [0.09501805156469345] accuracy[94.79] precision[20.0] recall[50.0] specificity[95.74] F1 score[0.29]\n",
      "[1381/5001] final loss [0.23272563517093658] accuracy[90.12] precision[0.0] recall[0.0] specificity[93.59] F1 score[0]\n",
      "[1382/5001] final loss [0.09736399352550507] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1383/5001] final loss [0.2470371127128601] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[1384/5001] final loss [0.1387399584054947] accuracy[88.36] precision[9.09] recall[10.53] specificity[93.31] F1 score[0.1]\n",
      "[1385/5001] final loss [0.008776861242949963] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1386/5001] final loss [0.18823780119419098] accuracy[89.0] precision[12.0] recall[23.08] specificity[92.09] F1 score[0.16]\n",
      "[1387/5001] final loss [0.055998802185058594] accuracy[93.75] precision[0.0] recall[0.0] specificity[97.83] F1 score[0]\n",
      "[1388/5001] final loss [0.14493303000926971] accuracy[89.13] precision[16.67] recall[16.67] specificity[94.19] F1 score[0.17]\n",
      "[1389/5001] final loss [0.1498914659023285] accuracy[94.0] precision[0.0] recall[0] specificity[94.0] F1 score[0]\n",
      "[1390/5001] final loss [0.11362163722515106] accuracy[94.67] precision[0.0] recall[0.0] specificity[95.95] F1 score[0]\n",
      "[1391/5001] final loss [0.01680588722229004] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1392/5001] final loss [0.16810716688632965] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[1393/5001] final loss [0.15452387928962708] accuracy[89.52] precision[33.33] recall[30.0] specificity[94.74] F1 score[0.32]\n",
      "[1394/5001] final loss [0.08921466767787933] accuracy[94.83] precision[0.0] recall[0] specificity[94.83] F1 score[0]\n",
      "[1395/5001] final loss [0.18555903434753418] accuracy[83.57] precision[9.32] recall[12.64] specificity[89.58] F1 score[0.11]\n",
      "[1396/5001] final loss [0.326948344707489] accuracy[90.74] precision[0.0] recall[0] specificity[90.74] F1 score[0]\n",
      "[1397/5001] final loss [0.08635490387678146] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[1398/5001] final loss [0.05502205714583397] accuracy[94.05] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[1399/5001] final loss [0.20130276679992676] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[1400/5001] final loss [0.22873646020889282] accuracy[92.36] precision[12.5] recall[16.67] specificity[95.36] F1 score[0.14]\n",
      "[1401/5001] final loss [0.2140725702047348] accuracy[87.5] precision[0.0] recall[0.0] specificity[91.3] F1 score[0]\n",
      "[1402/5001] final loss [0.1492786854505539] accuracy[89.19] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[1403/5001] final loss [0.0703902319073677] accuracy[92.5] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[1404/5001] final loss [0.11637504398822784] accuracy[90.32] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1405/5001] final loss [0.24581585824489594] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1406/5001] final loss [0.2656303346157074] accuracy[92.0] precision[9.09] recall[100.0] specificity[91.94] F1 score[0.17]\n",
      "[1407/5001] final loss [0.14305797219276428] accuracy[91.38] precision[10.0] recall[14.29] specificity[94.61] F1 score[0.12]\n",
      "[1408/5001] final loss [0.15546444058418274] accuracy[93.59] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[1409/5001] final loss [0.16132883727550507] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1410/5001] final loss [0.1839895248413086] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[1411/5001] final loss [0.10536037385463715] accuracy[96.3] precision[33.33] recall[100.0] specificity[96.23] F1 score[0.5]\n",
      "[1412/5001] final loss [0.07361064106225967] accuracy[98.0] precision[0.0] recall[0] specificity[98.0] F1 score[0]\n",
      "[1413/5001] final loss [0.08709105849266052] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1414/5001] final loss [0.13334083557128906] accuracy[87.76] precision[0.0] recall[0.0] specificity[91.49] F1 score[0]\n",
      "[1415/5001] final loss [0.02809080481529236] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1416/5001] final loss [0.06839647889137268] accuracy[90.91] precision[33.33] recall[50.0] specificity[93.55] F1 score[0.4]\n",
      "[1417/5001] final loss [0.028855659067630768] accuracy[98.77] precision[0.0] recall[0] specificity[98.77] F1 score[0]\n",
      "[1418/5001] final loss [0.19476792216300964] accuracy[87.76] precision[10.0] recall[10.0] specificity[93.43] F1 score[0.1]\n",
      "[1419/5001] final loss [0.045403026044368744] accuracy[79.0] precision[18.18] recall[5.71] specificity[94.55] F1 score[0.09]\n",
      "[1420/5001] final loss [0.0407940037548542] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1421/5001] final loss [0.18667961657047272] accuracy[91.28] precision[8.33] recall[33.33] specificity[92.47] F1 score[0.13]\n",
      "[1422/5001] final loss [0.1002870723605156] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1423/5001] final loss [0.04635787755250931] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1424/5001] final loss [0.1313960701227188] accuracy[89.29] precision[20.0] recall[16.67] specificity[94.87] F1 score[0.18]\n",
      "[1425/5001] final loss [0.17422232031822205] accuracy[88.46] precision[7.41] recall[28.57] specificity[90.12] F1 score[0.12]\n",
      "[1426/5001] final loss [0.24215403199195862] accuracy[90.75] precision[10.0] recall[12.5] specificity[94.55] F1 score[0.11]\n",
      "[1427/5001] final loss [0.14323818683624268] accuracy[89.23] precision[0.0] recall[0.0] specificity[92.06] F1 score[0]\n",
      "[1428/5001] final loss [0.20222271978855133] accuracy[89.45] precision[16.67] recall[15.38] specificity[94.62] F1 score[0.16]\n",
      "[1429/5001] final loss [0.10831991583108902] accuracy[87.1] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[1430/5001] final loss [0.0763654038310051] accuracy[92.12] precision[7.69] recall[20.0] specificity[93.94] F1 score[0.11]\n",
      "[1431/5001] final loss [0.27730801701545715] accuracy[93.27] precision[0.0] recall[0.0] specificity[94.17] F1 score[0]\n",
      "[1432/5001] final loss [0.15233023464679718] accuracy[96.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1433/5001] final loss [0.07395842671394348] accuracy[92.96] precision[11.11] recall[33.33] specificity[94.24] F1 score[0.17]\n",
      "[1434/5001] final loss [0.06060786545276642] accuracy[90.48] precision[0.0] recall[0] specificity[90.48] F1 score[0]\n",
      "[1435/5001] final loss [0.227163627743721] accuracy[92.59] precision[20.0] recall[100.0] specificity[92.45] F1 score[0.33]\n",
      "[1436/5001] final loss [0.14738811552524567] accuracy[92.67] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[1437/5001] final loss [0.3180834650993347] accuracy[98.21] precision[0.0] recall[0] specificity[98.21] F1 score[0]\n",
      "[1438/5001] final loss [0.08219413459300995] accuracy[90.48] precision[25.0] recall[11.11] specificity[97.18] F1 score[0.15]\n",
      "[1439/5001] final loss [0.0637902170419693] accuracy[88.66] precision[14.29] recall[16.67] specificity[93.41] F1 score[0.15]\n",
      "[1440/5001] final loss [0.06679369509220123] accuracy[84.74] precision[46.15] recall[21.43] specificity[95.68] F1 score[0.29]\n",
      "[1441/5001] final loss [0.22037693858146667] accuracy[95.34] precision[0.0] recall[0] specificity[95.34] F1 score[0]\n",
      "[1442/5001] final loss [0.05678720772266388] accuracy[80.95] precision[0.0] recall[0.0] specificity[89.47] F1 score[0]\n",
      "[1443/5001] final loss [0.12157323211431503] accuracy[91.47] precision[9.09] recall[11.11] specificity[95.05] F1 score[0.1]\n",
      "[1444/5001] final loss [0.18468622863292694] accuracy[91.11] precision[7.14] recall[12.5] specificity[94.01] F1 score[0.09]\n",
      "[1445/5001] final loss [0.3056296408176422] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1446/5001] final loss [0.06337245553731918] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1447/5001] final loss [0.1426769644021988] accuracy[90.1] precision[0.0] recall[0.0] specificity[91.92] F1 score[0]\n",
      "[1448/5001] final loss [0.06062016263604164] accuracy[92.45] precision[0.0] recall[0] specificity[92.45] F1 score[0]\n",
      "[1449/5001] final loss [0.09848514199256897] accuracy[84.68] precision[0.0] recall[0.0] specificity[92.16] F1 score[0]\n",
      "[1450/5001] final loss [0.11177379637956619] accuracy[95.08] precision[0.0] recall[0] specificity[95.08] F1 score[0]\n",
      "[1451/5001] final loss [0.16855253279209137] accuracy[79.52] precision[9.52] recall[7.69] specificity[89.67] F1 score[0.09]\n",
      "[1452/5001] final loss [0.14275075495243073] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1453/5001] final loss [0.15260709822177887] accuracy[93.98] precision[9.09] recall[25.0] specificity[95.28] F1 score[0.13]\n",
      "[1454/5001] final loss [0.10587459057569504] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[1455/5001] final loss [0.035131435841321945] accuracy[80.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1456/5001] final loss [0.09594399482011795] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1457/5001] final loss [0.04193008691072464] accuracy[96.08] precision[0.0] recall[0.0] specificity[98.0] F1 score[0]\n",
      "[1458/5001] final loss [0.21364779770374298] accuracy[89.1] precision[0.0] recall[0.0] specificity[92.67] F1 score[0]\n",
      "[1459/5001] final loss [0.1517261266708374] accuracy[85.71] precision[9.09] recall[4.76] specificity[94.71] F1 score[0.06]\n",
      "[1460/5001] final loss [0.061087992042303085] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1461/5001] final loss [0.11887598037719727] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[1462/5001] final loss [0.15107402205467224] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[1463/5001] final loss [0.05840929597616196] accuracy[92.75] precision[0.0] recall[0] specificity[92.75] F1 score[0]\n",
      "[1464/5001] final loss [0.16373160481452942] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[1465/5001] final loss [0.026827558875083923] accuracy[98.04] precision[0.0] recall[0] specificity[98.04] F1 score[0]\n",
      "[1466/5001] final loss [0.04174640402197838] accuracy[90.0] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[1467/5001] final loss [0.05721638724207878] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[1468/5001] final loss [0.07724935561418533] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1469/5001] final loss [0.3330467641353607] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1470/5001] final loss [0.12886874377727509] accuracy[83.65] precision[11.11] recall[10.0] specificity[91.49] F1 score[0.11]\n",
      "[1471/5001] final loss [0.032402828335762024] accuracy[88.89] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1472/5001] final loss [0.1964237540960312] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[1473/5001] final loss [0.2629028558731079] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1474/5001] final loss [0.10403372347354889] accuracy[85.53] precision[0.0] recall[0.0] specificity[95.59] F1 score[0]\n",
      "[1475/5001] final loss [0.0013576155761256814] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1476/5001] final loss [0.08073989301919937] accuracy[94.57] precision[0.0] recall[0] specificity[94.57] F1 score[0]\n",
      "[1477/5001] final loss [0.19153214991092682] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1478/5001] final loss [0.02678189054131508] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1479/5001] final loss [0.1485527753829956] accuracy[90.57] precision[0.0] recall[0] specificity[90.57] F1 score[0]\n",
      "[1480/5001] final loss [0.12462354451417923] accuracy[95.73] precision[0.0] recall[0] specificity[95.73] F1 score[0]\n",
      "[1481/5001] final loss [0.14925076067447662] accuracy[83.33] precision[50.0] recall[25.0] specificity[95.0] F1 score[0.33]\n",
      "[1482/5001] final loss [0.09968499094247818] accuracy[85.82] precision[18.18] recall[16.67] specificity[92.62] F1 score[0.17]\n",
      "[1483/5001] final loss [0.2877933979034424] accuracy[90.57] precision[0.0] recall[0] specificity[90.57] F1 score[0]\n",
      "[1484/5001] final loss [0.05876322463154793] accuracy[94.52] precision[0.0] recall[0.0] specificity[95.17] F1 score[0]\n",
      "[1485/5001] final loss [0.10827498137950897] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1486/5001] final loss [0.1704491376876831] accuracy[92.13] precision[22.22] recall[40.0] specificity[94.26] F1 score[0.29]\n",
      "[1487/5001] final loss [0.1702101081609726] accuracy[93.85] precision[0.0] recall[0] specificity[93.85] F1 score[0]\n",
      "[1488/5001] final loss [0.08248642086982727] accuracy[75.0] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[1489/5001] final loss [0.15348629653453827] accuracy[95.33] precision[12.5] recall[100.0] specificity[95.3] F1 score[0.22]\n",
      "[1490/5001] final loss [0.18905143439769745] accuracy[82.89] precision[16.67] recall[11.11] specificity[92.54] F1 score[0.13]\n",
      "[1491/5001] final loss [0.061126891523599625] accuracy[96.32] precision[0.0] recall[0.0] specificity[97.04] F1 score[0]\n",
      "[1492/5001] final loss [0.04937988519668579] accuracy[85.0] precision[0.0] recall[0.0] specificity[89.47] F1 score[0]\n",
      "[1493/5001] final loss [0.08878524601459503] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[1494/5001] final loss [0.16743962466716766] accuracy[86.54] precision[0.0] recall[0.0] specificity[97.83] F1 score[0]\n",
      "[1495/5001] final loss [0.05151059478521347] accuracy[81.82] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[1496/5001] final loss [0.15566307306289673] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[1497/5001] final loss [0.073369100689888] accuracy[95.92] precision[33.33] recall[100.0] specificity[95.83] F1 score[0.5]\n",
      "[1498/5001] final loss [0.18944425880908966] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1499/5001] final loss [0.14102213084697723] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[1500/5001] final loss [0.1547950804233551] accuracy[84.88] precision[6.67] recall[7.69] specificity[91.19] F1 score[0.07]\n",
      "[1501/5001] final loss [0.016947198659181595] accuracy[94.23] precision[0.0] recall[0] specificity[94.23] F1 score[0]\n",
      "[1502/5001] final loss [0.33734992146492004] accuracy[92.98] precision[100.0] recall[20.0] specificity[100.0] F1 score[0.33]\n",
      "[1503/5001] final loss [0.2771545648574829] accuracy[92.86] precision[14.29] recall[25.0] specificity[95.08] F1 score[0.18]\n",
      "[1504/5001] final loss [0.04954386129975319] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[1505/5001] final loss [0.10649392008781433] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1506/5001] final loss [0.08915384858846664] accuracy[89.87] precision[0.0] recall[0.0] specificity[95.95] F1 score[0]\n",
      "[1507/5001] final loss [0.18261829018592834] accuracy[93.02] precision[0.0] recall[0.0] specificity[97.56] F1 score[0]\n",
      "[1508/5001] final loss [0.1334908902645111] accuracy[97.37] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[1509/5001] final loss [0.2136867791414261] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1510/5001] final loss [0.10090857744216919] accuracy[89.13] precision[0.0] recall[0.0] specificity[97.62] F1 score[0]\n",
      "[1511/5001] final loss [0.13094928860664368] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[1512/5001] final loss [0.12136373668909073] accuracy[94.2] precision[7.14] recall[100.0] specificity[94.17] F1 score[0.13]\n",
      "[1513/5001] final loss [0.1700284779071808] accuracy[84.27] precision[10.0] recall[5.0] specificity[94.3] F1 score[0.07]\n",
      "[1514/5001] final loss [0.26186734437942505] accuracy[92.68] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1515/5001] final loss [0.14350557327270508] accuracy[82.13] precision[10.87] recall[13.89] specificity[88.83] F1 score[0.12]\n",
      "[1516/5001] final loss [0.00012361178232822567] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1517/5001] final loss [0.11298821866512299] accuracy[96.92] precision[0.0] recall[0] specificity[96.92] F1 score[0]\n",
      "[1518/5001] final loss [0.0379914790391922] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1519/5001] final loss [0.07509150356054306] accuracy[90.62] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[1520/5001] final loss [0.21807952225208282] accuracy[93.94] precision[18.18] recall[66.67] specificity[94.44] F1 score[0.29]\n",
      "[1521/5001] final loss [0.22032025456428528] accuracy[88.89] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1522/5001] final loss [0.1575619876384735] accuracy[90.16] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[1523/5001] final loss [0.07966407388448715] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1524/5001] final loss [0.14604027569293976] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1525/5001] final loss [0.056667476892471313] accuracy[92.13] precision[0.0] recall[0.0] specificity[94.25] F1 score[0]\n",
      "[1526/5001] final loss [0.19023829698562622] accuracy[88.89] precision[0.0] recall[0.0] specificity[91.43] F1 score[0]\n",
      "[1527/5001] final loss [0.13799290359020233] accuracy[95.06] precision[0.0] recall[0] specificity[95.06] F1 score[0]\n",
      "[1528/5001] final loss [0.21475787460803986] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[1529/5001] final loss [0.09697824716567993] accuracy[90.43] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[1530/5001] final loss [0.0805526152253151] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[1531/5001] final loss [0.19708774983882904] accuracy[86.67] precision[37.5] recall[37.5] specificity[92.54] F1 score[0.38]\n",
      "[1532/5001] final loss [0.0736352875828743] accuracy[94.16] precision[12.5] recall[50.0] specificity[94.81] F1 score[0.2]\n",
      "[1533/5001] final loss [0.15892218053340912] accuracy[90.0] precision[40.0] recall[50.0] specificity[93.48] F1 score[0.44]\n",
      "[1534/5001] final loss [0.15984702110290527] accuracy[94.0] precision[16.67] recall[50.0] specificity[94.9] F1 score[0.25]\n",
      "[1535/5001] final loss [0.03852519392967224] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1536/5001] final loss [0.016524923965334892] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1537/5001] final loss [0.05387522652745247] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[1538/5001] final loss [0.14158965647220612] accuracy[91.41] precision[16.67] recall[14.29] specificity[95.87] F1 score[0.15]\n",
      "[1539/5001] final loss [0.09750965982675552] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[1540/5001] final loss [0.047738585621118546] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[1541/5001] final loss [0.30345267057418823] accuracy[92.98] precision[0.0] recall[0] specificity[92.98] F1 score[0]\n",
      "[1542/5001] final loss [0.1567062884569168] accuracy[86.13] precision[30.0] recall[20.0] specificity[94.26] F1 score[0.24]\n",
      "[1543/5001] final loss [0.17721882462501526] accuracy[97.73] precision[0.0] recall[0] specificity[97.73] F1 score[0]\n",
      "[1544/5001] final loss [0.09083285927772522] accuracy[96.0] precision[50.0] recall[100.0] specificity[95.83] F1 score[0.67]\n",
      "[1545/5001] final loss [0.13499566912651062] accuracy[81.94] precision[33.33] recall[8.33] specificity[96.67] F1 score[0.13]\n",
      "[1546/5001] final loss [0.27236300706863403] accuracy[90.61] precision[10.53] recall[40.0] specificity[91.83] F1 score[0.17]\n",
      "[1547/5001] final loss [0.11973023414611816] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1548/5001] final loss [0.09466725587844849] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[1549/5001] final loss [0.13407590985298157] accuracy[92.75] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1550/5001] final loss [0.13849326968193054] accuracy[87.5] precision[0.0] recall[0.0] specificity[92.11] F1 score[0]\n",
      "[1551/5001] final loss [0.2284102737903595] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1552/5001] final loss [0.2164444476366043] accuracy[93.57] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1553/5001] final loss [0.24979807436466217] accuracy[94.57] precision[16.67] recall[100.0] specificity[94.51] F1 score[0.29]\n",
      "[1554/5001] final loss [0.1446732133626938] accuracy[93.9] precision[0.0] recall[0] specificity[93.9] F1 score[0]\n",
      "[1555/5001] final loss [0.2358807772397995] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1556/5001] final loss [0.11321282386779785] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1557/5001] final loss [0.18599066138267517] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1558/5001] final loss [0.15069757401943207] accuracy[92.77] precision[0.0] recall[0] specificity[92.77] F1 score[0]\n",
      "[1559/5001] final loss [0.0829133465886116] accuracy[70.41] precision[28.57] recall[17.39] specificity[86.67] F1 score[0.22]\n",
      "[1560/5001] final loss [0.11929875612258911] accuracy[88.27] precision[33.33] recall[16.67] specificity[96.27] F1 score[0.22]\n",
      "[1561/5001] final loss [0.10452275723218918] accuracy[88.89] precision[0.0] recall[0.0] specificity[91.43] F1 score[0]\n",
      "[1562/5001] final loss [0.02273624762892723] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1563/5001] final loss [0.15295089781284332] accuracy[91.07] precision[0.0] recall[0.0] specificity[95.33] F1 score[0]\n",
      "[1564/5001] final loss [0.16026975214481354] accuracy[88.66] precision[30.77] recall[23.53] specificity[94.92] F1 score[0.27]\n",
      "[1565/5001] final loss [0.14022959768772125] accuracy[90.18] precision[14.29] recall[16.67] specificity[94.34] F1 score[0.15]\n",
      "[1566/5001] final loss [0.22763653099536896] accuracy[82.61] precision[50.0] recall[16.67] specificity[96.49] F1 score[0.25]\n",
      "[1567/5001] final loss [0.2080242931842804] accuracy[94.4] precision[0.0] recall[0] specificity[94.4] F1 score[0]\n",
      "[1568/5001] final loss [0.12754736840724945] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[1569/5001] final loss [0.04856855794787407] accuracy[80.0] precision[0.0] recall[0] specificity[80.0] F1 score[0]\n",
      "[1570/5001] final loss [0.07282900810241699] accuracy[95.35] precision[16.67] recall[50.0] specificity[96.06] F1 score[0.25]\n",
      "[1571/5001] final loss [0.14043420553207397] accuracy[95.52] precision[0.0] recall[0] specificity[95.52] F1 score[0]\n",
      "[1572/5001] final loss [0.10736309736967087] accuracy[90.91] precision[0.0] recall[0.0] specificity[92.17] F1 score[0]\n",
      "[1573/5001] final loss [0.0616016685962677] accuracy[91.04] precision[33.33] recall[50.0] specificity[93.65] F1 score[0.4]\n",
      "[1574/5001] final loss [0.16878916323184967] accuracy[91.13] precision[0.0] recall[0.0] specificity[94.17] F1 score[0]\n",
      "[1575/5001] final loss [0.04128929600119591] accuracy[96.49] precision[0.0] recall[0] specificity[96.49] F1 score[0]\n",
      "[1576/5001] final loss [0.30282843112945557] accuracy[89.04] precision[14.29] recall[33.33] specificity[91.43] F1 score[0.2]\n",
      "[1577/5001] final loss [0.24975664913654327] accuracy[87.78] precision[0.0] recall[0.0] specificity[91.86] F1 score[0]\n",
      "[1578/5001] final loss [0.12680554389953613] accuracy[83.85] precision[31.58] recall[25.0] specificity[92.26] F1 score[0.28]\n",
      "[1579/5001] final loss [0.2430480718612671] accuracy[88.89] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1580/5001] final loss [0.07656341046094894] accuracy[94.62] precision[0.0] recall[0.0] specificity[97.78] F1 score[0]\n",
      "[1581/5001] final loss [0.2550033926963806] accuracy[97.3] precision[0.0] recall[0] specificity[97.3] F1 score[0]\n",
      "[1582/5001] final loss [0.08416510373353958] accuracy[94.74] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[1583/5001] final loss [0.011029036715626717] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[1584/5001] final loss [0.15185102820396423] accuracy[87.55] precision[18.75] recall[13.64] specificity[94.47] F1 score[0.16]\n",
      "[1585/5001] final loss [0.14111419022083282] accuracy[95.05] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[1586/5001] final loss [0.1489209681749344] accuracy[90.0] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[1587/5001] final loss [0.2691081166267395] accuracy[93.22] precision[0.0] recall[0] specificity[93.22] F1 score[0]\n",
      "[1588/5001] final loss [0.07279206812381744] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[1589/5001] final loss [0.02986011654138565] accuracy[89.19] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[1590/5001] final loss [0.1832590103149414] accuracy[94.07] precision[0.0] recall[0] specificity[94.07] F1 score[0]\n",
      "[1591/5001] final loss [0.03575979545712471] accuracy[95.61] precision[0.0] recall[0] specificity[95.61] F1 score[0]\n",
      "[1592/5001] final loss [0.01627400703728199] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1593/5001] final loss [0.14402662217617035] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1594/5001] final loss [0.14545339345932007] accuracy[96.08] precision[33.33] recall[100.0] specificity[96.0] F1 score[0.5]\n",
      "[1595/5001] final loss [0.14806705713272095] accuracy[90.53] precision[37.5] recall[31.58] specificity[95.54] F1 score[0.34]\n",
      "[1596/5001] final loss [0.17578712105751038] accuracy[94.69] precision[0.0] recall[0.0] specificity[95.54] F1 score[0]\n",
      "[1597/5001] final loss [0.007498761173337698] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1598/5001] final loss [0.1343717873096466] accuracy[92.21] precision[0.0] recall[0.0] specificity[94.25] F1 score[0]\n",
      "[1599/5001] final loss [0.1026991680264473] accuracy[85.71] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1600/5001] final loss [0.05786052718758583] accuracy[79.8] precision[42.86] recall[15.79] specificity[95.0] F1 score[0.23]\n",
      "[1601/5001] final loss [0.12902957201004028] accuracy[93.44] precision[0.0] recall[0] specificity[93.44] F1 score[0]\n",
      "[1602/5001] final loss [0.11758382618427277] accuracy[95.89] precision[0.0] recall[0] specificity[95.89] F1 score[0]\n",
      "[1603/5001] final loss [0.07978292554616928] accuracy[94.26] precision[0.0] recall[0.0] specificity[98.29] F1 score[0]\n",
      "[1604/5001] final loss [0.23328259587287903] accuracy[85.71] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[1605/5001] final loss [0.05623837932944298] accuracy[96.83] precision[33.33] recall[100.0] specificity[96.77] F1 score[0.5]\n",
      "[1606/5001] final loss [0.23810066282749176] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1607/5001] final loss [0.33575111627578735] accuracy[90.37] precision[0.0] recall[0.0] specificity[94.57] F1 score[0]\n",
      "[1608/5001] final loss [0.12405434250831604] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[1609/5001] final loss [0.2353028953075409] accuracy[91.03] precision[16.67] recall[33.33] specificity[93.33] F1 score[0.22]\n",
      "[1610/5001] final loss [0.1571955680847168] accuracy[85.51] precision[20.0] recall[14.29] specificity[93.55] F1 score[0.17]\n",
      "[1611/5001] final loss [0.3150550425052643] accuracy[87.27] precision[12.5] recall[9.09] specificity[94.29] F1 score[0.11]\n",
      "[1612/5001] final loss [0.11605050414800644] accuracy[90.2] precision[6.67] recall[22.22] specificity[91.95] F1 score[0.1]\n",
      "[1613/5001] final loss [0.2549809217453003] accuracy[92.1] precision[11.11] recall[22.22] specificity[94.33] F1 score[0.15]\n",
      "[1614/5001] final loss [0.10554060339927673] accuracy[98.08] precision[0.0] recall[0] specificity[98.08] F1 score[0]\n",
      "[1615/5001] final loss [0.13931773602962494] accuracy[88.38] precision[12.9] recall[20.0] specificity[92.29] F1 score[0.16]\n",
      "[1616/5001] final loss [0.09642702341079712] accuracy[91.77] precision[0.0] recall[0.0] specificity[92.17] F1 score[0]\n",
      "[1617/5001] final loss [0.08807192742824554] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1618/5001] final loss [0.024070585146546364] accuracy[94.83] precision[50.0] recall[33.33] specificity[98.18] F1 score[0.4]\n",
      "[1619/5001] final loss [0.13674376904964447] accuracy[92.78] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[1620/5001] final loss [0.15279968082904816] accuracy[90.8] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[1621/5001] final loss [0.04775398597121239] accuracy[93.18] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[1622/5001] final loss [0.3074693977832794] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1623/5001] final loss [0.14076976478099823] accuracy[94.79] precision[0.0] recall[0.0] specificity[96.81] F1 score[0]\n",
      "[1624/5001] final loss [0.15587009489536285] accuracy[87.5] precision[0.0] recall[0.0] specificity[90.59] F1 score[0]\n",
      "[1625/5001] final loss [0.2801723778247833] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1626/5001] final loss [0.2340167909860611] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[1627/5001] final loss [0.1768854260444641] accuracy[94.67] precision[14.29] recall[25.0] specificity[96.36] F1 score[0.18]\n",
      "[1628/5001] final loss [0.17708580195903778] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[1629/5001] final loss [0.05287892371416092] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[1630/5001] final loss [0.16958001255989075] accuracy[97.56] precision[0.0] recall[0] specificity[97.56] F1 score[0]\n",
      "[1631/5001] final loss [0.13983461260795593] accuracy[81.48] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[1632/5001] final loss [0.12919524312019348] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[1633/5001] final loss [0.09545077383518219] accuracy[91.88] precision[0.0] recall[0.0] specificity[93.04] F1 score[0]\n",
      "[1634/5001] final loss [0.15092113614082336] accuracy[92.94] precision[30.77] recall[30.77] specificity[96.28] F1 score[0.31]\n",
      "[1635/5001] final loss [0.09183499962091446] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1636/5001] final loss [0.28514400124549866] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[1637/5001] final loss [0.08148907870054245] accuracy[89.01] precision[25.0] recall[12.5] specificity[96.39] F1 score[0.17]\n",
      "[1638/5001] final loss [0.0020489529706537724] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1639/5001] final loss [0.09346409142017365] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1640/5001] final loss [0.41669192910194397] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1641/5001] final loss [0.1448620855808258] accuracy[92.44] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[1642/5001] final loss [0.0769382044672966] accuracy[93.33] precision[18.18] recall[50.0] specificity[94.41] F1 score[0.27]\n",
      "[1643/5001] final loss [0.11036842316389084] accuracy[92.54] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[1644/5001] final loss [0.00861548725515604] accuracy[88.76] precision[0.0] recall[0.0] specificity[97.53] F1 score[0]\n",
      "[1645/5001] final loss [0.032510530203580856] accuracy[85.0] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[1646/5001] final loss [0.15086989104747772] accuracy[77.08] precision[7.14] recall[10.0] specificity[84.88] F1 score[0.08]\n",
      "[1647/5001] final loss [0.11072267591953278] accuracy[90.61] precision[0.0] recall[0.0] specificity[94.25] F1 score[0]\n",
      "[1648/5001] final loss [0.20937034487724304] accuracy[88.11] precision[5.56] recall[9.09] specificity[92.13] F1 score[0.07]\n",
      "[1649/5001] final loss [0.1818237155675888] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[1650/5001] final loss [0.21531479060649872] accuracy[88.79] precision[8.7] recall[6.9] specificity[94.74] F1 score[0.08]\n",
      "[1651/5001] final loss [0.07319177687168121] accuracy[98.73] precision[0.0] recall[0] specificity[98.73] F1 score[0]\n",
      "[1652/5001] final loss [0.09644556045532227] accuracy[86.36] precision[8.33] recall[9.09] specificity[92.31] F1 score[0.09]\n",
      "[1653/5001] final loss [0.15654128789901733] accuracy[88.89] precision[0.0] recall[0.0] specificity[93.58] F1 score[0]\n",
      "[1654/5001] final loss [0.009516896679997444] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1655/5001] final loss [0.047460585832595825] accuracy[95.12] precision[50.0] recall[50.0] specificity[97.44] F1 score[0.5]\n",
      "[1656/5001] final loss [0.015603607520461082] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[1657/5001] final loss [0.26379498839378357] accuracy[95.27] precision[0.0] recall[0] specificity[95.27] F1 score[0]\n",
      "[1658/5001] final loss [0.19189204275608063] accuracy[85.75] precision[0.0] recall[0.0] specificity[91.65] F1 score[0]\n",
      "[1659/5001] final loss [0.148708313703537] accuracy[91.25] precision[0.0] recall[0.0] specificity[95.42] F1 score[0]\n",
      "[1660/5001] final loss [0.09518972039222717] accuracy[92.68] precision[33.33] recall[20.0] specificity[97.4] F1 score[0.25]\n",
      "[1661/5001] final loss [0.10927654802799225] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[1662/5001] final loss [0.08342902362346649] accuracy[93.4] precision[16.67] recall[33.33] specificity[95.15] F1 score[0.22]\n",
      "[1663/5001] final loss [0.27741578221321106] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1664/5001] final loss [0.23808707296848297] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1665/5001] final loss [0.19960938394069672] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1666/5001] final loss [0.09084876626729965] accuracy[85.02] precision[23.08] recall[10.0] specificity[95.39] F1 score[0.14]\n",
      "[1667/5001] final loss [0.09450839459896088] accuracy[90.74] precision[20.0] recall[50.0] specificity[92.31] F1 score[0.29]\n",
      "[1668/5001] final loss [0.1521841585636139] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[1669/5001] final loss [0.14598751068115234] accuracy[80.95] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[1670/5001] final loss [0.17831550538539886] accuracy[92.81] precision[6.25] recall[16.67] specificity[94.49] F1 score[0.09]\n",
      "[1671/5001] final loss [0.03354845568537712] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1672/5001] final loss [0.1011323556303978] accuracy[93.89] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[1673/5001] final loss [0.11724705994129181] accuracy[76.0] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1674/5001] final loss [0.08774866163730621] accuracy[84.62] precision[27.27] recall[33.33] specificity[90.24] F1 score[0.3]\n",
      "[1675/5001] final loss [0.08135955035686493] accuracy[93.02] precision[33.33] recall[50.0] specificity[95.12] F1 score[0.4]\n",
      "[1676/5001] final loss [0.12923093140125275] accuracy[89.11] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[1677/5001] final loss [0.04151094704866409] accuracy[93.59] precision[0.0] recall[0.0] specificity[96.05] F1 score[0]\n",
      "[1678/5001] final loss [0.059119801968336105] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[1679/5001] final loss [0.02369902841746807] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1680/5001] final loss [0.048576269298791885] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[1681/5001] final loss [0.1799071878194809] accuracy[94.64] precision[50.0] recall[33.33] specificity[98.11] F1 score[0.4]\n",
      "[1682/5001] final loss [0.09271392226219177] accuracy[95.52] precision[0.0] recall[0] specificity[95.52] F1 score[0]\n",
      "[1683/5001] final loss [0.06197262182831764] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1684/5001] final loss [0.158827543258667] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[1685/5001] final loss [0.08930835127830505] accuracy[97.22] precision[0.0] recall[0] specificity[97.22] F1 score[0]\n",
      "[1686/5001] final loss [0.04785482585430145] accuracy[93.88] precision[0.0] recall[0.0] specificity[95.83] F1 score[0]\n",
      "[1687/5001] final loss [0.1441795825958252] accuracy[91.1] precision[30.0] recall[33.33] specificity[94.89] F1 score[0.32]\n",
      "[1688/5001] final loss [0.05129031464457512] accuracy[95.59] precision[0.0] recall[0] specificity[95.59] F1 score[0]\n",
      "[1689/5001] final loss [0.24900394678115845] accuracy[95.28] precision[28.57] recall[66.67] specificity[95.97] F1 score[0.4]\n",
      "[1690/5001] final loss [0.08591626584529877] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[1691/5001] final loss [0.10205605626106262] accuracy[91.43] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1692/5001] final loss [0.046487957239151] accuracy[90.48] precision[0.0] recall[0] specificity[90.48] F1 score[0]\n",
      "[1693/5001] final loss [0.11436482518911362] accuracy[95.0] precision[0.0] recall[0.0] specificity[97.44] F1 score[0]\n",
      "[1694/5001] final loss [0.28588658571243286] accuracy[95.71] precision[0.0] recall[0] specificity[95.71] F1 score[0]\n",
      "[1695/5001] final loss [0.11263421177864075] accuracy[90.96] precision[0.0] recall[0.0] specificity[94.48] F1 score[0]\n",
      "[1696/5001] final loss [0.1435517817735672] accuracy[94.02] precision[0.0] recall[0] specificity[94.02] F1 score[0]\n",
      "[1697/5001] final loss [0.17330993711948395] accuracy[95.38] precision[0.0] recall[0] specificity[95.38] F1 score[0]\n",
      "[1698/5001] final loss [0.11567679047584534] accuracy[94.51] precision[0.0] recall[0.0] specificity[95.09] F1 score[0]\n",
      "[1699/5001] final loss [0.16286374628543854] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1700/5001] final loss [0.11189360916614532] accuracy[84.13] precision[11.11] recall[7.69] specificity[92.92] F1 score[0.09]\n",
      "[1701/5001] final loss [0.04031479358673096] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[1702/5001] final loss [0.18135926127433777] accuracy[90.0] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[1703/5001] final loss [0.14121586084365845] accuracy[94.55] precision[50.0] recall[33.33] specificity[98.08] F1 score[0.4]\n",
      "[1704/5001] final loss [0.0441400520503521] accuracy[93.44] precision[0.0] recall[0] specificity[93.44] F1 score[0]\n",
      "[1705/5001] final loss [0.1518770158290863] accuracy[89.33] precision[11.11] recall[20.0] specificity[92.56] F1 score[0.14]\n",
      "[1706/5001] final loss [0.03817987069487572] accuracy[91.3] precision[50.0] recall[25.0] specificity[97.62] F1 score[0.33]\n",
      "[1707/5001] final loss [0.12400095164775848] accuracy[93.84] precision[16.67] recall[20.0] specificity[96.45] F1 score[0.18]\n",
      "[1708/5001] final loss [0.18249553442001343] accuracy[87.34] precision[30.0] recall[50.0] specificity[90.41] F1 score[0.38]\n",
      "[1709/5001] final loss [0.19780012965202332] accuracy[84.62] precision[18.18] recall[28.57] specificity[89.29] F1 score[0.22]\n",
      "[1710/5001] final loss [0.16862547397613525] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1711/5001] final loss [0.21510763466358185] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1712/5001] final loss [0.13759233057498932] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[1713/5001] final loss [0.15087933838367462] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1714/5001] final loss [0.13651369512081146] accuracy[88.04] precision[21.43] recall[21.43] specificity[93.53] F1 score[0.21]\n",
      "[1715/5001] final loss [0.10965394973754883] accuracy[87.58] precision[20.0] recall[15.38] specificity[94.29] F1 score[0.17]\n",
      "[1716/5001] final loss [0.10882700234651566] accuracy[89.83] precision[20.0] recall[33.33] specificity[92.86] F1 score[0.25]\n",
      "[1717/5001] final loss [0.15597230195999146] accuracy[95.8] precision[0.0] recall[0] specificity[95.8] F1 score[0]\n",
      "[1718/5001] final loss [0.10607984662055969] accuracy[95.18] precision[20.0] recall[100.0] specificity[95.12] F1 score[0.33]\n",
      "[1719/5001] final loss [0.15970680117607117] accuracy[86.32] precision[14.29] recall[9.09] specificity[94.34] F1 score[0.11]\n",
      "[1720/5001] final loss [0.22233347594738007] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1721/5001] final loss [0.027624638751149178] accuracy[92.04] precision[16.67] recall[20.0] specificity[95.37] F1 score[0.18]\n",
      "[1722/5001] final loss [0.205130934715271] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[1723/5001] final loss [0.11600589752197266] accuracy[94.67] precision[0.0] recall[0] specificity[94.67] F1 score[0]\n",
      "[1724/5001] final loss [0.0620720274746418] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[1725/5001] final loss [0.07927724719047546] accuracy[88.64] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[1726/5001] final loss [0.03099256008863449] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1727/5001] final loss [0.1269359588623047] accuracy[90.71] precision[0.0] recall[0.0] specificity[94.07] F1 score[0]\n",
      "[1728/5001] final loss [0.2006814181804657] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1729/5001] final loss [0.11582833528518677] accuracy[95.4] precision[0.0] recall[0] specificity[95.4] F1 score[0]\n",
      "[1730/5001] final loss [0.1594502180814743] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1731/5001] final loss [0.16435506939888] accuracy[89.9] precision[33.33] recall[11.11] specificity[97.78] F1 score[0.17]\n",
      "[1732/5001] final loss [0.0738360583782196] accuracy[70.37] precision[100.0] recall[11.11] specificity[100.0] F1 score[0.2]\n",
      "[1733/5001] final loss [0.2238277643918991] accuracy[86.32] precision[20.0] recall[10.0] specificity[95.29] F1 score[0.13]\n",
      "[1734/5001] final loss [0.17397543787956238] accuracy[89.95] precision[5.88] recall[16.67] specificity[92.12] F1 score[0.09]\n",
      "[1735/5001] final loss [0.09930596500635147] accuracy[87.86] precision[15.38] recall[16.67] specificity[93.17] F1 score[0.16]\n",
      "[1736/5001] final loss [0.11866682022809982] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1737/5001] final loss [0.17380845546722412] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1738/5001] final loss [0.015137884765863419] accuracy[95.7] precision[0.0] recall[0] specificity[95.7] F1 score[0]\n",
      "[1739/5001] final loss [0.030258994549512863] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[1740/5001] final loss [0.05201858654618263] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[1741/5001] final loss [0.13852715492248535] accuracy[86.67] precision[0.0] recall[0.0] specificity[90.7] F1 score[0]\n",
      "[1742/5001] final loss [0.13117104768753052] accuracy[90.91] precision[0.0] recall[0.0] specificity[93.02] F1 score[0]\n",
      "[1743/5001] final loss [0.12743011116981506] accuracy[91.49] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[1744/5001] final loss [0.14463205635547638] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[1745/5001] final loss [0.035084694623947144] accuracy[81.08] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1746/5001] final loss [0.3142353594303131] accuracy[92.86] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[1747/5001] final loss [0.14693805575370789] accuracy[93.96] precision[8.33] recall[100.0] specificity[93.92] F1 score[0.15]\n",
      "[1748/5001] final loss [0.055156972259283066] accuracy[91.07] precision[0.0] recall[0.0] specificity[92.73] F1 score[0]\n",
      "[1749/5001] final loss [0.0896904468536377] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[1750/5001] final loss [0.11704535037279129] accuracy[93.42] precision[0.0] recall[0.0] specificity[94.67] F1 score[0]\n",
      "[1751/5001] final loss [0.07979253679513931] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1752/5001] final loss [0.07116209715604782] accuracy[87.5] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1753/5001] final loss [0.10079020261764526] accuracy[90.53] precision[15.38] recall[22.22] specificity[93.92] F1 score[0.18]\n",
      "[1754/5001] final loss [0.059745486825704575] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[1755/5001] final loss [0.07211004942655563] accuracy[94.8] precision[0.0] recall[0] specificity[94.8] F1 score[0]\n",
      "[1756/5001] final loss [0.05222916603088379] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1757/5001] final loss [0.021593570709228516] accuracy[92.16] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[1758/5001] final loss [0.1609538346529007] accuracy[92.49] precision[20.0] recall[28.57] specificity[95.18] F1 score[0.24]\n",
      "[1759/5001] final loss [0.14695905148983002] accuracy[91.3] precision[25.0] recall[25.0] specificity[95.38] F1 score[0.25]\n",
      "[1760/5001] final loss [0.10753657668828964] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1761/5001] final loss [0.03507095202803612] accuracy[96.39] precision[0.0] recall[0] specificity[96.39] F1 score[0]\n",
      "[1762/5001] final loss [0.2535720467567444] accuracy[94.23] precision[0.0] recall[0] specificity[94.23] F1 score[0]\n",
      "[1763/5001] final loss [0.09316015988588333] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[1764/5001] final loss [0.010342306457459927] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[1765/5001] final loss [0.1333320140838623] accuracy[94.5] precision[0.0] recall[0.0] specificity[95.37] F1 score[0]\n",
      "[1766/5001] final loss [0.053858913481235504] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1767/5001] final loss [0.12706847488880157] accuracy[92.11] precision[25.0] recall[100.0] specificity[91.89] F1 score[0.4]\n",
      "[1768/5001] final loss [0.21484357118606567] accuracy[93.75] precision[16.67] recall[50.0] specificity[94.68] F1 score[0.25]\n",
      "[1769/5001] final loss [0.06780250370502472] accuracy[93.44] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[1770/5001] final loss [0.09275764226913452] accuracy[96.95] precision[0.0] recall[0] specificity[96.95] F1 score[0]\n",
      "[1771/5001] final loss [0.29173707962036133] accuracy[91.3] precision[12.5] recall[50.0] specificity[92.22] F1 score[0.2]\n",
      "[1772/5001] final loss [0.12058509141206741] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[1773/5001] final loss [0.029324138537049294] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1774/5001] final loss [0.1357920616865158] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[1775/5001] final loss [0.20180165767669678] accuracy[88.08] precision[16.67] recall[13.33] specificity[94.38] F1 score[0.15]\n",
      "[1776/5001] final loss [0.16801634430885315] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[1777/5001] final loss [0.16461919248104095] accuracy[75.0] precision[33.33] recall[8.33] specificity[95.0] F1 score[0.13]\n",
      "[1778/5001] final loss [0.060772523283958435] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1779/5001] final loss [0.12344743311405182] accuracy[93.97] precision[0.0] recall[0] specificity[93.97] F1 score[0]\n",
      "[1780/5001] final loss [0.2524133026599884] accuracy[88.37] precision[0.0] recall[0.0] specificity[92.68] F1 score[0]\n",
      "[1781/5001] final loss [0.07146020233631134] accuracy[95.18] precision[20.0] recall[100.0] specificity[95.12] F1 score[0.33]\n",
      "[1782/5001] final loss [0.031890496611595154] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1783/5001] final loss [0.08968047797679901] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[1784/5001] final loss [0.4245852530002594] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1785/5001] final loss [0.07723170518875122] accuracy[90.2] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[1786/5001] final loss [0.11428209394216537] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1787/5001] final loss [0.16465386748313904] accuracy[92.24] precision[0.0] recall[0.0] specificity[93.45] F1 score[0]\n",
      "[1788/5001] final loss [0.12052751332521439] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.38] F1 score[0]\n",
      "[1789/5001] final loss [0.25573915243148804] accuracy[95.15] precision[0.0] recall[0] specificity[95.15] F1 score[0]\n",
      "[1790/5001] final loss [0.12774649262428284] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[1791/5001] final loss [0.15117262303829193] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1792/5001] final loss [0.06501089036464691] accuracy[94.05] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[1793/5001] final loss [0.14311029016971588] accuracy[89.14] precision[5.26] recall[50.0] specificity[89.6] F1 score[0.1]\n",
      "[1794/5001] final loss [0.22998666763305664] accuracy[87.5] precision[12.5] recall[13.33] specificity[93.03] F1 score[0.13]\n",
      "[1795/5001] final loss [0.35015252232551575] accuracy[97.14] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1796/5001] final loss [0.06283488869667053] accuracy[92.65] precision[0.0] recall[0.0] specificity[96.92] F1 score[0]\n",
      "[1797/5001] final loss [0.019626403227448463] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1798/5001] final loss [0.09027450531721115] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[1799/5001] final loss [0.025742368772625923] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[1800/5001] final loss [0.04944727569818497] accuracy[94.74] precision[0.0] recall[0.0] specificity[96.77] F1 score[0]\n",
      "[1801/5001] final loss [0.10728968679904938] accuracy[92.31] precision[25.0] recall[50.0] specificity[94.0] F1 score[0.33]\n",
      "[1802/5001] final loss [0.0678144246339798] accuracy[89.71] precision[0.0] recall[0.0] specificity[95.31] F1 score[0]\n",
      "[1803/5001] final loss [0.2561556398868561] accuracy[96.21] precision[0.0] recall[0] specificity[96.21] F1 score[0]\n",
      "[1804/5001] final loss [0.2633424997329712] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1805/5001] final loss [0.17553918063640594] accuracy[85.11] precision[0.0] recall[0.0] specificity[91.95] F1 score[0]\n",
      "[1806/5001] final loss [0.05735614523291588] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1807/5001] final loss [0.09482481330633163] accuracy[93.44] precision[0.0] recall[0.0] specificity[94.21] F1 score[0]\n",
      "[1808/5001] final loss [0.0650702714920044] accuracy[86.51] precision[20.0] recall[12.0] specificity[94.71] F1 score[0.15]\n",
      "[1809/5001] final loss [0.1270933598279953] accuracy[96.72] precision[0.0] recall[0] specificity[96.72] F1 score[0]\n",
      "[1810/5001] final loss [0.21387867629528046] accuracy[95.49] precision[0.0] recall[0.0] specificity[96.21] F1 score[0]\n",
      "[1811/5001] final loss [0.12124910950660706] accuracy[95.48] precision[22.22] recall[66.67] specificity[95.98] F1 score[0.33]\n",
      "[1812/5001] final loss [0.04056379944086075] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[1813/5001] final loss [0.07106129825115204] accuracy[78.57] precision[25.0] recall[14.29] specificity[91.43] F1 score[0.18]\n",
      "[1814/5001] final loss [0.11616943031549454] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[1815/5001] final loss [0.17473866045475006] accuracy[81.36] precision[26.67] recall[15.38] specificity[92.72] F1 score[0.2]\n",
      "[1816/5001] final loss [0.022120686247944832] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1817/5001] final loss [0.1297268122434616] accuracy[96.23] precision[50.0] recall[50.0] specificity[98.04] F1 score[0.5]\n",
      "[1818/5001] final loss [0.3238489329814911] accuracy[93.1] precision[10.0] recall[50.0] specificity[93.71] F1 score[0.17]\n",
      "[1819/5001] final loss [0.07374625653028488] accuracy[93.94] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[1820/5001] final loss [0.027921456843614578] accuracy[95.0] precision[0.0] recall[0.0] specificity[96.61] F1 score[0]\n",
      "[1821/5001] final loss [0.017848407849669456] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1822/5001] final loss [0.2071271538734436] accuracy[92.49] precision[0.0] recall[0.0] specificity[93.02] F1 score[0]\n",
      "[1823/5001] final loss [0.10722538828849792] accuracy[92.97] precision[0.0] recall[0] specificity[92.97] F1 score[0]\n",
      "[1824/5001] final loss [0.19296324253082275] accuracy[88.14] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[1825/5001] final loss [0.08969798684120178] accuracy[95.93] precision[0.0] recall[0] specificity[95.93] F1 score[0]\n",
      "[1826/5001] final loss [0.13135196268558502] accuracy[88.14] precision[41.67] recall[23.81] specificity[95.95] F1 score[0.3]\n",
      "[1827/5001] final loss [0.09413905441761017] accuracy[92.08] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[1828/5001] final loss [0.10695657134056091] accuracy[95.12] precision[33.33] recall[100.0] specificity[95.0] F1 score[0.5]\n",
      "[1829/5001] final loss [0.15623337030410767] accuracy[87.5] precision[10.0] recall[14.29] specificity[92.04] F1 score[0.12]\n",
      "[1830/5001] final loss [0.050949517637491226] accuracy[94.12] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[1831/5001] final loss [0.03576722741127014] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1832/5001] final loss [0.12325214594602585] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1833/5001] final loss [0.257059782743454] accuracy[92.31] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[1834/5001] final loss [0.0776340588927269] accuracy[94.7] precision[0.0] recall[0] specificity[94.7] F1 score[0]\n",
      "[1835/5001] final loss [0.13022102415561676] accuracy[89.93] precision[36.36] recall[33.33] specificity[94.89] F1 score[0.35]\n",
      "[1836/5001] final loss [0.08978994935750961] accuracy[92.34] precision[0.0] recall[0.0] specificity[93.18] F1 score[0]\n",
      "[1837/5001] final loss [0.044426970183849335] accuracy[88.33] precision[33.33] recall[16.67] specificity[96.3] F1 score[0.22]\n",
      "[1838/5001] final loss [0.04498942196369171] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[1839/5001] final loss [0.015789596363902092] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[1840/5001] final loss [0.031224308535456657] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[1841/5001] final loss [0.02035684511065483] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1842/5001] final loss [0.11192076653242111] accuracy[89.0] precision[0.0] recall[0.0] specificity[90.82] F1 score[0]\n",
      "[1843/5001] final loss [0.0827755481004715] accuracy[93.55] precision[0.0] recall[0.0] specificity[95.08] F1 score[0]\n",
      "[1844/5001] final loss [0.21659202873706818] accuracy[83.5] precision[33.33] recall[13.33] specificity[95.45] F1 score[0.19]\n",
      "[1845/5001] final loss [0.1438220888376236] accuracy[86.14] precision[9.09] recall[20.0] specificity[89.58] F1 score[0.12]\n",
      "[1846/5001] final loss [0.08721142262220383] accuracy[94.52] precision[25.0] recall[50.0] specificity[95.77] F1 score[0.33]\n",
      "[1847/5001] final loss [0.03938964754343033] accuracy[95.28] precision[0.0] recall[0] specificity[95.28] F1 score[0]\n",
      "[1848/5001] final loss [0.1331349015235901] accuracy[88.64] precision[28.57] recall[28.57] specificity[93.83] F1 score[0.29]\n",
      "[1849/5001] final loss [0.11307595670223236] accuracy[95.08] precision[0.0] recall[0] specificity[95.08] F1 score[0]\n",
      "[1850/5001] final loss [0.2516411244869232] accuracy[89.74] precision[80.0] recall[57.14] specificity[96.88] F1 score[0.67]\n",
      "[1851/5001] final loss [0.24585787951946259] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1852/5001] final loss [0.11783501505851746] accuracy[91.67] precision[0.0] recall[0.0] specificity[92.63] F1 score[0]\n",
      "[1853/5001] final loss [0.09355557709932327] accuracy[92.13] precision[20.0] recall[25.0] specificity[95.29] F1 score[0.22]\n",
      "[1854/5001] final loss [0.07075581699609756] accuracy[90.78] precision[0.0] recall[0.0] specificity[96.39] F1 score[0]\n",
      "[1855/5001] final loss [0.05656356364488602] accuracy[90.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1856/5001] final loss [0.01837003417313099] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[1857/5001] final loss [0.0794418454170227] accuracy[88.24] precision[0.0] recall[0] specificity[88.24] F1 score[0]\n",
      "[1858/5001] final loss [0.13691413402557373] accuracy[86.39] precision[53.85] recall[29.17] specificity[95.86] F1 score[0.38]\n",
      "[1859/5001] final loss [0.22886039316654205] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1860/5001] final loss [0.21218252182006836] accuracy[91.76] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[1861/5001] final loss [0.2512354552745819] accuracy[86.11] precision[50.0] recall[20.0] specificity[96.77] F1 score[0.29]\n",
      "[1862/5001] final loss [0.05775676295161247] accuracy[89.8] precision[0.0] recall[0] specificity[89.8] F1 score[0]\n",
      "[1863/5001] final loss [0.0431978814303875] accuracy[93.83] precision[0.0] recall[0.0] specificity[97.44] F1 score[0]\n",
      "[1864/5001] final loss [0.03201959654688835] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1865/5001] final loss [0.11173616349697113] accuracy[93.07] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[1866/5001] final loss [0.22266508638858795] accuracy[90.83] precision[6.25] recall[3.85] specificity[96.34] F1 score[0.05]\n",
      "[1867/5001] final loss [0.20836269855499268] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1868/5001] final loss [0.6208633184432983] accuracy[96.34] precision[0.0] recall[0] specificity[96.34] F1 score[0]\n",
      "[1869/5001] final loss [0.1367177963256836] accuracy[90.91] precision[0.0] recall[0.0] specificity[97.56] F1 score[0]\n",
      "[1870/5001] final loss [0.08929694443941116] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[1871/5001] final loss [0.09229598939418793] accuracy[88.46] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[1872/5001] final loss [0.1404857039451599] accuracy[92.75] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[1873/5001] final loss [0.14084210991859436] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1874/5001] final loss [0.07981452345848083] accuracy[89.17] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[1875/5001] final loss [0.144583061337471] accuracy[94.57] precision[0.0] recall[0] specificity[94.57] F1 score[0]\n",
      "[1876/5001] final loss [0.148372083902359] accuracy[96.18] precision[16.67] recall[100.0] specificity[96.15] F1 score[0.29]\n",
      "[1877/5001] final loss [0.0749097689986229] accuracy[94.12] precision[0.0] recall[0.0] specificity[95.52] F1 score[0]\n",
      "[1878/5001] final loss [0.12273049354553223] accuracy[90.91] precision[0.0] recall[0.0] specificity[93.02] F1 score[0]\n",
      "[1879/5001] final loss [0.03240585699677467] accuracy[79.17] precision[50.0] recall[20.0] specificity[94.74] F1 score[0.29]\n",
      "[1880/5001] final loss [0.3018656075000763] accuracy[93.75] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[1881/5001] final loss [0.1410386562347412] accuracy[93.39] precision[0.0] recall[0] specificity[93.39] F1 score[0]\n",
      "[1882/5001] final loss [0.24068184196949005] accuracy[95.71] precision[0.0] recall[0] specificity[95.71] F1 score[0]\n",
      "[1883/5001] final loss [0.07498570531606674] accuracy[98.53] precision[0.0] recall[0] specificity[98.53] F1 score[0]\n",
      "[1884/5001] final loss [0.11484784632921219] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[1885/5001] final loss [0.1741662174463272] accuracy[96.05] precision[0.0] recall[0] specificity[96.05] F1 score[0]\n",
      "[1886/5001] final loss [0.08015846461057663] accuracy[90.98] precision[9.09] recall[33.33] specificity[92.31] F1 score[0.14]\n",
      "[1887/5001] final loss [0.07940980046987534] accuracy[94.17] precision[0.0] recall[0] specificity[94.17] F1 score[0]\n",
      "[1888/5001] final loss [0.1394154131412506] accuracy[85.42] precision[25.0] recall[20.0] specificity[93.02] F1 score[0.22]\n",
      "[1889/5001] final loss [0.0264465119689703] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[1890/5001] final loss [0.14784526824951172] accuracy[84.15] precision[20.0] recall[15.0] specificity[92.64] F1 score[0.17]\n",
      "[1891/5001] final loss [0.025864005088806152] accuracy[91.3] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[1892/5001] final loss [0.15529091656208038] accuracy[88.46] precision[0.0] recall[0.0] specificity[93.24] F1 score[0]\n",
      "[1893/5001] final loss [0.013577955774962902] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[1894/5001] final loss [0.12943148612976074] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1895/5001] final loss [0.10801272094249725] accuracy[86.74] precision[5.88] recall[11.11] specificity[90.7] F1 score[0.08]\n",
      "[1896/5001] final loss [0.14289821684360504] accuracy[88.24] precision[42.86] recall[33.33] specificity[94.74] F1 score[0.37]\n",
      "[1897/5001] final loss [0.050987016409635544] accuracy[94.83] precision[0.0] recall[0] specificity[94.83] F1 score[0]\n",
      "[1898/5001] final loss [0.11664049327373505] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1899/5001] final loss [0.12927134335041046] accuracy[91.04] precision[0.0] recall[0.0] specificity[96.83] F1 score[0]\n",
      "[1900/5001] final loss [0.095332071185112] accuracy[91.86] precision[0.0] recall[0.0] specificity[92.4] F1 score[0]\n",
      "[1901/5001] final loss [0.14885789155960083] accuracy[88.0] precision[0.0] recall[0.0] specificity[92.96] F1 score[0]\n",
      "[1902/5001] final loss [0.08013874292373657] accuracy[93.1] precision[0.0] recall[0.0] specificity[95.07] F1 score[0]\n",
      "[1903/5001] final loss [0.13394272327423096] accuracy[91.98] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[1904/5001] final loss [0.08211445808410645] accuracy[90.74] precision[0.0] recall[0] specificity[90.74] F1 score[0]\n",
      "[1905/5001] final loss [0.05281620845198631] accuracy[64.71] precision[100.0] recall[14.29] specificity[100.0] F1 score[0.25]\n",
      "[1906/5001] final loss [0.09213271737098694] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1907/5001] final loss [0.23161138594150543] accuracy[95.37] precision[0.0] recall[0] specificity[95.37] F1 score[0]\n",
      "[1908/5001] final loss [0.09077922999858856] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[1909/5001] final loss [0.07204443216323853] accuracy[83.96] precision[25.0] recall[15.38] specificity[93.55] F1 score[0.19]\n",
      "[1910/5001] final loss [0.07658248394727707] accuracy[90.95] precision[11.11] recall[7.69] specificity[96.15] F1 score[0.09]\n",
      "[1911/5001] final loss [0.15763524174690247] accuracy[93.4] precision[7.69] recall[10.0] specificity[96.1] F1 score[0.09]\n",
      "[1912/5001] final loss [0.1403789222240448] accuracy[83.56] precision[20.0] recall[11.11] specificity[93.75] F1 score[0.14]\n",
      "[1913/5001] final loss [0.13932937383651733] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[1914/5001] final loss [0.09363885968923569] accuracy[89.15] precision[10.0] recall[16.67] specificity[92.68] F1 score[0.13]\n",
      "[1915/5001] final loss [0.007950806058943272] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1916/5001] final loss [0.15054479241371155] accuracy[96.25] precision[0.0] recall[0] specificity[96.25] F1 score[0]\n",
      "[1917/5001] final loss [0.03914932906627655] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1918/5001] final loss [0.3210007846355438] accuracy[92.0] precision[50.0] recall[50.0] specificity[95.65] F1 score[0.5]\n",
      "[1919/5001] final loss [0.019503362476825714] accuracy[88.37] precision[25.0] recall[33.33] specificity[92.5] F1 score[0.29]\n",
      "[1920/5001] final loss [0.09691809117794037] accuracy[83.46] precision[0.0] recall[0.0] specificity[93.81] F1 score[0]\n",
      "[1921/5001] final loss [0.17882545292377472] accuracy[86.15] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[1922/5001] final loss [0.06208764389157295] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1923/5001] final loss [0.14900897443294525] accuracy[94.27] precision[7.14] recall[33.33] specificity[94.98] F1 score[0.12]\n",
      "[1924/5001] final loss [0.13156403601169586] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[1925/5001] final loss [0.11246725171804428] accuracy[91.89] precision[60.0] recall[42.86] specificity[97.01] F1 score[0.5]\n",
      "[1926/5001] final loss [0.0697481632232666] accuracy[80.5] precision[12.5] recall[10.53] specificity[90.0] F1 score[0.11]\n",
      "[1927/5001] final loss [0.14684994518756866] accuracy[93.25] precision[0.0] recall[0.0] specificity[93.83] F1 score[0]\n",
      "[1928/5001] final loss [0.15938575565814972] accuracy[92.73] precision[25.0] recall[50.0] specificity[94.34] F1 score[0.33]\n",
      "[1929/5001] final loss [0.14734479784965515] accuracy[90.62] precision[0.0] recall[0] specificity[90.62] F1 score[0]\n",
      "[1930/5001] final loss [0.05436721816658974] accuracy[89.02] precision[0.0] recall[0.0] specificity[94.48] F1 score[0]\n",
      "[1931/5001] final loss [0.0476209856569767] accuracy[96.36] precision[0.0] recall[0] specificity[96.36] F1 score[0]\n",
      "[1932/5001] final loss [0.19552481174468994] accuracy[92.06] precision[0.0] recall[0] specificity[92.06] F1 score[0]\n",
      "[1933/5001] final loss [0.2353184074163437] accuracy[95.5] precision[0.0] recall[0.0] specificity[95.98] F1 score[0]\n",
      "[1934/5001] final loss [0.08385719358921051] accuracy[93.97] precision[0.0] recall[0.0] specificity[94.78] F1 score[0]\n",
      "[1935/5001] final loss [0.13449890911579132] accuracy[91.64] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[1936/5001] final loss [0.07706477493047714] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1937/5001] final loss [0.05012321099638939] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[1938/5001] final loss [0.09112358838319778] accuracy[93.42] precision[0.0] recall[0.0] specificity[97.26] F1 score[0]\n",
      "[1939/5001] final loss [0.08859091252088547] accuracy[91.62] precision[0.0] recall[0.0] specificity[96.23] F1 score[0]\n",
      "[1940/5001] final loss [0.24274395406246185] accuracy[87.14] precision[18.75] recall[17.65] specificity[93.26] F1 score[0.18]\n",
      "[1941/5001] final loss [0.10389760136604309] accuracy[91.3] precision[50.0] recall[50.0] specificity[95.24] F1 score[0.5]\n",
      "[1942/5001] final loss [0.08487525582313538] accuracy[92.13] precision[12.5] recall[12.5] specificity[95.88] F1 score[0.12]\n",
      "[1943/5001] final loss [0.11100906133651733] accuracy[90.36] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[1944/5001] final loss [0.07964804023504257] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1945/5001] final loss [0.08225344121456146] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[1946/5001] final loss [0.07871139794588089] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1947/5001] final loss [0.16393838822841644] accuracy[93.52] precision[50.0] recall[28.57] specificity[98.02] F1 score[0.36]\n",
      "[1948/5001] final loss [0.06269057095050812] accuracy[92.98] precision[0.0] recall[0.0] specificity[98.15] F1 score[0]\n",
      "[1949/5001] final loss [0.17528364062309265] accuracy[92.68] precision[25.0] recall[25.0] specificity[96.15] F1 score[0.25]\n",
      "[1950/5001] final loss [0.16701309382915497] accuracy[93.33] precision[0.0] recall[0.0] specificity[95.15] F1 score[0]\n",
      "[1951/5001] final loss [0.09527537971735] accuracy[94.74] precision[0.0] recall[0.0] specificity[95.74] F1 score[0]\n",
      "[1952/5001] final loss [0.0006336961523629725] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1953/5001] final loss [0.08653435856103897] accuracy[89.09] precision[0.0] recall[0.0] specificity[90.74] F1 score[0]\n",
      "[1954/5001] final loss [0.04017709940671921] accuracy[96.39] precision[0.0] recall[0] specificity[96.39] F1 score[0]\n",
      "[1955/5001] final loss [0.1690278798341751] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1956/5001] final loss [0.17044870555400848] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[1957/5001] final loss [0.05776925012469292] accuracy[93.55] precision[50.0] recall[50.0] specificity[96.55] F1 score[0.5]\n",
      "[1958/5001] final loss [0.03337458148598671] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[1959/5001] final loss [0.07507355511188507] accuracy[82.61] precision[0.0] recall[0.0] specificity[90.48] F1 score[0]\n",
      "[1960/5001] final loss [0.17064088582992554] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[1961/5001] final loss [0.27117761969566345] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[1962/5001] final loss [0.13336677849292755] accuracy[91.67] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[1963/5001] final loss [0.2408875823020935] accuracy[88.21] precision[6.25] recall[6.67] specificity[93.51] F1 score[0.06]\n",
      "[1964/5001] final loss [0.2243392914533615] accuracy[91.3] precision[11.11] recall[14.29] specificity[94.81] F1 score[0.13]\n",
      "[1965/5001] final loss [0.09478068351745605] accuracy[79.45] precision[14.29] recall[10.0] specificity[90.48] F1 score[0.12]\n",
      "[1966/5001] final loss [0.10130549222230911] accuracy[94.03] precision[33.33] recall[33.33] specificity[96.88] F1 score[0.33]\n",
      "[1967/5001] final loss [0.3907668888568878] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[1968/5001] final loss [0.046416305005550385] accuracy[97.47] precision[0.0] recall[0.0] specificity[98.72] F1 score[0]\n",
      "[1969/5001] final loss [0.2659488916397095] accuracy[93.55] precision[20.0] recall[20.0] specificity[96.64] F1 score[0.2]\n",
      "[1970/5001] final loss [0.05251144617795944] accuracy[93.18] precision[33.33] recall[12.5] specificity[98.39] F1 score[0.18]\n",
      "[1971/5001] final loss [0.07146590203046799] accuracy[87.18] precision[0.0] recall[0.0] specificity[91.07] F1 score[0]\n",
      "[1972/5001] final loss [0.09116540849208832] accuracy[92.38] precision[40.0] recall[28.57] specificity[96.94] F1 score[0.33]\n",
      "[1973/5001] final loss [0.30664893984794617] accuracy[90.91] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[1974/5001] final loss [0.1757349818944931] accuracy[81.48] precision[100.0] recall[16.67] specificity[100.0] F1 score[0.29]\n",
      "[1975/5001] final loss [0.10204599797725677] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[1976/5001] final loss [0.10900186002254486] accuracy[96.36] precision[0.0] recall[0] specificity[96.36] F1 score[0]\n",
      "[1977/5001] final loss [0.02424246072769165] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[1978/5001] final loss [0.02927776798605919] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1979/5001] final loss [0.03615815192461014] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[1980/5001] final loss [0.06139334663748741] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[1981/5001] final loss [0.12126213312149048] accuracy[90.62] precision[0.0] recall[0.0] specificity[96.67] F1 score[0]\n",
      "[1982/5001] final loss [0.1684437245130539] accuracy[91.1] precision[9.09] recall[25.0] specificity[92.96] F1 score[0.13]\n",
      "[1983/5001] final loss [0.22801995277404785] accuracy[93.67] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[1984/5001] final loss [0.24712161719799042] accuracy[84.44] precision[40.0] recall[33.33] specificity[92.31] F1 score[0.36]\n",
      "[1985/5001] final loss [0.061967309564352036] accuracy[84.09] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[1986/5001] final loss [0.5239146947860718] accuracy[96.35] precision[0.0] recall[0.0] specificity[97.06] F1 score[0]\n",
      "[1987/5001] final loss [0.11532299965620041] accuracy[92.42] precision[33.33] recall[66.67] specificity[93.65] F1 score[0.44]\n",
      "[1988/5001] final loss [0.18913811445236206] accuracy[94.89] precision[12.5] recall[100.0] specificity[94.85] F1 score[0.22]\n",
      "[1989/5001] final loss [0.25365105271339417] accuracy[96.91] precision[0.0] recall[0] specificity[96.91] F1 score[0]\n",
      "[1990/5001] final loss [0.15510810911655426] accuracy[92.05] precision[0.0] recall[0.0] specificity[96.43] F1 score[0]\n",
      "[1991/5001] final loss [0.04095543175935745] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[1992/5001] final loss [0.06420329958200455] accuracy[93.24] precision[0.0] recall[0.0] specificity[94.52] F1 score[0]\n",
      "[1993/5001] final loss [0.16199685633182526] accuracy[83.64] precision[0.0] recall[0.0] specificity[93.88] F1 score[0]\n",
      "[1994/5001] final loss [0.2350035160779953] accuracy[87.78] precision[20.0] recall[23.08] specificity[92.81] F1 score[0.21]\n",
      "[1995/5001] final loss [0.15878945589065552] accuracy[89.89] precision[0.0] recall[0.0] specificity[91.95] F1 score[0]\n",
      "[1996/5001] final loss [0.10557299852371216] accuracy[90.53] precision[0.0] recall[0.0] specificity[95.56] F1 score[0]\n",
      "[1997/5001] final loss [0.06823624670505524] accuracy[88.0] precision[50.0] recall[22.22] specificity[96.97] F1 score[0.31]\n",
      "[1998/5001] final loss [0.005016474984586239] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[1999/5001] final loss [0.23109781742095947] accuracy[90.7] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[2000/5001] final loss [0.06684274226427078] accuracy[87.88] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[2001/5001] final loss [0.07375450432300568] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[2002/5001] final loss [0.14362382888793945] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2003/5001] final loss [0.11247212439775467] accuracy[85.07] precision[27.27] recall[20.0] specificity[93.28] F1 score[0.23]\n",
      "[2004/5001] final loss [0.13874699175357819] accuracy[92.52] precision[33.33] recall[33.33] specificity[96.04] F1 score[0.33]\n",
      "[2005/5001] final loss [0.15371663868427277] accuracy[86.36] precision[8.33] recall[9.09] specificity[92.31] F1 score[0.09]\n",
      "[2006/5001] final loss [0.18266811966896057] accuracy[86.27] precision[12.5] recall[12.5] specificity[92.55] F1 score[0.12]\n",
      "[2007/5001] final loss [0.05646110698580742] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[2008/5001] final loss [0.11488363891839981] accuracy[87.85] precision[16.67] recall[11.11] specificity[94.9] F1 score[0.13]\n",
      "[2009/5001] final loss [0.03946889936923981] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[2010/5001] final loss [0.1073865294456482] accuracy[98.26] precision[0.0] recall[0] specificity[98.26] F1 score[0]\n",
      "[2011/5001] final loss [0.1234053298830986] accuracy[80.3] precision[20.0] recall[10.0] specificity[92.86] F1 score[0.13]\n",
      "[2012/5001] final loss [0.2745356261730194] accuracy[92.31] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[2013/5001] final loss [0.092577263712883] accuracy[92.52] precision[0.0] recall[0.0] specificity[95.77] F1 score[0]\n",
      "[2014/5001] final loss [0.21494798362255096] accuracy[73.33] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2015/5001] final loss [0.1835058182477951] accuracy[92.27] precision[11.11] recall[14.29] specificity[95.4] F1 score[0.13]\n",
      "[2016/5001] final loss [0.14894287288188934] accuracy[93.78] precision[0.0] recall[0] specificity[93.78] F1 score[0]\n",
      "[2017/5001] final loss [0.14607854187488556] accuracy[92.71] precision[0.0] recall[0] specificity[92.71] F1 score[0]\n",
      "[2018/5001] final loss [0.1318059265613556] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2019/5001] final loss [0.06498590111732483] accuracy[92.5] precision[16.67] recall[20.0] specificity[95.65] F1 score[0.18]\n",
      "[2020/5001] final loss [0.10874804854393005] accuracy[93.75] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[2021/5001] final loss [0.23133313655853271] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[2022/5001] final loss [0.06458164006471634] accuracy[93.85] precision[0.0] recall[0] specificity[93.85] F1 score[0]\n",
      "[2023/5001] final loss [0.1918654888868332] accuracy[86.55] precision[8.33] recall[16.67] specificity[90.27] F1 score[0.11]\n",
      "[2024/5001] final loss [0.15013648569583893] accuracy[92.13] precision[14.29] recall[50.0] specificity[93.1] F1 score[0.22]\n",
      "[2025/5001] final loss [0.13007834553718567] accuracy[89.29] precision[0.0] recall[0] specificity[89.29] F1 score[0]\n",
      "[2026/5001] final loss [0.08586767315864563] accuracy[83.54] precision[0.0] recall[0.0] specificity[92.96] F1 score[0]\n",
      "[2027/5001] final loss [0.18508245050907135] accuracy[86.82] precision[9.09] recall[12.5] specificity[91.74] F1 score[0.11]\n",
      "[2028/5001] final loss [0.03539276868104935] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2029/5001] final loss [0.2999382019042969] accuracy[89.8] precision[33.33] recall[25.0] specificity[95.56] F1 score[0.29]\n",
      "[2030/5001] final loss [0.13545963168144226] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[2031/5001] final loss [0.10713623464107513] accuracy[89.31] precision[0.0] recall[0.0] specificity[93.6] F1 score[0]\n",
      "[2032/5001] final loss [0.04408133774995804] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2033/5001] final loss [0.13608065247535706] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[2034/5001] final loss [0.11060333251953125] accuracy[96.73] precision[0.0] recall[0] specificity[96.73] F1 score[0]\n",
      "[2035/5001] final loss [0.0811779722571373] accuracy[91.43] precision[0.0] recall[0] specificity[91.43] F1 score[0]\n",
      "[2036/5001] final loss [0.020896561443805695] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[2037/5001] final loss [0.21439190208911896] accuracy[89.76] precision[0.0] recall[0.0] specificity[94.21] F1 score[0]\n",
      "[2038/5001] final loss [0.10931297391653061] accuracy[92.86] precision[20.0] recall[25.0] specificity[95.74] F1 score[0.22]\n",
      "[2039/5001] final loss [0.020885666832327843] accuracy[92.11] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2040/5001] final loss [0.02230221964418888] accuracy[93.38] precision[0.0] recall[0.0] specificity[97.92] F1 score[0]\n",
      "[2041/5001] final loss [0.07828503847122192] accuracy[93.55] precision[20.0] recall[33.33] specificity[95.56] F1 score[0.25]\n",
      "[2042/5001] final loss [0.0330379456281662] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[2043/5001] final loss [0.13237084448337555] accuracy[88.56] precision[4.76] recall[6.25] specificity[93.1] F1 score[0.05]\n",
      "[2044/5001] final loss [0.1204301193356514] accuracy[92.67] precision[0.0] recall[0.0] specificity[95.21] F1 score[0]\n",
      "[2045/5001] final loss [0.1447821855545044] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2046/5001] final loss [0.08480998128652573] accuracy[92.78] precision[20.0] recall[25.0] specificity[95.7] F1 score[0.22]\n",
      "[2047/5001] final loss [0.1126672625541687] accuracy[88.24] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[2048/5001] final loss [0.038671839982271194] accuracy[83.02] precision[0.0] recall[0.0] specificity[97.78] F1 score[0]\n",
      "[2049/5001] final loss [0.11510613560676575] accuracy[84.72] precision[8.0] recall[8.7] specificity[91.32] F1 score[0.08]\n",
      "[2050/5001] final loss [0.05535930395126343] accuracy[92.47] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[2051/5001] final loss [0.12458867579698563] accuracy[81.48] precision[11.11] recall[7.69] specificity[91.58] F1 score[0.09]\n",
      "[2052/5001] final loss [0.03321460261940956] accuracy[92.63] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[2053/5001] final loss [0.2135699838399887] accuracy[95.08] precision[40.0] recall[40.0] specificity[97.44] F1 score[0.4]\n",
      "[2054/5001] final loss [0.08206836879253387] accuracy[97.5] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2055/5001] final loss [0.08090447634458542] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[2056/5001] final loss [0.2251158207654953] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[2057/5001] final loss [0.1634186953306198] accuracy[97.14] precision[50.0] recall[100.0] specificity[97.06] F1 score[0.67]\n",
      "[2058/5001] final loss [0.133572056889534] accuracy[92.45] precision[11.11] recall[20.0] specificity[94.81] F1 score[0.14]\n",
      "[2059/5001] final loss [0.01915578357875347] accuracy[94.74] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2060/5001] final loss [0.09966560453176498] accuracy[93.88] precision[100.0] recall[40.0] specificity[100.0] F1 score[0.57]\n",
      "[2061/5001] final loss [0.04201877862215042] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[2062/5001] final loss [0.13134953379631042] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2063/5001] final loss [0.2094515860080719] accuracy[80.12] precision[20.0] recall[13.04] specificity[91.3] F1 score[0.16]\n",
      "[2064/5001] final loss [0.08709387481212616] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[2065/5001] final loss [0.3331466019153595] accuracy[97.87] precision[66.67] recall[100.0] specificity[97.78] F1 score[0.8]\n",
      "[2066/5001] final loss [0.02053162269294262] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2067/5001] final loss [0.2110709846019745] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[2068/5001] final loss [0.1035897433757782] accuracy[86.51] precision[0.0] recall[0.0] specificity[92.37] F1 score[0]\n",
      "[2069/5001] final loss [0.1165875643491745] accuracy[87.86] precision[25.0] recall[20.0] specificity[94.3] F1 score[0.22]\n",
      "[2070/5001] final loss [0.010259298607707024] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2071/5001] final loss [0.05892229825258255] accuracy[86.79] precision[0.0] recall[0] specificity[86.79] F1 score[0]\n",
      "[2072/5001] final loss [0.10274602472782135] accuracy[94.29] precision[25.0] recall[50.0] specificity[95.59] F1 score[0.33]\n",
      "[2073/5001] final loss [0.15477854013442993] accuracy[77.78] precision[0.0] recall[0.0] specificity[87.5] F1 score[0]\n",
      "[2074/5001] final loss [0.026655146852135658] accuracy[94.74] precision[0.0] recall[0.0] specificity[98.18] F1 score[0]\n",
      "[2075/5001] final loss [0.06565926969051361] accuracy[96.55] precision[33.33] recall[50.0] specificity[97.65] F1 score[0.4]\n",
      "[2076/5001] final loss [0.11703068763017654] accuracy[91.18] precision[0.0] recall[0] specificity[91.18] F1 score[0]\n",
      "[2077/5001] final loss [0.056071534752845764] accuracy[85.51] precision[0.0] recall[0.0] specificity[92.19] F1 score[0]\n",
      "[2078/5001] final loss [0.0904812142252922] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2079/5001] final loss [0.013325795531272888] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2080/5001] final loss [0.06968533247709274] accuracy[91.46] precision[16.67] recall[33.33] specificity[93.67] F1 score[0.22]\n",
      "[2081/5001] final loss [0.06725849211215973] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2082/5001] final loss [0.18250690400600433] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[2083/5001] final loss [0.10968710482120514] accuracy[93.98] precision[0.0] recall[0.0] specificity[94.7] F1 score[0]\n",
      "[2084/5001] final loss [0.18061433732509613] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[2085/5001] final loss [0.1032421812415123] accuracy[90.55] precision[0.0] recall[0.0] specificity[93.5] F1 score[0]\n",
      "[2086/5001] final loss [0.09061107784509659] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.9] F1 score[0]\n",
      "[2087/5001] final loss [0.0031007961370050907] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2088/5001] final loss [0.12387774884700775] accuracy[88.31] precision[30.77] recall[30.77] specificity[93.62] F1 score[0.31]\n",
      "[2089/5001] final loss [0.16942183673381805] accuracy[88.41] precision[33.33] recall[33.33] specificity[93.65] F1 score[0.33]\n",
      "[2090/5001] final loss [0.08766181021928787] accuracy[92.78] precision[14.29] recall[50.0] specificity[93.68] F1 score[0.22]\n",
      "[2091/5001] final loss [0.1510518342256546] accuracy[93.44] precision[0.0] recall[0] specificity[93.44] F1 score[0]\n",
      "[2092/5001] final loss [0.10198596119880676] accuracy[90.0] precision[16.67] recall[10.0] specificity[96.15] F1 score[0.13]\n",
      "[2093/5001] final loss [0.06468303501605988] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[2094/5001] final loss [0.29493486881256104] accuracy[87.58] precision[11.11] recall[7.69] specificity[94.59] F1 score[0.09]\n",
      "[2095/5001] final loss [0.19264167547225952] accuracy[93.51] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[2096/5001] final loss [0.19156041741371155] accuracy[93.65] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[2097/5001] final loss [0.17163249850273132] accuracy[85.41] precision[15.38] recall[17.39] specificity[91.47] F1 score[0.16]\n",
      "[2098/5001] final loss [0.1802135705947876] accuracy[88.68] precision[0.0] recall[0.0] specificity[90.38] F1 score[0]\n",
      "[2099/5001] final loss [0.062115900218486786] accuracy[66.04] precision[20.0] recall[6.67] specificity[89.47] F1 score[0.1]\n",
      "[2100/5001] final loss [0.12006434053182602] accuracy[92.21] precision[0.0] recall[0.0] specificity[93.42] F1 score[0]\n",
      "[2101/5001] final loss [0.12474358081817627] accuracy[88.76] precision[20.0] recall[15.38] specificity[94.87] F1 score[0.17]\n",
      "[2102/5001] final loss [0.12524625658988953] accuracy[82.57] precision[10.0] recall[9.09] specificity[90.82] F1 score[0.1]\n",
      "[2103/5001] final loss [0.1345943957567215] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2104/5001] final loss [0.05037226900458336] accuracy[90.24] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[2105/5001] final loss [0.07388389110565186] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[2106/5001] final loss [0.14827266335487366] accuracy[89.53] precision[7.69] recall[14.29] specificity[92.73] F1 score[0.1]\n",
      "[2107/5001] final loss [0.11774525046348572] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2108/5001] final loss [0.11528881639242172] accuracy[89.55] precision[50.0] recall[28.57] specificity[96.67] F1 score[0.36]\n",
      "[2109/5001] final loss [0.04170960560441017] accuracy[92.59] precision[0.0] recall[0.0] specificity[96.15] F1 score[0]\n",
      "[2110/5001] final loss [0.11961955577135086] accuracy[94.16] precision[0.0] recall[0] specificity[94.16] F1 score[0]\n",
      "[2111/5001] final loss [0.2283983826637268] accuracy[93.44] precision[33.33] recall[33.33] specificity[96.55] F1 score[0.33]\n",
      "[2112/5001] final loss [0.04337576404213905] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[2113/5001] final loss [0.11203698813915253] accuracy[93.39] precision[14.29] recall[33.33] specificity[94.92] F1 score[0.2]\n",
      "[2114/5001] final loss [0.1876719444990158] accuracy[94.81] precision[0.0] recall[0] specificity[94.81] F1 score[0]\n",
      "[2115/5001] final loss [0.08744204044342041] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[2116/5001] final loss [0.14558830857276917] accuracy[96.05] precision[0.0] recall[0] specificity[96.05] F1 score[0]\n",
      "[2117/5001] final loss [0.1388702392578125] accuracy[94.59] precision[0.0] recall[0.0] specificity[97.22] F1 score[0]\n",
      "[2118/5001] final loss [0.0546460822224617] accuracy[86.76] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[2119/5001] final loss [0.11298833787441254] accuracy[92.14] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[2120/5001] final loss [0.1044793501496315] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[2121/5001] final loss [0.1745462566614151] accuracy[72.22] precision[100.0] recall[16.67] specificity[100.0] F1 score[0.29]\n",
      "[2122/5001] final loss [0.3027704954147339] accuracy[89.9] precision[10.0] recall[8.33] specificity[95.16] F1 score[0.09]\n",
      "[2123/5001] final loss [0.14754663407802582] accuracy[88.39] precision[12.5] recall[14.29] specificity[93.33] F1 score[0.13]\n",
      "[2124/5001] final loss [0.042761363089084625] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2125/5001] final loss [0.10192098468542099] accuracy[83.02] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[2126/5001] final loss [0.07651564478874207] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[2127/5001] final loss [0.1131257712841034] accuracy[91.75] precision[6.67] recall[33.33] specificity[92.67] F1 score[0.11]\n",
      "[2128/5001] final loss [0.009722930379211903] accuracy[92.19] precision[0.0] recall[0.0] specificity[96.72] F1 score[0]\n",
      "[2129/5001] final loss [0.08461391180753708] accuracy[96.34] precision[0.0] recall[0] specificity[96.34] F1 score[0]\n",
      "[2130/5001] final loss [0.04822353646159172] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2131/5001] final loss [0.011667987331748009] accuracy[90.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2132/5001] final loss [0.19627314805984497] accuracy[93.22] precision[0.0] recall[0] specificity[93.22] F1 score[0]\n",
      "[2133/5001] final loss [0.10652723908424377] accuracy[90.48] precision[14.29] recall[33.33] specificity[92.59] F1 score[0.2]\n",
      "[2134/5001] final loss [0.11217876523733139] accuracy[91.12] precision[0.0] recall[0.0] specificity[96.25] F1 score[0]\n",
      "[2135/5001] final loss [0.10633354634046555] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[2136/5001] final loss [0.038303449749946594] accuracy[95.59] precision[0.0] recall[0] specificity[95.59] F1 score[0]\n",
      "[2137/5001] final loss [0.20403467118740082] accuracy[93.07] precision[0.0] recall[0.0] specificity[95.92] F1 score[0]\n",
      "[2138/5001] final loss [0.03677435219287872] accuracy[90.38] precision[0.0] recall[0.0] specificity[95.92] F1 score[0]\n",
      "[2139/5001] final loss [0.24805229902267456] accuracy[85.25] precision[10.0] recall[8.57] specificity[92.6] F1 score[0.09]\n",
      "[2140/5001] final loss [0.14523768424987793] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[2141/5001] final loss [0.22770662605762482] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[2142/5001] final loss [0.18573693931102753] accuracy[90.09] precision[10.0] recall[6.67] specificity[95.85] F1 score[0.08]\n",
      "[2143/5001] final loss [0.17237412929534912] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[2144/5001] final loss [0.3182118535041809] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2145/5001] final loss [0.08941696584224701] accuracy[89.87] precision[0.0] recall[0.0] specificity[93.42] F1 score[0]\n",
      "[2146/5001] final loss [0.10904983431100845] accuracy[88.1] precision[12.5] recall[7.14] specificity[95.45] F1 score[0.09]\n",
      "[2147/5001] final loss [0.24347148835659027] accuracy[92.68] precision[20.0] recall[33.33] specificity[94.94] F1 score[0.25]\n",
      "[2148/5001] final loss [0.15983499586582184] accuracy[92.56] precision[18.18] recall[100.0] specificity[92.44] F1 score[0.31]\n",
      "[2149/5001] final loss [0.08096374571323395] accuracy[88.06] precision[25.0] recall[16.67] specificity[95.08] F1 score[0.2]\n",
      "[2150/5001] final loss [0.10219154506921768] accuracy[93.75] precision[14.29] recall[100.0] specificity[93.68] F1 score[0.25]\n",
      "[2151/5001] final loss [0.17152610421180725] accuracy[84.77] precision[23.08] recall[13.04] specificity[94.25] F1 score[0.17]\n",
      "[2152/5001] final loss [0.22349131107330322] accuracy[95.29] precision[0.0] recall[0] specificity[95.29] F1 score[0]\n",
      "[2153/5001] final loss [0.09361372888088226] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2154/5001] final loss [0.05468767508864403] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[2155/5001] final loss [0.23270726203918457] accuracy[78.43] precision[0.0] recall[0.0] specificity[88.89] F1 score[0]\n",
      "[2156/5001] final loss [0.16364537179470062] accuracy[82.8] precision[14.29] recall[9.09] specificity[92.68] F1 score[0.11]\n",
      "[2157/5001] final loss [0.04370012879371643] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2158/5001] final loss [0.4946848452091217] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[2159/5001] final loss [0.013358725234866142] accuracy[95.65] precision[0.0] recall[0.0] specificity[97.35] F1 score[0]\n",
      "[2160/5001] final loss [0.21676452457904816] accuracy[92.19] precision[0.0] recall[0.0] specificity[93.65] F1 score[0]\n",
      "[2161/5001] final loss [0.16493859887123108] accuracy[91.58] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[2162/5001] final loss [0.0864189863204956] accuracy[95.1] precision[0.0] recall[0] specificity[95.1] F1 score[0]\n",
      "[2163/5001] final loss [0.07613754272460938] accuracy[93.08] precision[10.0] recall[10.0] specificity[96.4] F1 score[0.1]\n",
      "[2164/5001] final loss [0.11950816214084625] accuracy[90.24] precision[16.67] recall[25.0] specificity[93.59] F1 score[0.2]\n",
      "[2165/5001] final loss [0.15412917733192444] accuracy[82.12] precision[8.33] recall[5.88] specificity[91.79] F1 score[0.07]\n",
      "[2166/5001] final loss [0.07434112578630447] accuracy[97.3] precision[0.0] recall[0] specificity[97.3] F1 score[0]\n",
      "[2167/5001] final loss [0.06302348524332047] accuracy[89.36] precision[0.0] recall[0.0] specificity[92.92] F1 score[0]\n",
      "[[2168/10000]] loop skipped\n",
      "[2169/5002] final loss [0.27343735098838806] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2170/5002] final loss [0.117867611348629] accuracy[93.12] precision[0.0] recall[0.0] specificity[93.5] F1 score[0]\n",
      "[2171/5002] final loss [0.27024397253990173] accuracy[94.62] precision[0.0] recall[0.0] specificity[96.7] F1 score[0]\n",
      "[2172/5002] final loss [0.10294041782617569] accuracy[96.72] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2173/5002] final loss [0.047781363129615784] accuracy[87.26] precision[0.0] recall[0.0] specificity[97.16] F1 score[0]\n",
      "[2174/5002] final loss [0.2137259840965271] accuracy[87.23] precision[0.0] recall[0.0] specificity[95.22] F1 score[0]\n",
      "[2175/5002] final loss [0.34549006819725037] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2176/5002] final loss [0.18752369284629822] accuracy[89.53] precision[20.0] recall[16.67] specificity[95.0] F1 score[0.18]\n",
      "[2177/5002] final loss [0.03038705326616764] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2178/5002] final loss [0.10363122820854187] accuracy[89.6] precision[0.0] recall[0.0] specificity[91.88] F1 score[0]\n",
      "[2179/5002] final loss [0.02245349809527397] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[2180/5002] final loss [0.09883098304271698] accuracy[86.72] precision[0.0] recall[0.0] specificity[93.28] F1 score[0]\n",
      "[2181/5002] final loss [0.08115790784358978] accuracy[92.31] precision[12.5] recall[20.0] specificity[94.93] F1 score[0.15]\n",
      "[2182/5002] final loss [0.19069895148277283] accuracy[90.62] precision[33.33] recall[50.0] specificity[93.33] F1 score[0.4]\n",
      "[2183/5002] final loss [0.040364429354667664] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[2184/5002] final loss [0.1647161990404129] accuracy[94.17] precision[0.0] recall[0.0] specificity[96.04] F1 score[0]\n",
      "[2185/5002] final loss [0.07406144589185715] accuracy[95.37] precision[0.0] recall[0.0] specificity[98.1] F1 score[0]\n",
      "[2186/5002] final loss [0.14891546964645386] accuracy[84.17] precision[50.0] recall[45.45] specificity[91.45] F1 score[0.48]\n",
      "[2187/5002] final loss [0.05736396089196205] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2188/5002] final loss [0.14987410604953766] accuracy[81.32] precision[0.0] recall[0.0] specificity[89.16] F1 score[0]\n",
      "[2189/5002] final loss [0.01563614420592785] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2190/5002] final loss [0.10552871227264404] accuracy[90.0] precision[0.0] recall[0.0] specificity[91.3] F1 score[0]\n",
      "[2191/5002] final loss [0.19385337829589844] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[2192/5002] final loss [0.07334379106760025] accuracy[80.95] precision[66.67] recall[22.22] specificity[96.97] F1 score[0.33]\n",
      "[2193/5002] final loss [0.09931381046772003] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[2194/5002] final loss [0.12389770895242691] accuracy[84.88] precision[16.67] recall[11.11] specificity[93.51] F1 score[0.13]\n",
      "[2195/5002] final loss [0.06428956985473633] accuracy[85.33] precision[0.0] recall[0.0] specificity[92.75] F1 score[0]\n",
      "[2196/5002] final loss [0.04897400364279747] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[2197/5002] final loss [0.24822625517845154] accuracy[80.95] precision[50.0] recall[25.0] specificity[94.12] F1 score[0.33]\n",
      "[2198/5002] final loss [0.11008362472057343] accuracy[92.31] precision[0.0] recall[0.0] specificity[94.88] F1 score[0]\n",
      "[2199/5002] final loss [0.10275686532258987] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2200/5002] final loss [0.16882392764091492] accuracy[89.78] precision[10.0] recall[16.67] specificity[93.13] F1 score[0.13]\n",
      "[2201/5002] final loss [0.09692350775003433] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[2202/5002] final loss [0.2981354892253876] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2203/5002] final loss [0.069009929895401] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2204/5002] final loss [0.19335472583770752] accuracy[81.55] precision[21.43] recall[27.27] specificity[88.04] F1 score[0.24]\n",
      "[2205/5002] final loss [0.09948200732469559] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[2206/5002] final loss [0.3231571316719055] accuracy[93.81] precision[0.0] recall[0] specificity[93.81] F1 score[0]\n",
      "[2207/5002] final loss [0.17909564077854156] accuracy[91.67] precision[15.38] recall[14.29] specificity[95.8] F1 score[0.15]\n",
      "[2208/5002] final loss [0.07159645855426788] accuracy[91.89] precision[0.0] recall[0.0] specificity[97.14] F1 score[0]\n",
      "[2209/5002] final loss [0.04453763738274574] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2210/5002] final loss [0.036619581282138824] accuracy[96.32] precision[0.0] recall[0] specificity[96.32] F1 score[0]\n",
      "[2211/5002] final loss [0.0508280023932457] accuracy[84.62] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2212/5002] final loss [0.044334445148706436] accuracy[80.0] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[2213/5002] final loss [0.10634207725524902] accuracy[88.46] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[2214/5002] final loss [0.03660972788929939] accuracy[91.94] precision[0.0] recall[0.0] specificity[93.44] F1 score[0]\n",
      "[2215/5002] final loss [0.17158757150173187] accuracy[94.08] precision[0.0] recall[0.0] specificity[95.33] F1 score[0]\n",
      "[2216/5002] final loss [0.018763819709420204] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2217/5002] final loss [0.0917247012257576] accuracy[92.86] precision[20.0] recall[100.0] specificity[92.73] F1 score[0.33]\n",
      "[2218/5002] final loss [0.04061204567551613] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2219/5002] final loss [0.23718151450157166] accuracy[90.32] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[2220/5002] final loss [0.16249552369117737] accuracy[91.67] precision[12.5] recall[33.33] specificity[93.33] F1 score[0.18]\n",
      "[2221/5002] final loss [0.09640616178512573] accuracy[94.17] precision[0.0] recall[0.0] specificity[96.04] F1 score[0]\n",
      "[2222/5002] final loss [0.13420747220516205] accuracy[89.21] precision[0.0] recall[0.0] specificity[92.54] F1 score[0]\n",
      "[2223/5002] final loss [0.1318085491657257] accuracy[88.46] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[2224/5002] final loss [0.3130083680152893] accuracy[91.25] precision[0.0] recall[0.0] specificity[93.59] F1 score[0]\n",
      "[2225/5002] final loss [0.10862278193235397] accuracy[93.71] precision[0.0] recall[0] specificity[93.71] F1 score[0]\n",
      "[2226/5002] final loss [0.202379047870636] accuracy[89.66] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[2227/5002] final loss [0.057716596871614456] accuracy[92.66] precision[33.33] recall[33.33] specificity[96.12] F1 score[0.33]\n",
      "[2228/5002] final loss [0.08369316905736923] accuracy[73.63] precision[40.0] recall[18.18] specificity[91.3] F1 score[0.25]\n",
      "[2229/5002] final loss [0.1948145627975464] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[2230/5002] final loss [0.12379464507102966] accuracy[75.0] precision[40.0] recall[11.11] specificity[94.83] F1 score[0.17]\n",
      "[2231/5002] final loss [0.01680012047290802] accuracy[98.25] precision[0.0] recall[0] specificity[98.25] F1 score[0]\n",
      "[2232/5002] final loss [0.12619970738887787] accuracy[92.23] precision[25.0] recall[16.67] specificity[96.91] F1 score[0.2]\n",
      "[2233/5002] final loss [0.220938041806221] accuracy[95.15] precision[20.0] recall[50.0] specificity[96.04] F1 score[0.29]\n",
      "[2234/5002] final loss [0.2517218589782715] accuracy[93.55] precision[33.33] recall[33.33] specificity[96.61] F1 score[0.33]\n",
      "[2235/5002] final loss [0.19519966840744019] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2236/5002] final loss [0.2998960614204407] accuracy[85.99] precision[8.0] recall[8.7] specificity[92.1] F1 score[0.08]\n",
      "[2237/5002] final loss [0.19612304866313934] accuracy[84.31] precision[0.0] recall[0.0] specificity[91.49] F1 score[0]\n",
      "[2238/5002] final loss [0.013261696323752403] accuracy[94.95] precision[16.67] recall[100.0] specificity[94.9] F1 score[0.29]\n",
      "[2239/5002] final loss [0.12483730912208557] accuracy[88.89] precision[10.0] recall[12.5] specificity[93.38] F1 score[0.11]\n",
      "[2240/5002] final loss [0.013420416973531246] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2241/5002] final loss [0.22858428955078125] accuracy[97.4] precision[0.0] recall[0] specificity[97.4] F1 score[0]\n",
      "[2242/5002] final loss [0.14516183733940125] accuracy[82.9] precision[14.29] recall[12.12] specificity[91.34] F1 score[0.13]\n",
      "[2243/5002] final loss [0.1301792412996292] accuracy[88.24] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[2244/5002] final loss [0.08054492622613907] accuracy[95.06] precision[0.0] recall[0.0] specificity[96.25] F1 score[0]\n",
      "[2245/5002] final loss [0.014998848550021648] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2246/5002] final loss [0.11104264855384827] accuracy[93.72] precision[8.33] recall[33.33] specificity[94.61] F1 score[0.13]\n",
      "[2247/5002] final loss [0.0791766494512558] accuracy[94.48] precision[20.0] recall[50.0] specificity[95.48] F1 score[0.29]\n",
      "[2248/5002] final loss [0.49647998809814453] accuracy[89.66] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[2249/5002] final loss [0.048057302832603455] accuracy[87.93] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[2250/5002] final loss [0.08525323122739792] accuracy[84.96] precision[50.0] recall[11.76] specificity[97.92] F1 score[0.19]\n",
      "[2251/5002] final loss [0.028038213029503822] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2252/5002] final loss [0.1193951889872551] accuracy[89.76] precision[0.0] recall[0.0] specificity[94.9] F1 score[0]\n",
      "[2253/5002] final loss [0.13709527254104614] accuracy[84.3] precision[25.0] recall[13.33] specificity[94.34] F1 score[0.17]\n",
      "[2254/5002] final loss [0.142203688621521] accuracy[89.77] precision[0.0] recall[0.0] specificity[92.34] F1 score[0]\n",
      "[2255/5002] final loss [0.020229101181030273] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2256/5002] final loss [0.039580512791872025] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[2257/5002] final loss [0.052033837884664536] accuracy[89.38] precision[0.0] recall[0.0] specificity[95.28] F1 score[0]\n",
      "[2258/5002] final loss [0.20896963775157928] accuracy[86.34] precision[23.08] recall[20.0] specificity[93.15] F1 score[0.21]\n",
      "[2259/5002] final loss [0.1500292718410492] accuracy[82.05] precision[25.0] recall[13.64] specificity[93.28] F1 score[0.18]\n",
      "[2260/5002] final loss [0.077694371342659] accuracy[93.81] precision[33.33] recall[50.0] specificity[95.7] F1 score[0.4]\n",
      "[2261/5002] final loss [0.06697101891040802] accuracy[94.55] precision[50.0] recall[16.67] specificity[99.04] F1 score[0.25]\n",
      "[2262/5002] final loss [0.0915651023387909] accuracy[95.5] precision[0.0] recall[0] specificity[95.5] F1 score[0]\n",
      "[2263/5002] final loss [0.205129012465477] accuracy[93.98] precision[0.0] recall[0.0] specificity[94.7] F1 score[0]\n",
      "[2264/5002] final loss [0.07211440056562424] accuracy[83.33] precision[0.0] recall[0.0] specificity[91.95] F1 score[0]\n",
      "[2265/5002] final loss [0.056882474571466446] accuracy[83.33] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[2266/5002] final loss [0.2181888073682785] accuracy[92.44] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[2267/5002] final loss [0.07995984703302383] accuracy[92.42] precision[0.0] recall[0.0] specificity[93.85] F1 score[0]\n",
      "[2268/5002] final loss [0.15013691782951355] accuracy[94.52] precision[0.0] recall[0] specificity[94.52] F1 score[0]\n",
      "[2269/5002] final loss [0.0917036160826683] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[2270/5002] final loss [0.15198856592178345] accuracy[89.8] precision[0.0] recall[0] specificity[89.8] F1 score[0]\n",
      "[2271/5002] final loss [0.11289945244789124] accuracy[88.57] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[2272/5002] final loss [0.0974704921245575] accuracy[89.31] precision[0.0] recall[0.0] specificity[91.41] F1 score[0]\n",
      "[2273/5002] final loss [0.45813801884651184] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2274/5002] final loss [0.3193144202232361] accuracy[94.93] precision[0.0] recall[0] specificity[94.93] F1 score[0]\n",
      "[2275/5002] final loss [0.1900380402803421] accuracy[82.03] precision[25.0] recall[38.46] specificity[86.96] F1 score[0.3]\n",
      "[2276/5002] final loss [0.16999587416648865] accuracy[91.18] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[2277/5002] final loss [0.277011513710022] accuracy[82.84] precision[6.45] recall[6.45] specificity[90.55] F1 score[0.06]\n",
      "[2278/5002] final loss [0.1553432047367096] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2279/5002] final loss [0.28463214635849] accuracy[90.75] precision[28.57] recall[40.0] specificity[93.87] F1 score[0.33]\n",
      "[2280/5002] final loss [0.1000845804810524] accuracy[92.86] precision[0.0] recall[0.0] specificity[98.73] F1 score[0]\n",
      "[2281/5002] final loss [0.13541370630264282] accuracy[90.7] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[2282/5002] final loss [0.1387600153684616] accuracy[92.69] precision[6.67] recall[33.33] specificity[93.52] F1 score[0.11]\n",
      "[2283/5002] final loss [0.012995690107345581] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2284/5002] final loss [0.06330479681491852] accuracy[85.42] precision[0.0] recall[0.0] specificity[91.11] F1 score[0]\n",
      "[2285/5002] final loss [0.14862219989299774] accuracy[92.42] precision[0.0] recall[0.0] specificity[93.13] F1 score[0]\n",
      "[2286/5002] final loss [0.11592680215835571] accuracy[85.95] precision[5.26] recall[11.11] specificity[89.77] F1 score[0.07]\n",
      "[2287/5002] final loss [0.08079853653907776] accuracy[94.16] precision[0.0] recall[0] specificity[94.16] F1 score[0]\n",
      "[2288/5002] final loss [0.17993660271167755] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2289/5002] final loss [0.12862339615821838] accuracy[84.72] precision[33.33] recall[10.0] specificity[96.77] F1 score[0.15]\n",
      "[2290/5002] final loss [0.2608868181705475] accuracy[90.41] precision[10.0] recall[16.67] specificity[93.57] F1 score[0.13]\n",
      "[2291/5002] final loss [0.07069485634565353] accuracy[94.25] precision[0.0] recall[0.0] specificity[96.47] F1 score[0]\n",
      "[2292/5002] final loss [0.03527301922440529] accuracy[94.17] precision[50.0] recall[42.86] specificity[97.35] F1 score[0.46]\n",
      "[2293/5002] final loss [0.13349035382270813] accuracy[93.16] precision[20.0] recall[100.0] specificity[93.04] F1 score[0.33]\n",
      "[2294/5002] final loss [0.1599465310573578] accuracy[89.78] precision[18.18] recall[44.44] specificity[91.67] F1 score[0.26]\n",
      "[2295/5002] final loss [0.057887353003025055] accuracy[91.23] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[2296/5002] final loss [0.1678023785352707] accuracy[88.66] precision[12.5] recall[20.0] specificity[92.39] F1 score[0.15]\n",
      "[2297/5002] final loss [0.07431990653276443] accuracy[78.95] precision[42.86] recall[13.04] specificity[95.6] F1 score[0.2]\n",
      "[2298/5002] final loss [0.1586301624774933] accuracy[97.01] precision[33.33] recall[100.0] specificity[96.97] F1 score[0.5]\n",
      "[2299/5002] final loss [0.003266321262344718] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2300/5002] final loss [0.16082938015460968] accuracy[88.79] precision[0.0] recall[0.0] specificity[97.17] F1 score[0]\n",
      "[2301/5002] final loss [0.055033549666404724] accuracy[92.9] precision[0.0] recall[0] specificity[92.9] F1 score[0]\n",
      "[2302/5002] final loss [0.022595740854740143] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2303/5002] final loss [0.12310905009508133] accuracy[96.61] precision[14.29] recall[100.0] specificity[96.59] F1 score[0.25]\n",
      "[2304/5002] final loss [0.19910062849521637] accuracy[89.19] precision[0.0] recall[0.0] specificity[97.06] F1 score[0]\n",
      "[2305/5002] final loss [0.10534615069627762] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[2306/5002] final loss [0.07224483788013458] accuracy[90.91] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[2307/5002] final loss [0.25523117184638977] accuracy[92.31] precision[7.41] recall[18.18] specificity[94.2] F1 score[0.11]\n",
      "[2308/5002] final loss [0.17501085996627808] accuracy[89.05] precision[15.38] recall[14.29] specificity[94.39] F1 score[0.15]\n",
      "[2309/5002] final loss [0.090556800365448] accuracy[83.33] precision[0.0] recall[0.0] specificity[88.24] F1 score[0]\n",
      "[2310/5002] final loss [0.09441565722227097] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[2311/5002] final loss [0.09169907122850418] accuracy[92.45] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[2312/5002] final loss [0.4886818826198578] accuracy[95.83] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2313/5002] final loss [0.07129936665296555] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[2314/5002] final loss [0.1762091964483261] accuracy[93.7] precision[0.0] recall[0.0] specificity[94.51] F1 score[0]\n",
      "[2315/5002] final loss [0.38390663266181946] accuracy[87.1] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[2316/5002] final loss [0.01928013749420643] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[2317/5002] final loss [0.04360383749008179] accuracy[90.24] precision[0.0] recall[0] specificity[90.24] F1 score[0]\n",
      "[2318/5002] final loss [0.07378165423870087] accuracy[86.89] precision[17.39] recall[10.26] specificity[94.91] F1 score[0.13]\n",
      "[2319/5002] final loss [0.10286182165145874] accuracy[86.96] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[2320/5002] final loss [0.26714277267456055] accuracy[85.47] precision[25.0] recall[6.67] specificity[97.06] F1 score[0.11]\n",
      "[2321/5002] final loss [0.20665612816810608] accuracy[93.58] precision[0.0] recall[0.0] specificity[94.09] F1 score[0]\n",
      "[2322/5002] final loss [0.016151919960975647] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[2323/5002] final loss [0.30432671308517456] accuracy[91.09] precision[6.25] recall[12.5] specificity[93.72] F1 score[0.08]\n",
      "[2324/5002] final loss [0.03833818435668945] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[2325/5002] final loss [0.056153178215026855] accuracy[94.94] precision[0.0] recall[0] specificity[94.94] F1 score[0]\n",
      "[2326/5002] final loss [0.05242311954498291] accuracy[95.0] precision[11.11] recall[100.0] specificity[94.97] F1 score[0.2]\n",
      "[2327/5002] final loss [0.04746922478079796] accuracy[83.58] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[2328/5002] final loss [0.052517540752887726] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2329/5002] final loss [0.01397730503231287] accuracy[94.23] precision[0.0] recall[0] specificity[94.23] F1 score[0]\n",
      "[2330/5002] final loss [0.1307605355978012] accuracy[94.29] precision[16.67] recall[50.0] specificity[95.15] F1 score[0.25]\n",
      "[2331/5002] final loss [0.21146652102470398] accuracy[92.16] precision[0.0] recall[0.0] specificity[93.07] F1 score[0]\n",
      "[2332/5002] final loss [0.13648518919944763] accuracy[93.62] precision[33.33] recall[50.0] specificity[95.56] F1 score[0.4]\n",
      "[2333/5002] final loss [0.13143159449100494] accuracy[82.32] precision[23.08] recall[13.64] specificity[92.96] F1 score[0.17]\n",
      "[2334/5002] final loss [0.12271421402692795] accuracy[92.86] precision[14.29] recall[25.0] specificity[95.08] F1 score[0.18]\n",
      "[2335/5002] final loss [0.21122056245803833] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2336/5002] final loss [0.10681149363517761] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[2337/5002] final loss [0.15092261135578156] accuracy[92.51] precision[6.67] recall[100.0] specificity[92.47] F1 score[0.13]\n",
      "[2338/5002] final loss [0.13443221151828766] accuracy[85.19] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[2339/5002] final loss [0.11405467987060547] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2340/5002] final loss [0.08819489181041718] accuracy[87.88] precision[0.0] recall[0.0] specificity[92.06] F1 score[0]\n",
      "[2341/5002] final loss [0.18214507400989532] accuracy[95.79] precision[0.0] recall[0] specificity[95.79] F1 score[0]\n",
      "[2342/5002] final loss [0.10908015072345734] accuracy[95.65] precision[50.0] recall[100.0] specificity[95.45] F1 score[0.67]\n",
      "[2343/5002] final loss [0.06625388562679291] accuracy[97.76] precision[25.0] recall[100.0] specificity[97.74] F1 score[0.4]\n",
      "[2344/5002] final loss [0.2275836020708084] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[2345/5002] final loss [0.0002527309115976095] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2346/5002] final loss [0.09312354028224945] accuracy[90.98] precision[14.29] recall[16.67] specificity[94.83] F1 score[0.15]\n",
      "[2347/5002] final loss [0.059614140540361404] accuracy[90.38] precision[11.76] recall[20.0] specificity[93.45] F1 score[0.15]\n",
      "[2348/5002] final loss [0.11541352421045303] accuracy[94.12] precision[25.0] recall[50.0] specificity[95.45] F1 score[0.33]\n",
      "[2349/5002] final loss [0.06720071285963058] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[2350/5002] final loss [0.29420238733291626] accuracy[91.39] precision[10.0] recall[20.0] specificity[93.84] F1 score[0.13]\n",
      "[2351/5002] final loss [0.13621194660663605] accuracy[89.22] precision[10.0] recall[10.0] specificity[94.27] F1 score[0.1]\n",
      "[2352/5002] final loss [0.03179164230823517] accuracy[90.62] precision[16.67] recall[50.0] specificity[91.94] F1 score[0.25]\n",
      "[2353/5002] final loss [0.11203256994485855] accuracy[97.22] precision[50.0] recall[33.33] specificity[99.05] F1 score[0.4]\n",
      "[2354/5002] final loss [0.05009699612855911] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[2355/5002] final loss [0.24532479047775269] accuracy[88.73] precision[0.0] recall[0] specificity[88.73] F1 score[0]\n",
      "[2356/5002] final loss [0.09956379234790802] accuracy[89.23] precision[0.0] recall[0.0] specificity[90.62] F1 score[0]\n",
      "[2357/5002] final loss [0.18168076872825623] accuracy[90.32] precision[50.0] recall[22.22] specificity[97.62] F1 score[0.31]\n",
      "[2358/5002] final loss [0.125555619597435] accuracy[94.74] precision[16.67] recall[25.0] specificity[96.62] F1 score[0.2]\n",
      "[2359/5002] final loss [0.12899945676326752] accuracy[89.16] precision[20.0] recall[16.67] specificity[94.81] F1 score[0.18]\n",
      "[2360/5002] final loss [0.17867982387542725] accuracy[72.41] precision[85.71] recall[28.57] specificity[97.3] F1 score[0.43]\n",
      "[2361/5002] final loss [0.052871495485305786] accuracy[93.88] precision[50.0] recall[33.33] specificity[97.83] F1 score[0.4]\n",
      "[2362/5002] final loss [0.03446920961141586] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[2363/5002] final loss [0.01020548865199089] accuracy[95.45] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[2364/5002] final loss [0.08287443965673447] accuracy[82.35] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[2365/5002] final loss [0.10371720790863037] accuracy[89.92] precision[0.0] recall[0.0] specificity[94.69] F1 score[0]\n",
      "[2366/5002] final loss [0.22126924991607666] accuracy[87.84] precision[30.0] recall[21.43] specificity[94.78] F1 score[0.25]\n",
      "[2367/5002] final loss [0.014894741587340832] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2368/5002] final loss [0.04091827571392059] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2369/5002] final loss [0.16183054447174072] accuracy[89.49] precision[5.88] recall[7.69] specificity[93.69] F1 score[0.07]\n",
      "[2370/5002] final loss [0.0135521050542593] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[2371/5002] final loss [0.11400167644023895] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[2372/5002] final loss [0.030975261703133583] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[2373/5002] final loss [0.19303056597709656] accuracy[82.5] precision[0.0] recall[0.0] specificity[88.0] F1 score[0]\n",
      "[2374/5002] final loss [0.04202346131205559] accuracy[94.81] precision[0.0] recall[0.0] specificity[95.42] F1 score[0]\n",
      "[2375/5002] final loss [0.07696732133626938] accuracy[90.32] precision[33.33] recall[50.0] specificity[93.1] F1 score[0.4]\n",
      "[2376/5002] final loss [0.03191785141825676] accuracy[88.24] precision[50.0] recall[25.0] specificity[96.67] F1 score[0.33]\n",
      "[2377/5002] final loss [0.07672882080078125] accuracy[86.5] precision[26.67] recall[26.67] specificity[92.57] F1 score[0.27]\n",
      "[2378/5002] final loss [0.032740965485572815] accuracy[79.17] precision[40.0] recall[14.29] specificity[94.83] F1 score[0.21]\n",
      "[2379/5002] final loss [0.027756666764616966] accuracy[86.57] precision[50.0] recall[11.11] specificity[98.28] F1 score[0.18]\n",
      "[2380/5002] final loss [0.03997565060853958] accuracy[87.8] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[2381/5002] final loss [0.12947089970111847] accuracy[97.83] precision[0.0] recall[0] specificity[97.83] F1 score[0]\n",
      "[2382/5002] final loss [0.1081816777586937] accuracy[89.47] precision[20.0] recall[20.0] specificity[94.37] F1 score[0.2]\n",
      "[2383/5002] final loss [0.13081976771354675] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[2384/5002] final loss [0.15861928462982178] accuracy[90.12] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[2385/5002] final loss [0.027804234996438026] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2386/5002] final loss [0.08375951647758484] accuracy[91.09] precision[0.0] recall[0.0] specificity[93.88] F1 score[0]\n",
      "[2387/5002] final loss [0.22721679508686066] accuracy[81.92] precision[11.63] recall[15.15] specificity[88.55] F1 score[0.13]\n",
      "[2388/5002] final loss [0.06739728897809982] accuracy[86.79] precision[11.11] recall[7.14] specificity[94.48] F1 score[0.09]\n",
      "[2389/5002] final loss [0.11116397380828857] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[2390/5002] final loss [0.12698571383953094] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2391/5002] final loss [0.12241365015506744] accuracy[88.89] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[2392/5002] final loss [0.259471595287323] accuracy[93.22] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[2393/5002] final loss [0.07409422099590302] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[2394/5002] final loss [0.09688976407051086] accuracy[75.0] precision[0.0] recall[0] specificity[75.0] F1 score[0]\n",
      "[2395/5002] final loss [0.18498779833316803] accuracy[89.22] precision[11.11] recall[25.0] specificity[91.84] F1 score[0.15]\n",
      "[2396/5002] final loss [0.09482070058584213] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2397/5002] final loss [0.013857545331120491] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2398/5002] final loss [0.07482607662677765] accuracy[86.79] precision[0.0] recall[0.0] specificity[95.83] F1 score[0]\n",
      "[2399/5002] final loss [0.12577137351036072] accuracy[91.86] precision[0.0] recall[0.0] specificity[92.94] F1 score[0]\n",
      "[2400/5002] final loss [0.050665128976106644] accuracy[94.5] precision[0.0] recall[0] specificity[94.5] F1 score[0]\n",
      "[2401/5002] final loss [0.15674428641796112] accuracy[91.3] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[2402/5002] final loss [0.13879439234733582] accuracy[99.07] precision[0.0] recall[0] specificity[99.07] F1 score[0]\n",
      "[2403/5002] final loss [0.07056411355733871] accuracy[87.65] precision[25.0] recall[12.5] specificity[95.89] F1 score[0.17]\n",
      "[2404/5002] final loss [0.2356366515159607] accuracy[92.42] precision[0.0] recall[0.0] specificity[95.59] F1 score[0]\n",
      "[2405/5002] final loss [0.09173964709043503] accuracy[91.4] precision[0.0] recall[0.0] specificity[93.41] F1 score[0]\n",
      "[2406/5002] final loss [0.15372301638126373] accuracy[95.06] precision[0.0] recall[0] specificity[95.06] F1 score[0]\n",
      "[2407/5002] final loss [0.1180073693394661] accuracy[92.75] precision[10.0] recall[50.0] specificity[93.38] F1 score[0.17]\n",
      "[2408/5002] final loss [0.2505347728729248] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2409/5002] final loss [0.09647958725690842] accuracy[92.05] precision[14.29] recall[50.0] specificity[93.02] F1 score[0.22]\n",
      "[2410/5002] final loss [0.1736302226781845] accuracy[75.0] precision[54.55] recall[16.22] specificity[95.33] F1 score[0.25]\n",
      "[2411/5002] final loss [0.16087569296360016] accuracy[91.75] precision[25.0] recall[16.67] specificity[96.7] F1 score[0.2]\n",
      "[2412/5002] final loss [0.1392279416322708] accuracy[83.58] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[2413/5002] final loss [0.1448468565940857] accuracy[87.5] precision[0.0] recall[0.0] specificity[92.97] F1 score[0]\n",
      "[2414/5002] final loss [0.059300199151039124] accuracy[95.65] precision[20.0] recall[100.0] specificity[95.6] F1 score[0.33]\n",
      "[2415/5002] final loss [0.05570034310221672] accuracy[94.07] precision[0.0] recall[0.0] specificity[95.49] F1 score[0]\n",
      "[2416/5002] final loss [0.18716509640216827] accuracy[89.72] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[2417/5002] final loss [0.06926005333662033] accuracy[92.98] precision[0.0] recall[0] specificity[92.98] F1 score[0]\n",
      "[2418/5002] final loss [0.13153833150863647] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2419/5002] final loss [0.05965793877840042] accuracy[90.53] precision[0.0] recall[0.0] specificity[94.51] F1 score[0]\n",
      "[2420/5002] final loss [0.12656958401203156] accuracy[88.16] precision[20.0] recall[16.67] specificity[94.29] F1 score[0.18]\n",
      "[2421/5002] final loss [0.09941180795431137] accuracy[96.09] precision[0.0] recall[0] specificity[96.09] F1 score[0]\n",
      "[2422/5002] final loss [0.11564648896455765] accuracy[92.64] precision[0.0] recall[0.0] specificity[93.36] F1 score[0]\n",
      "[2423/5002] final loss [0.09977211803197861] accuracy[93.0] precision[0.0] recall[0.0] specificity[95.88] F1 score[0]\n",
      "[2424/5002] final loss [0.4377533793449402] accuracy[91.96] precision[8.33] recall[12.5] specificity[94.91] F1 score[0.1]\n",
      "[2425/5002] final loss [0.283649206161499] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[2426/5002] final loss [0.10806232690811157] accuracy[94.5] precision[62.5] recall[62.5] specificity[97.03] F1 score[0.62]\n",
      "[2427/5002] final loss [0.4007866084575653] accuracy[89.36] precision[50.0] recall[20.0] specificity[97.62] F1 score[0.29]\n",
      "[2428/5002] final loss [0.2504843771457672] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[2429/5002] final loss [0.05969476327300072] accuracy[84.27] precision[16.67] recall[33.33] specificity[87.95] F1 score[0.22]\n",
      "[2430/5002] final loss [0.09488262236118317] accuracy[90.77] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[2431/5002] final loss [0.06328972429037094] accuracy[78.57] precision[75.0] recall[21.43] specificity[97.62] F1 score[0.33]\n",
      "[2432/5002] final loss [0.08019132912158966] accuracy[85.88] precision[0.0] recall[0.0] specificity[92.41] F1 score[0]\n",
      "[2433/5002] final loss [0.30187952518463135] accuracy[83.14] precision[5.0] recall[9.09] specificity[88.2] F1 score[0.06]\n",
      "[2434/5002] final loss [0.3222578763961792] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2435/5002] final loss [0.04967724159359932] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[2436/5002] final loss [0.03550904989242554] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2437/5002] final loss [0.10059220343828201] accuracy[88.36] precision[0.0] recall[0.0] specificity[93.82] F1 score[0]\n",
      "[2438/5002] final loss [0.05723676458001137] accuracy[98.15] precision[0.0] recall[0] specificity[98.15] F1 score[0]\n",
      "[2439/5002] final loss [0.12152311205863953] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[2440/5002] final loss [0.12847185134887695] accuracy[90.91] precision[8.33] recall[25.0] specificity[92.67] F1 score[0.12]\n",
      "[2441/5002] final loss [0.14140085875988007] accuracy[96.1] precision[0.0] recall[0] specificity[96.1] F1 score[0]\n",
      "[2442/5002] final loss [0.2023283839225769] accuracy[94.59] precision[14.29] recall[100.0] specificity[94.55] F1 score[0.25]\n",
      "[2443/5002] final loss [0.23290883004665375] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2444/5002] final loss [0.10247497260570526] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[2445/5002] final loss [0.14046764373779297] accuracy[95.24] precision[50.0] recall[100.0] specificity[95.0] F1 score[0.67]\n",
      "[2446/5002] final loss [0.12649330496788025] accuracy[91.35] precision[0.0] recall[0.0] specificity[92.23] F1 score[0]\n",
      "[2447/5002] final loss [0.15345162153244019] accuracy[91.3] precision[18.18] recall[22.22] specificity[94.86] F1 score[0.2]\n",
      "[2448/5002] final loss [0.005775910802185535] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2449/5002] final loss [0.11657855659723282] accuracy[93.48] precision[33.33] recall[50.0] specificity[95.45] F1 score[0.4]\n",
      "[2450/5002] final loss [0.545032799243927] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[2451/5002] final loss [0.1022537350654602] accuracy[89.13] precision[33.33] recall[25.0] specificity[95.24] F1 score[0.29]\n",
      "[2452/5002] final loss [0.20738816261291504] accuracy[84.85] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[2453/5002] final loss [0.08678587526082993] accuracy[94.04] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[2454/5002] final loss [0.22450868785381317] accuracy[88.71] precision[22.22] recall[22.22] specificity[93.91] F1 score[0.22]\n",
      "[2455/5002] final loss [0.13404183089733124] accuracy[88.08] precision[13.64] recall[20.0] specificity[92.24] F1 score[0.16]\n",
      "[2456/5002] final loss [0.11484143882989883] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[2457/5002] final loss [0.024626532569527626] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2458/5002] final loss [0.08968255668878555] accuracy[87.8] precision[4.76] recall[100.0] specificity[87.73] F1 score[0.09]\n",
      "[2459/5002] final loss [0.05971893295645714] accuracy[79.31] precision[14.29] recall[7.69] specificity[91.89] F1 score[0.1]\n",
      "[2460/5002] final loss [0.14075207710266113] accuracy[88.89] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[2461/5002] final loss [0.07308641821146011] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2462/5002] final loss [0.1651323139667511] accuracy[94.55] precision[0.0] recall[0] specificity[94.55] F1 score[0]\n",
      "[2463/5002] final loss [0.08303899317979813] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[2464/5002] final loss [0.2002529352903366] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2465/5002] final loss [0.07152462005615234] accuracy[89.29] precision[100.0] recall[25.0] specificity[100.0] F1 score[0.4]\n",
      "[2466/5002] final loss [0.0684857964515686] accuracy[97.5] precision[0.0] recall[0.0] specificity[98.73] F1 score[0]\n",
      "[2467/5002] final loss [0.13046051561832428] accuracy[79.31] precision[20.0] recall[11.11] specificity[91.84] F1 score[0.14]\n",
      "[2468/5002] final loss [0.06662256270647049] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[2469/5002] final loss [0.13191844522953033] accuracy[76.36] precision[25.0] recall[22.22] specificity[86.96] F1 score[0.24]\n",
      "[2470/5002] final loss [0.2177116870880127] accuracy[97.14] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[2471/5002] final loss [0.0029646011535078287] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2472/5002] final loss [0.22022642195224762] accuracy[82.97] precision[30.0] recall[15.38] specificity[94.09] F1 score[0.2]\n",
      "[2473/5002] final loss [0.06726431846618652] accuracy[94.52] precision[0.0] recall[0.0] specificity[97.18] F1 score[0]\n",
      "[2474/5002] final loss [0.0695594921708107] accuracy[96.99] precision[0.0] recall[0] specificity[96.99] F1 score[0]\n",
      "[2475/5002] final loss [0.08951695263385773] accuracy[85.11] precision[33.33] recall[16.67] specificity[95.12] F1 score[0.22]\n",
      "[2476/5002] final loss [0.03535621240735054] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2477/5002] final loss [0.06476789712905884] accuracy[89.91] precision[20.0] recall[12.5] specificity[96.04] F1 score[0.15]\n",
      "[2478/5002] final loss [0.03228101134300232] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[2479/5002] final loss [0.05944028124213219] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2480/5002] final loss [0.0061929658986628056] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2481/5002] final loss [0.08926927298307419] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2482/5002] final loss [0.2527940571308136] accuracy[89.84] precision[21.43] recall[27.27] specificity[93.75] F1 score[0.24]\n",
      "[2483/5002] final loss [0.027989502996206284] accuracy[91.89] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[2484/5002] final loss [0.09721478819847107] accuracy[90.0] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[2485/5002] final loss [0.05395505949854851] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[2486/5002] final loss [0.07702374458312988] accuracy[92.31] precision[14.29] recall[50.0] specificity[93.26] F1 score[0.22]\n",
      "[2487/5002] final loss [0.11999281495809555] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2488/5002] final loss [0.07102544605731964] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[2489/5002] final loss [0.09539543837308884] accuracy[93.28] precision[0.0] recall[0.0] specificity[94.07] F1 score[0]\n",
      "[2490/5002] final loss [0.20226852595806122] accuracy[92.81] precision[0.0] recall[0.0] specificity[93.37] F1 score[0]\n",
      "[2491/5002] final loss [0.027881136164069176] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[2492/5002] final loss [0.11122068762779236] accuracy[89.77] precision[0.0] recall[0.0] specificity[96.34] F1 score[0]\n",
      "[2493/5002] final loss [0.12656307220458984] accuracy[91.62] precision[11.11] recall[14.29] specificity[95.0] F1 score[0.13]\n",
      "[2494/5002] final loss [0.14532659947872162] accuracy[92.62] precision[0.0] recall[0.0] specificity[95.76] F1 score[0]\n",
      "[2495/5002] final loss [0.07398127019405365] accuracy[95.0] precision[0.0] recall[0.0] specificity[96.61] F1 score[0]\n",
      "[2496/5002] final loss [0.13804659247398376] accuracy[91.35] precision[0.0] recall[0.0] specificity[92.96] F1 score[0]\n",
      "[2497/5002] final loss [0.17468847334384918] accuracy[84.0] precision[25.0] recall[10.0] specificity[95.38] F1 score[0.14]\n",
      "[2498/5002] final loss [0.0650830864906311] accuracy[86.59] precision[33.33] recall[22.22] specificity[94.52] F1 score[0.27]\n",
      "[2499/5002] final loss [0.13190396130084991] accuracy[82.58] precision[0.0] recall[0.0] specificity[93.63] F1 score[0]\n",
      "[2500/5002] final loss [0.018585409969091415] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[2501/5002] final loss [0.04596558213233948] accuracy[88.03] precision[0.0] recall[0.0] specificity[96.26] F1 score[0]\n",
      "[2502/5002] final loss [0.11125878244638443] accuracy[95.89] precision[0.0] recall[0] specificity[95.89] F1 score[0]\n",
      "[2503/5002] final loss [0.17062748968601227] accuracy[91.84] precision[0.0] recall[0.0] specificity[92.47] F1 score[0]\n",
      "[2504/5002] final loss [0.12163401395082474] accuracy[66.67] precision[16.67] recall[18.18] specificity[78.26] F1 score[0.17]\n",
      "[2505/5002] final loss [0.08469869196414948] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2506/5002] final loss [0.07246296852827072] accuracy[88.24] precision[33.33] recall[20.0] specificity[95.65] F1 score[0.25]\n",
      "[2507/5002] final loss [0.07804315537214279] accuracy[93.1] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[2508/5002] final loss [0.16229192912578583] accuracy[87.72] precision[7.69] recall[5.88] specificity[94.31] F1 score[0.07]\n",
      "[2509/5002] final loss [0.1649247258901596] accuracy[88.57] precision[11.11] recall[7.69] specificity[95.06] F1 score[0.09]\n",
      "[2510/5002] final loss [0.06693415343761444] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2511/5002] final loss [0.021263577044010162] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[2512/5002] final loss [0.08440867066383362] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2513/5002] final loss [0.08784951269626617] accuracy[85.29] precision[9.09] recall[9.09] specificity[92.0] F1 score[0.09]\n",
      "[2514/5002] final loss [0.23869533836841583] accuracy[94.85] precision[20.0] recall[50.0] specificity[95.79] F1 score[0.29]\n",
      "[2515/5002] final loss [0.1800016611814499] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[2516/5002] final loss [0.025082416832447052] accuracy[94.74] precision[0.0] recall[0.0] specificity[97.3] F1 score[0]\n",
      "[2517/5002] final loss [0.05215860530734062] accuracy[82.86] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[2518/5002] final loss [0.07592939585447311] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[2519/5002] final loss [0.1492428332567215] accuracy[92.21] precision[0.0] recall[0.0] specificity[93.42] F1 score[0]\n",
      "[2520/5002] final loss [0.06858515739440918] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2521/5002] final loss [0.2137051522731781] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2522/5002] final loss [0.017555752769112587] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[2523/5002] final loss [0.05215517804026604] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[2524/5002] final loss [0.15268443524837494] accuracy[89.87] precision[0.0] recall[0.0] specificity[93.42] F1 score[0]\n",
      "[2525/5002] final loss [0.14956173300743103] accuracy[89.47] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[2526/5002] final loss [0.13743695616722107] accuracy[89.76] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[2527/5002] final loss [0.19826987385749817] accuracy[86.88] precision[17.86] recall[18.52] specificity[92.72] F1 score[0.18]\n",
      "[2528/5002] final loss [0.05149482190608978] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2529/5002] final loss [0.044472645968198776] accuracy[85.59] precision[11.11] recall[10.0] specificity[92.59] F1 score[0.11]\n",
      "[2530/5002] final loss [0.06782563030719757] accuracy[82.14] precision[0.0] recall[0.0] specificity[88.46] F1 score[0]\n",
      "[2531/5002] final loss [0.15712349116802216] accuracy[88.68] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[2532/5002] final loss [0.04426473379135132] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[2533/5002] final loss [0.03836016356945038] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[2534/5002] final loss [0.14012788236141205] accuracy[83.33] precision[100.0] recall[33.33] specificity[100.0] F1 score[0.5]\n",
      "[2535/5002] final loss [0.025884250178933144] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2536/5002] final loss [0.12846772372722626] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[2537/5002] final loss [0.31526798009872437] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2538/5002] final loss [0.10882695019245148] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[2539/5002] final loss [0.129564568400383] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[2540/5002] final loss [0.04489022120833397] accuracy[95.24] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2541/5002] final loss [0.15547887980937958] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2542/5002] final loss [0.07969927787780762] accuracy[76.92] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[2543/5002] final loss [0.022898603230714798] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2544/5002] final loss [0.10883022099733353] accuracy[93.98] precision[0.0] recall[0] specificity[93.98] F1 score[0]\n",
      "[2545/5002] final loss [0.033044323325157166] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[2546/5002] final loss [0.035591427236795425] accuracy[96.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2547/5002] final loss [0.10778176039457321] accuracy[85.0] precision[0.0] recall[0.0] specificity[89.47] F1 score[0]\n",
      "[2548/5002] final loss [0.16791465878486633] accuracy[95.24] precision[33.33] recall[100.0] specificity[95.12] F1 score[0.5]\n",
      "[2549/5002] final loss [0.0687897577881813] accuracy[85.66] precision[30.77] recall[12.12] specificity[96.12] F1 score[0.17]\n",
      "[2550/5002] final loss [0.1404862254858017] accuracy[77.44] precision[33.33] recall[7.14] specificity[96.19] F1 score[0.12]\n",
      "[2551/5002] final loss [0.16066710650920868] accuracy[90.0] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[2552/5002] final loss [0.017318621277809143] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2553/5002] final loss [0.003029395127668977] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2554/5002] final loss [0.09885047376155853] accuracy[95.31] precision[33.33] recall[50.0] specificity[96.77] F1 score[0.4]\n",
      "[2555/5002] final loss [0.11671663820743561] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2556/5002] final loss [0.15304265916347504] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2557/5002] final loss [0.09286579489707947] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2558/5002] final loss [0.18069683015346527] accuracy[88.79] precision[14.29] recall[14.29] specificity[94.0] F1 score[0.14]\n",
      "[2559/5002] final loss [0.02118821069598198] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2560/5002] final loss [0.11928386986255646] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[2561/5002] final loss [0.09171034395694733] accuracy[97.59] precision[0.0] recall[0] specificity[97.59] F1 score[0]\n",
      "[2562/5002] final loss [0.1119653508067131] accuracy[89.89] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[2563/5002] final loss [0.06503751128911972] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[2564/5002] final loss [0.10049229860305786] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2565/5002] final loss [0.24943186342716217] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[2566/5002] final loss [0.13249292969703674] accuracy[92.86] precision[0.0] recall[0.0] specificity[93.69] F1 score[0]\n",
      "[2567/5002] final loss [0.07530198991298676] accuracy[85.71] precision[33.33] recall[7.69] specificity[97.65] F1 score[0.12]\n",
      "[2568/5002] final loss [0.1395304650068283] accuracy[94.21] precision[0.0] recall[0] specificity[94.21] F1 score[0]\n",
      "[2569/5002] final loss [0.16954848170280457] accuracy[95.45] precision[25.0] recall[50.0] specificity[96.51] F1 score[0.33]\n",
      "[2570/5002] final loss [0.06691132485866547] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2571/5002] final loss [0.01801467314362526] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[2572/5002] final loss [0.16380971670150757] accuracy[89.42] precision[13.04] recall[25.0] specificity[92.37] F1 score[0.17]\n",
      "[2573/5002] final loss [0.040043819695711136] accuracy[92.0] precision[0.0] recall[0.0] specificity[94.52] F1 score[0]\n",
      "[2574/5002] final loss [0.009909856133162975] accuracy[84.24] precision[0.0] recall[0.0] specificity[95.21] F1 score[0]\n",
      "[2575/5002] final loss [0.14916235208511353] accuracy[93.1] precision[25.0] recall[16.67] specificity[97.27] F1 score[0.2]\n",
      "[2576/5002] final loss [0.06386630237102509] accuracy[96.77] precision[0.0] recall[0.0] specificity[98.36] F1 score[0]\n",
      "[2577/5002] final loss [0.18300648033618927] accuracy[88.89] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[2578/5002] final loss [0.18841782212257385] accuracy[83.06] precision[18.18] recall[14.29] specificity[91.82] F1 score[0.16]\n",
      "[2579/5002] final loss [0.217274472117424] accuracy[93.42] precision[16.67] recall[100.0] specificity[93.33] F1 score[0.29]\n",
      "[2580/5002] final loss [0.024731094017624855] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2581/5002] final loss [0.19794411957263947] accuracy[91.67] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[2582/5002] final loss [0.17003542184829712] accuracy[91.11] precision[25.0] recall[50.0] specificity[93.02] F1 score[0.33]\n",
      "[2583/5002] final loss [0.058738309890031815] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2584/5002] final loss [0.1430148184299469] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[2585/5002] final loss [0.05771496146917343] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2586/5002] final loss [0.1467011272907257] accuracy[91.89] precision[33.33] recall[50.0] specificity[94.29] F1 score[0.4]\n",
      "[2587/5002] final loss [0.20232842862606049] accuracy[75.0] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[2588/5002] final loss [0.105092853307724] accuracy[86.67] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[2589/5002] final loss [0.05820954963564873] accuracy[93.04] precision[0.0] recall[0.0] specificity[94.69] F1 score[0]\n",
      "[2590/5002] final loss [0.1233878806233406] accuracy[93.75] precision[66.67] recall[50.0] specificity[97.73] F1 score[0.57]\n",
      "[2591/5002] final loss [0.2372177541255951] accuracy[89.72] precision[9.52] recall[22.22] specificity[92.21] F1 score[0.13]\n",
      "[2592/5002] final loss [0.09629197418689728] accuracy[94.51] precision[0.0] recall[0] specificity[94.51] F1 score[0]\n",
      "[2593/5002] final loss [0.5023394823074341] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[2594/5002] final loss [0.25549307465553284] accuracy[95.51] precision[0.0] recall[0] specificity[95.51] F1 score[0]\n",
      "[2595/5002] final loss [0.09980139881372452] accuracy[86.08] precision[28.57] recall[25.0] specificity[92.96] F1 score[0.27]\n",
      "[2596/5002] final loss [0.06824418157339096] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[2597/5002] final loss [0.12668927013874054] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2598/5002] final loss [0.10545710474252701] accuracy[92.76] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[[2599/10000]] loop skipped\n",
      "[2600/5003] final loss [0.27760112285614014] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[2601/5003] final loss [0.06551949679851532] accuracy[90.77] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[2602/5003] final loss [0.13138261437416077] accuracy[94.68] precision[0.0] recall[0] specificity[94.68] F1 score[0]\n",
      "[2603/5003] final loss [0.10837357491254807] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[2604/5003] final loss [0.15028172731399536] accuracy[91.84] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[2605/5003] final loss [0.050966888666152954] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[2606/5003] final loss [0.2027006447315216] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2607/5003] final loss [0.1869298815727234] accuracy[94.87] precision[7.69] recall[100.0] specificity[94.85] F1 score[0.14]\n",
      "[2608/5003] final loss [0.301164448261261] accuracy[94.55] precision[0.0] recall[0] specificity[94.55] F1 score[0]\n",
      "[2609/5003] final loss [0.23100274801254272] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[2610/5003] final loss [0.12627273797988892] accuracy[82.39] precision[33.33] recall[10.71] specificity[95.95] F1 score[0.16]\n",
      "[2611/5003] final loss [0.046547044068574905] accuracy[92.76] precision[28.57] recall[25.0] specificity[96.53] F1 score[0.27]\n",
      "[2612/5003] final loss [0.08817725628614426] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2613/5003] final loss [0.02220800146460533] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2614/5003] final loss [0.1897386610507965] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[2615/5003] final loss [0.0974249467253685] accuracy[93.14] precision[0.0] recall[0] specificity[93.14] F1 score[0]\n",
      "[2616/5003] final loss [0.09203363209962845] accuracy[92.37] precision[16.67] recall[16.67] specificity[96.0] F1 score[0.17]\n",
      "[2617/5003] final loss [0.15155550837516785] accuracy[87.77] precision[13.64] recall[16.67] specificity[92.69] F1 score[0.15]\n",
      "[2618/5003] final loss [0.10242486000061035] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2619/5003] final loss [0.1811499297618866] accuracy[87.32] precision[50.0] recall[22.22] specificity[96.77] F1 score[0.31]\n",
      "[2620/5003] final loss [0.1376345306634903] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2621/5003] final loss [0.0621756985783577] accuracy[91.53] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[2622/5003] final loss [0.1435370147228241] accuracy[89.55] precision[20.0] recall[25.0] specificity[93.65] F1 score[0.22]\n",
      "[2623/5003] final loss [0.011921102181077003] accuracy[90.72] precision[0.0] recall[0.0] specificity[94.62] F1 score[0]\n",
      "[2624/5003] final loss [0.25209343433380127] accuracy[90.91] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[2625/5003] final loss [0.05432138592004776] accuracy[81.48] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[2626/5003] final loss [0.06378529965877533] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2627/5003] final loss [0.25896716117858887] accuracy[82.52] precision[21.43] recall[10.71] specificity[93.82] F1 score[0.14]\n",
      "[2628/5003] final loss [0.06767554581165314] accuracy[95.45] precision[0.0] recall[0.0] specificity[96.92] F1 score[0]\n",
      "[2629/5003] final loss [0.0927482545375824] accuracy[91.67] precision[40.0] recall[50.0] specificity[94.64] F1 score[0.44]\n",
      "[2630/5003] final loss [0.05141370743513107] accuracy[92.99] precision[0.0] recall[0.0] specificity[93.59] F1 score[0]\n",
      "[2631/5003] final loss [0.09203336387872696] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2632/5003] final loss [0.06505706161260605] accuracy[86.49] precision[9.09] recall[6.25] specificity[94.08] F1 score[0.07]\n",
      "[2633/5003] final loss [0.014126118272542953] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[2634/5003] final loss [0.04312041029334068] accuracy[92.14] precision[0.0] recall[0.0] specificity[94.16] F1 score[0]\n",
      "[2635/5003] final loss [0.11295652389526367] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2636/5003] final loss [0.09101427346467972] accuracy[95.37] precision[28.57] recall[100.0] specificity[95.28] F1 score[0.44]\n",
      "[2637/5003] final loss [0.1758890599012375] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[2638/5003] final loss [0.013833139091730118] accuracy[93.38] precision[0.0] recall[0.0] specificity[96.58] F1 score[0]\n",
      "[2639/5003] final loss [0.1390157788991928] accuracy[97.83] precision[0.0] recall[0] specificity[97.83] F1 score[0]\n",
      "[2640/5003] final loss [0.023977704346179962] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2641/5003] final loss [0.18116648495197296] accuracy[76.92] precision[0.0] recall[0.0] specificity[83.33] F1 score[0]\n",
      "[2642/5003] final loss [0.07374445348978043] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2643/5003] final loss [0.21123312413692474] accuracy[92.47] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[2644/5003] final loss [0.08775228261947632] accuracy[94.81] precision[0.0] recall[0.0] specificity[95.52] F1 score[0]\n",
      "[2645/5003] final loss [0.09424906969070435] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2646/5003] final loss [0.07356169819831848] accuracy[87.5] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[2647/5003] final loss [0.08629969507455826] accuracy[82.09] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[2648/5003] final loss [0.07347021251916885] accuracy[94.74] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[2649/5003] final loss [0.16990111768245697] accuracy[91.96] precision[0.0] recall[0.0] specificity[92.79] F1 score[0]\n",
      "[2650/5003] final loss [0.255113422870636] accuracy[91.67] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[2651/5003] final loss [0.059144843369722366] accuracy[91.43] precision[0.0] recall[0.0] specificity[96.97] F1 score[0]\n",
      "[2652/5003] final loss [0.09160163998603821] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2653/5003] final loss [0.12420713156461716] accuracy[95.6] precision[0.0] recall[0] specificity[95.6] F1 score[0]\n",
      "[2654/5003] final loss [0.189271941781044] accuracy[95.83] precision[50.0] recall[100.0] specificity[95.65] F1 score[0.67]\n",
      "[2655/5003] final loss [0.01000578049570322] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2656/5003] final loss [0.04825287312269211] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2657/5003] final loss [0.10274907201528549] accuracy[90.74] precision[12.5] recall[15.38] specificity[94.55] F1 score[0.14]\n",
      "[2658/5003] final loss [0.4556361734867096] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2659/5003] final loss [0.11426922678947449] accuracy[83.33] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[2660/5003] final loss [0.07864553481340408] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[2661/5003] final loss [0.021494988352060318] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2662/5003] final loss [0.05055923014879227] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[2663/5003] final loss [0.063343346118927] accuracy[94.63] precision[0.0] recall[0.0] specificity[96.58] F1 score[0]\n",
      "[2664/5003] final loss [0.270248681306839] accuracy[90.77] precision[0.0] recall[0.0] specificity[93.65] F1 score[0]\n",
      "[2665/5003] final loss [0.17717386782169342] accuracy[92.81] precision[0.0] recall[0.0] specificity[95.56] F1 score[0]\n",
      "[2666/5003] final loss [0.016413623467087746] accuracy[98.59] precision[0.0] recall[0] specificity[98.59] F1 score[0]\n",
      "[2667/5003] final loss [0.24208246171474457] accuracy[89.47] precision[8.33] recall[7.14] specificity[94.86] F1 score[0.08]\n",
      "[2668/5003] final loss [0.0003365793963894248] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2669/5003] final loss [0.015238705091178417] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[2670/5003] final loss [0.06082691252231598] accuracy[93.66] precision[7.69] recall[50.0] specificity[94.09] F1 score[0.13]\n",
      "[2671/5003] final loss [0.12148191034793854] accuracy[76.64] precision[38.46] recall[22.73] specificity[90.59] F1 score[0.29]\n",
      "[2672/5003] final loss [0.08878747373819351] accuracy[89.8] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[2673/5003] final loss [0.10004684329032898] accuracy[89.13] precision[0.0] recall[0.0] specificity[93.18] F1 score[0]\n",
      "[2674/5003] final loss [0.13362029194831848] accuracy[87.38] precision[20.0] recall[14.29] specificity[94.46] F1 score[0.17]\n",
      "[2675/5003] final loss [0.13546977937221527] accuracy[89.72] precision[14.29] recall[16.67] specificity[94.06] F1 score[0.15]\n",
      "[2676/5003] final loss [0.19675970077514648] accuracy[88.32] precision[5.56] recall[11.11] specificity[91.71] F1 score[0.07]\n",
      "[2677/5003] final loss [0.09593949466943741] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[2678/5003] final loss [0.3340321481227875] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[2679/5003] final loss [0.08159483969211578] accuracy[90.44] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[2680/5003] final loss [0.17050908505916595] accuracy[94.67] precision[0.0] recall[0] specificity[94.67] F1 score[0]\n",
      "[2681/5003] final loss [0.1699245721101761] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2682/5003] final loss [0.07751245051622391] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[2683/5003] final loss [0.11799835413694382] accuracy[93.62] precision[25.0] recall[100.0] specificity[93.48] F1 score[0.4]\n",
      "[2684/5003] final loss [0.08684033900499344] accuracy[92.13] precision[7.69] recall[33.33] specificity[93.14] F1 score[0.12]\n",
      "[2685/5003] final loss [0.0816023051738739] accuracy[91.3] precision[0.0] recall[0.0] specificity[94.38] F1 score[0]\n",
      "[2686/5003] final loss [0.21384243667125702] accuracy[95.12] precision[50.0] recall[50.0] specificity[97.44] F1 score[0.5]\n",
      "[2687/5003] final loss [0.15088576078414917] accuracy[94.12] precision[0.0] recall[0.0] specificity[98.46] F1 score[0]\n",
      "[2688/5003] final loss [0.13675548136234283] accuracy[91.91] precision[25.0] recall[28.57] specificity[95.35] F1 score[0.27]\n",
      "[2689/5003] final loss [0.03401566296815872] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2690/5003] final loss [0.11642920225858688] accuracy[94.0] precision[0.0] recall[0] specificity[94.0] F1 score[0]\n",
      "[2691/5003] final loss [0.09162637591362] accuracy[96.1] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[2692/5003] final loss [0.019086645916104317] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2693/5003] final loss [0.14833413064479828] accuracy[87.5] precision[0.0] recall[0.0] specificity[92.11] F1 score[0]\n",
      "[2694/5003] final loss [0.07449831068515778] accuracy[94.33] precision[0.0] recall[0] specificity[94.33] F1 score[0]\n",
      "[2695/5003] final loss [0.0704493299126625] accuracy[93.33] precision[0.0] recall[0.0] specificity[96.55] F1 score[0]\n",
      "[2696/5003] final loss [0.00975449476391077] accuracy[85.96] precision[50.0] recall[12.5] specificity[97.96] F1 score[0.2]\n",
      "[2697/5003] final loss [0.16821587085723877] accuracy[88.41] precision[33.33] recall[33.33] specificity[93.65] F1 score[0.33]\n",
      "[2698/5003] final loss [0.23642021417617798] accuracy[87.89] precision[6.45] recall[21.05] specificity[90.07] F1 score[0.1]\n",
      "[2699/5003] final loss [0.11252652853727341] accuracy[92.0] precision[25.0] recall[25.0] specificity[95.77] F1 score[0.25]\n",
      "[2700/5003] final loss [0.03627539426088333] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2701/5003] final loss [0.10166822373867035] accuracy[93.22] precision[20.0] recall[20.0] specificity[96.46] F1 score[0.2]\n",
      "[2702/5003] final loss [0.11626145243644714] accuracy[91.54] precision[0.0] recall[0.0] specificity[92.25] F1 score[0]\n",
      "[2703/5003] final loss [0.0713173970580101] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2704/5003] final loss [0.10820329189300537] accuracy[90.57] precision[18.75] recall[20.0] specificity[94.8] F1 score[0.19]\n",
      "[2705/5003] final loss [0.050756484270095825] accuracy[91.43] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[2706/5003] final loss [0.11003762483596802] accuracy[89.55] precision[50.0] recall[28.57] specificity[96.67] F1 score[0.36]\n",
      "[2707/5003] final loss [0.25264203548431396] accuracy[90.43] precision[16.67] recall[20.0] specificity[94.38] F1 score[0.18]\n",
      "[2708/5003] final loss [0.18549303710460663] accuracy[85.06] precision[22.22] recall[25.0] specificity[91.14] F1 score[0.24]\n",
      "[2709/5003] final loss [0.3614561855792999] accuracy[92.73] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[2710/5003] final loss [0.03967192396521568] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[2711/5003] final loss [0.12377811223268509] accuracy[78.79] precision[50.0] recall[14.29] specificity[96.15] F1 score[0.22]\n",
      "[2712/5003] final loss [0.07488363981246948] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[2713/5003] final loss [0.12462609261274338] accuracy[87.27] precision[0.0] recall[0.0] specificity[89.72] F1 score[0]\n",
      "[2714/5003] final loss [0.15902398526668549] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.53] F1 score[0]\n",
      "[2715/5003] final loss [0.1862240880727768] accuracy[94.03] precision[9.09] recall[14.29] specificity[96.17] F1 score[0.11]\n",
      "[2716/5003] final loss [0.011124617420136929] accuracy[92.98] precision[0.0] recall[0.0] specificity[94.64] F1 score[0]\n",
      "[2717/5003] final loss [0.14853258430957794] accuracy[89.86] precision[0.0] recall[0.0] specificity[94.66] F1 score[0]\n",
      "[2718/5003] final loss [0.03476656973361969] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2719/5003] final loss [0.11752882599830627] accuracy[84.25] precision[14.29] recall[6.67] specificity[94.64] F1 score[0.09]\n",
      "[2720/5003] final loss [0.07933910936117172] accuracy[90.48] precision[22.22] recall[66.67] specificity[91.36] F1 score[0.33]\n",
      "[2721/5003] final loss [0.1496301293373108] accuracy[88.83] precision[23.08] recall[18.75] specificity[94.74] F1 score[0.21]\n",
      "[2722/5003] final loss [0.19140523672103882] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[2723/5003] final loss [0.07646013051271439] accuracy[91.11] precision[0.0] recall[0] specificity[91.11] F1 score[0]\n",
      "[2724/5003] final loss [0.15344661474227905] accuracy[92.59] precision[0.0] recall[0.0] specificity[96.15] F1 score[0]\n",
      "[2725/5003] final loss [0.024688636884093285] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2726/5003] final loss [0.18579702079296112] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2727/5003] final loss [0.11655882745981216] accuracy[93.43] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[2728/5003] final loss [0.11143721640110016] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2729/5003] final loss [0.12387795746326447] accuracy[93.91] precision[33.33] recall[40.0] specificity[96.36] F1 score[0.36]\n",
      "[2730/5003] final loss [0.20169228315353394] accuracy[92.11] precision[0.0] recall[0] specificity[92.11] F1 score[0]\n",
      "[2731/5003] final loss [0.18105266988277435] accuracy[85.05] precision[0.0] recall[0.0] specificity[88.35] F1 score[0]\n",
      "[2732/5003] final loss [0.056199509650468826] accuracy[94.23] precision[33.33] recall[50.0] specificity[96.0] F1 score[0.4]\n",
      "[2733/5003] final loss [0.1050715446472168] accuracy[91.61] precision[0.0] recall[0.0] specificity[94.93] F1 score[0]\n",
      "[2734/5003] final loss [0.2960987687110901] accuracy[84.39] precision[10.0] recall[7.69] specificity[92.59] F1 score[0.09]\n",
      "[2735/5003] final loss [0.13844609260559082] accuracy[86.49] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[2736/5003] final loss [0.2100869119167328] accuracy[85.63] precision[11.11] recall[20.0] specificity[89.81] F1 score[0.14]\n",
      "[2737/5003] final loss [0.01576610654592514] accuracy[88.89] precision[0.0] recall[0.0] specificity[96.97] F1 score[0]\n",
      "[2738/5003] final loss [0.04218578338623047] accuracy[87.14] precision[0.0] recall[0.0] specificity[93.85] F1 score[0]\n",
      "[2739/5003] final loss [0.0844157412648201] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2740/5003] final loss [0.16655805706977844] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2741/5003] final loss [0.12379049509763718] accuracy[97.03] precision[0.0] recall[0.0] specificity[98.99] F1 score[0]\n",
      "[2742/5003] final loss [0.1150333434343338] accuracy[81.22] precision[7.14] recall[4.26] specificity[92.15] F1 score[0.05]\n",
      "[2743/5003] final loss [0.2157059907913208] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[2744/5003] final loss [0.12235250324010849] accuracy[93.63] precision[8.33] recall[33.33] specificity[94.53] F1 score[0.13]\n",
      "[2745/5003] final loss [0.017108909785747528] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[2746/5003] final loss [0.16355472803115845] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[2747/5003] final loss [0.026657046750187874] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[2748/5003] final loss [0.14504186809062958] accuracy[93.6] precision[0.0] recall[0.0] specificity[95.27] F1 score[0]\n",
      "[2749/5003] final loss [0.1394944190979004] accuracy[89.16] precision[20.0] recall[6.67] specificity[97.35] F1 score[0.1]\n",
      "[2750/5003] final loss [0.1374574899673462] accuracy[96.36] precision[0.0] recall[0.0] specificity[98.15] F1 score[0]\n",
      "[2751/5003] final loss [0.09487330913543701] accuracy[89.83] precision[0.0] recall[0.0] specificity[91.38] F1 score[0]\n",
      "[2752/5003] final loss [0.1334158182144165] accuracy[92.31] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[2753/5003] final loss [0.05496495962142944] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2754/5003] final loss [0.21658968925476074] accuracy[88.39] precision[14.29] recall[12.5] specificity[94.23] F1 score[0.13]\n",
      "[2755/5003] final loss [0.1253051608800888] accuracy[87.93] precision[21.74] recall[33.33] specificity[91.71] F1 score[0.26]\n",
      "[2756/5003] final loss [0.13051500916481018] accuracy[80.0] precision[100.0] recall[30.77] specificity[100.0] F1 score[0.47]\n",
      "[2757/5003] final loss [0.27776622772216797] accuracy[81.16] precision[33.33] recall[18.18] specificity[93.1] F1 score[0.24]\n",
      "[2758/5003] final loss [0.1986468881368637] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2759/5003] final loss [0.03772362321615219] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[2760/5003] final loss [0.1425360143184662] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[2761/5003] final loss [0.06399699300527573] accuracy[89.47] precision[50.0] recall[25.0] specificity[97.06] F1 score[0.33]\n",
      "[2762/5003] final loss [0.0847293883562088] accuracy[93.65] precision[0.0] recall[0.0] specificity[96.72] F1 score[0]\n",
      "[2763/5003] final loss [0.2341604083776474] accuracy[92.0] precision[40.0] recall[40.0] specificity[95.71] F1 score[0.4]\n",
      "[2764/5003] final loss [0.017490478232502937] accuracy[96.05] precision[25.0] recall[100.0] specificity[96.0] F1 score[0.4]\n",
      "[2765/5003] final loss [0.20801104605197906] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[2766/5003] final loss [0.10627074539661407] accuracy[87.32] precision[33.33] recall[12.5] specificity[96.83] F1 score[0.18]\n",
      "[2767/5003] final loss [0.32137247920036316] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2768/5003] final loss [0.09613312035799026] accuracy[93.52] precision[0.0] recall[0.0] specificity[94.39] F1 score[0]\n",
      "[2769/5003] final loss [0.31924983859062195] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2770/5003] final loss [0.2386987954378128] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[2771/5003] final loss [0.18106681108474731] accuracy[95.49] precision[0.0] recall[0] specificity[95.49] F1 score[0]\n",
      "[2772/5003] final loss [0.10784030705690384] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[2773/5003] final loss [0.12284430116415024] accuracy[92.93] precision[0.0] recall[0] specificity[92.93] F1 score[0]\n",
      "[2774/5003] final loss [0.08630432188510895] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[2775/5003] final loss [0.0024128418881446123] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2776/5003] final loss [0.24934270977973938] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[2777/5003] final loss [0.1662534475326538] accuracy[85.42] precision[20.0] recall[25.0] specificity[90.91] F1 score[0.22]\n",
      "[2778/5003] final loss [0.039176810532808304] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2779/5003] final loss [0.047227926552295685] accuracy[88.89] precision[0.0] recall[0.0] specificity[91.8] F1 score[0]\n",
      "[2780/5003] final loss [0.08509346842765808] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[2781/5003] final loss [0.12051691859960556] accuracy[96.77] precision[50.0] recall[100.0] specificity[96.67] F1 score[0.67]\n",
      "[2782/5003] final loss [0.07983941584825516] accuracy[96.51] precision[0.0] recall[0] specificity[96.51] F1 score[0]\n",
      "[2783/5003] final loss [0.06230673938989639] accuracy[79.01] precision[40.0] recall[12.5] specificity[95.38] F1 score[0.19]\n",
      "[2784/5003] final loss [0.16694553196430206] accuracy[95.08] precision[0.0] recall[0] specificity[95.08] F1 score[0]\n",
      "[2785/5003] final loss [0.13139255344867706] accuracy[80.92] precision[10.0] recall[5.88] specificity[92.11] F1 score[0.07]\n",
      "[2786/5003] final loss [0.22060897946357727] accuracy[93.28] precision[0.0] recall[0] specificity[93.28] F1 score[0]\n",
      "[2787/5003] final loss [0.0640704482793808] accuracy[91.94] precision[0.0] recall[0] specificity[91.94] F1 score[0]\n",
      "[2788/5003] final loss [0.1630115807056427] accuracy[92.44] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[2789/5003] final loss [0.07806205004453659] accuracy[93.33] precision[0.0] recall[0.0] specificity[95.15] F1 score[0]\n",
      "[2790/5003] final loss [0.09208649396896362] accuracy[88.1] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[2791/5003] final loss [0.23831862211227417] accuracy[91.77] precision[11.11] recall[40.0] specificity[92.92] F1 score[0.17]\n",
      "[2792/5003] final loss [0.1104569062590599] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2793/5003] final loss [0.06646347045898438] accuracy[88.24] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[2794/5003] final loss [0.03171888366341591] accuracy[90.0] precision[0.0] recall[0.0] specificity[92.78] F1 score[0]\n",
      "[2795/5003] final loss [0.12232553958892822] accuracy[93.02] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[2796/5003] final loss [0.40763619542121887] accuracy[96.08] precision[0.0] recall[0] specificity[96.08] F1 score[0]\n",
      "[2797/5003] final loss [0.17900605499744415] accuracy[88.72] precision[17.65] recall[27.27] specificity[92.39] F1 score[0.21]\n",
      "[2798/5003] final loss [0.058830417692661285] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[2799/5003] final loss [0.11297984421253204] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[2800/5003] final loss [0.3129422068595886] accuracy[89.73] precision[0.0] recall[0.0] specificity[93.79] F1 score[0]\n",
      "[2801/5003] final loss [0.4463473856449127] accuracy[75.0] precision[0.0] recall[0] specificity[75.0] F1 score[0]\n",
      "[2802/5003] final loss [0.11967886984348297] accuracy[93.75] precision[0.0] recall[0.0] specificity[94.94] F1 score[0]\n",
      "[2803/5003] final loss [0.08214134722948074] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2804/5003] final loss [0.018654601648449898] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2805/5003] final loss [0.025002742186188698] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2806/5003] final loss [0.07926055788993835] accuracy[89.47] precision[0.0] recall[0.0] specificity[96.23] F1 score[0]\n",
      "[2807/5003] final loss [0.21738171577453613] accuracy[96.92] precision[0.0] recall[0] specificity[96.92] F1 score[0]\n",
      "[2808/5003] final loss [0.22693288326263428] accuracy[86.49] precision[33.33] recall[25.0] specificity[93.94] F1 score[0.29]\n",
      "[2809/5003] final loss [0.030822506174445152] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[2810/5003] final loss [0.1605692356824875] accuracy[86.73] precision[27.27] recall[30.0] specificity[92.23] F1 score[0.29]\n",
      "[2811/5003] final loss [0.08529908210039139] accuracy[89.61] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[2812/5003] final loss [0.06798142194747925] accuracy[98.39] precision[50.0] recall[100.0] specificity[98.36] F1 score[0.67]\n",
      "[2813/5003] final loss [0.27795612812042236] accuracy[98.33] precision[0.0] recall[0] specificity[98.33] F1 score[0]\n",
      "[2814/5003] final loss [0.15589363873004913] accuracy[93.43] precision[0.0] recall[0.0] specificity[96.6] F1 score[0]\n",
      "[2815/5003] final loss [0.1269344538450241] accuracy[87.13] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[2816/5003] final loss [0.13447749614715576] accuracy[76.47] precision[50.0] recall[8.33] specificity[97.44] F1 score[0.14]\n",
      "[2817/5003] final loss [0.1458434909582138] accuracy[86.67] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[2818/5003] final loss [0.5027543306350708] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2819/5003] final loss [0.10009779781103134] accuracy[93.55] precision[20.0] recall[33.33] specificity[95.56] F1 score[0.25]\n",
      "[2820/5003] final loss [0.04220400005578995] accuracy[94.94] precision[0.0] recall[0] specificity[94.94] F1 score[0]\n",
      "[2821/5003] final loss [0.27061888575553894] accuracy[94.05] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[2822/5003] final loss [0.05847740173339844] accuracy[75.0] precision[0.0] recall[0] specificity[75.0] F1 score[0]\n",
      "[2823/5003] final loss [0.16870982944965363] accuracy[92.06] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[2824/5003] final loss [0.14421270787715912] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[2825/5003] final loss [0.2030421644449234] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2826/5003] final loss [0.026213519275188446] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[2827/5003] final loss [0.08463557809591293] accuracy[87.77] precision[9.09] recall[12.5] specificity[92.37] F1 score[0.11]\n",
      "[2828/5003] final loss [0.11100231856107712] accuracy[86.83] precision[21.43] recall[12.5] specificity[94.98] F1 score[0.16]\n",
      "[2829/5003] final loss [0.1509488970041275] accuracy[96.97] precision[50.0] recall[100.0] specificity[96.88] F1 score[0.67]\n",
      "[2830/5003] final loss [0.08977291733026505] accuracy[96.75] precision[11.11] recall[100.0] specificity[96.73] F1 score[0.2]\n",
      "[2831/5003] final loss [0.155633345246315] accuracy[92.62] precision[0.0] recall[0.0] specificity[94.96] F1 score[0]\n",
      "[2832/5003] final loss [0.16741956770420074] accuracy[92.05] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[2833/5003] final loss [0.07717199623584747] accuracy[94.12] precision[0.0] recall[0.0] specificity[95.52] F1 score[0]\n",
      "[2834/5003] final loss [0.04538073018193245] accuracy[96.09] precision[0.0] recall[0] specificity[96.09] F1 score[0]\n",
      "[2835/5003] final loss [0.14236396551132202] accuracy[93.39] precision[16.67] recall[25.0] specificity[95.73] F1 score[0.2]\n",
      "[2836/5003] final loss [0.1804930716753006] accuracy[83.33] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[2837/5003] final loss [0.17661671340465546] accuracy[85.0] precision[0.0] recall[0.0] specificity[90.07] F1 score[0]\n",
      "[2838/5003] final loss [0.20685873925685883] accuracy[86.21] precision[28.57] recall[22.22] specificity[93.59] F1 score[0.25]\n",
      "[2839/5003] final loss [0.06556631624698639] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[2840/5003] final loss [0.10049616545438766] accuracy[87.5] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[2841/5003] final loss [0.016290338709950447] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2842/5003] final loss [0.09489165991544724] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2843/5003] final loss [0.07958348095417023] accuracy[91.53] precision[0.0] recall[0.0] specificity[98.18] F1 score[0]\n",
      "[2844/5003] final loss [0.14568141102790833] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[2845/5003] final loss [0.13098104298114777] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[2846/5003] final loss [0.16674551367759705] accuracy[90.13] precision[12.5] recall[20.0] specificity[93.43] F1 score[0.15]\n",
      "[2847/5003] final loss [0.10262365639209747] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2848/5003] final loss [0.13607561588287354] accuracy[95.65] precision[25.0] recall[100.0] specificity[95.59] F1 score[0.4]\n",
      "[2849/5003] final loss [0.04634042829275131] accuracy[94.94] precision[0.0] recall[0] specificity[94.94] F1 score[0]\n",
      "[2850/5003] final loss [0.03971574082970619] accuracy[87.65] precision[80.0] recall[30.77] specificity[98.53] F1 score[0.44]\n",
      "[2851/5003] final loss [0.0652255192399025] accuracy[91.78] precision[0.0] recall[0.0] specificity[94.37] F1 score[0]\n",
      "[2852/5003] final loss [0.122942253947258] accuracy[92.02] precision[20.0] recall[30.0] specificity[94.74] F1 score[0.24]\n",
      "[2853/5003] final loss [0.10181376338005066] accuracy[91.3] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[2854/5003] final loss [0.18459060788154602] accuracy[94.35] precision[0.0] recall[0] specificity[94.35] F1 score[0]\n",
      "[2855/5003] final loss [0.21478582918643951] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[2856/5003] final loss [0.03806089237332344] accuracy[95.41] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[2857/5003] final loss [0.12496987730264664] accuracy[91.23] precision[0.0] recall[0] specificity[91.23] F1 score[0]\n",
      "[2858/5003] final loss [0.27122962474823] accuracy[95.18] precision[0.0] recall[0.0] specificity[96.34] F1 score[0]\n",
      "[2859/5003] final loss [0.21337246894836426] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2860/5003] final loss [0.164126455783844] accuracy[86.27] precision[16.67] recall[33.33] specificity[89.58] F1 score[0.22]\n",
      "[2861/5003] final loss [0.03936351090669632] accuracy[92.65] precision[16.67] recall[16.67] specificity[96.15] F1 score[0.17]\n",
      "[2862/5003] final loss [0.07512154430150986] accuracy[92.5] precision[0.0] recall[0.0] specificity[93.67] F1 score[0]\n",
      "[2863/5003] final loss [0.09768292307853699] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[2864/5003] final loss [0.1721668690443039] accuracy[94.2] precision[0.0] recall[0.0] specificity[94.89] F1 score[0]\n",
      "[2865/5003] final loss [0.0054786549881100655] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2866/5003] final loss [0.18409761786460876] accuracy[80.58] precision[27.27] recall[20.0] specificity[90.91] F1 score[0.23]\n",
      "[2867/5003] final loss [0.22335752844810486] accuracy[86.93] precision[7.69] recall[8.33] specificity[92.68] F1 score[0.08]\n",
      "[2868/5003] final loss [0.046906113624572754] accuracy[94.81] precision[0.0] recall[0.0] specificity[97.33] F1 score[0]\n",
      "[2869/5003] final loss [0.2878402769565582] accuracy[88.02] precision[20.0] recall[14.29] specificity[94.77] F1 score[0.17]\n",
      "[2870/5003] final loss [0.07450637221336365] accuracy[94.53] precision[0.0] recall[0] specificity[94.53] F1 score[0]\n",
      "[2871/5003] final loss [0.11336028575897217] accuracy[85.11] precision[0.0] recall[0.0] specificity[93.02] F1 score[0]\n",
      "[2872/5003] final loss [0.09128189831972122] accuracy[79.44] precision[33.33] recall[15.79] specificity[93.18] F1 score[0.21]\n",
      "[2873/5003] final loss [0.07729681581258774] accuracy[94.3] precision[0.0] recall[0.0] specificity[96.13] F1 score[0]\n",
      "[2874/5003] final loss [0.02224818989634514] accuracy[93.18] precision[0.0] recall[0.0] specificity[97.62] F1 score[0]\n",
      "[2875/5003] final loss [0.014888470992445946] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[2876/5003] final loss [0.15985314548015594] accuracy[92.04] precision[0.0] recall[0.0] specificity[93.69] F1 score[0]\n",
      "[2877/5003] final loss [0.33526676893234253] accuracy[95.52] precision[0.0] recall[0] specificity[95.52] F1 score[0]\n",
      "[2878/5003] final loss [0.10976996272802353] accuracy[86.36] precision[16.67] recall[20.0] specificity[91.8] F1 score[0.18]\n",
      "[2879/5003] final loss [0.12601329386234283] accuracy[89.04] precision[75.0] recall[30.0] specificity[98.41] F1 score[0.43]\n",
      "[2880/5003] final loss [0.0786665678024292] accuracy[89.09] precision[0.0] recall[0.0] specificity[90.74] F1 score[0]\n",
      "[2881/5003] final loss [0.25814035534858704] accuracy[86.63] precision[25.0] recall[17.65] specificity[94.19] F1 score[0.21]\n",
      "[2882/5003] final loss [0.14139866828918457] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[2883/5003] final loss [0.21720072627067566] accuracy[98.08] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2884/5003] final loss [0.21796901524066925] accuracy[92.68] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[2885/5003] final loss [0.07018347829580307] accuracy[91.87] precision[0.0] recall[0] specificity[91.87] F1 score[0]\n",
      "[2886/5003] final loss [0.009610741399228573] accuracy[92.11] precision[0.0] recall[0.0] specificity[96.33] F1 score[0]\n",
      "[2887/5003] final loss [0.10409222543239594] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2888/5003] final loss [0.15545697510242462] accuracy[96.67] precision[0.0] recall[0.0] specificity[98.31] F1 score[0]\n",
      "[2889/5003] final loss [0.09962843358516693] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[2890/5003] final loss [0.08794867247343063] accuracy[87.5] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2891/5003] final loss [0.17760737240314484] accuracy[86.45] precision[14.81] recall[40.0] specificity[88.73] F1 score[0.22]\n",
      "[2892/5003] final loss [0.12779714167118073] accuracy[93.21] precision[0.0] recall[0] specificity[93.21] F1 score[0]\n",
      "[2893/5003] final loss [0.11633823066949844] accuracy[94.07] precision[0.0] recall[0.0] specificity[94.78] F1 score[0]\n",
      "[2894/5003] final loss [0.0367257222533226] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2895/5003] final loss [0.13436385989189148] accuracy[92.35] precision[8.33] recall[20.0] specificity[94.24] F1 score[0.12]\n",
      "[2896/5003] final loss [0.04060394689440727] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2897/5003] final loss [0.14273396134376526] accuracy[89.66] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[2898/5003] final loss [0.21610239148139954] accuracy[85.5] precision[22.22] recall[14.29] specificity[94.02] F1 score[0.17]\n",
      "[2899/5003] final loss [0.11092713475227356] accuracy[83.02] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[2900/5003] final loss [0.07278808951377869] accuracy[93.97] precision[0.0] recall[0.0] specificity[97.32] F1 score[0]\n",
      "[2901/5003] final loss [0.08684506267309189] accuracy[94.62] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[2902/5003] final loss [0.18991680443286896] accuracy[95.04] precision[0.0] recall[0] specificity[95.04] F1 score[0]\n",
      "[[2903/10000]] loop skipped\n",
      "[2904/5004] final loss [0.09064717590808868] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[2905/5004] final loss [0.2165016233921051] accuracy[86.88] precision[14.29] recall[7.41] specificity[95.29] F1 score[0.1]\n",
      "[2906/5004] final loss [0.18915672600269318] accuracy[94.59] precision[25.0] recall[50.0] specificity[95.83] F1 score[0.33]\n",
      "[2907/5004] final loss [0.1090705394744873] accuracy[95.0] precision[66.67] recall[40.0] specificity[98.67] F1 score[0.5]\n",
      "[2908/5004] final loss [0.11125051230192184] accuracy[88.14] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[2909/5004] final loss [0.07972739636898041] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[2910/5004] final loss [0.1089022308588028] accuracy[78.57] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[2911/5004] final loss [0.18866701424121857] accuracy[92.19] precision[0.0] recall[0] specificity[92.19] F1 score[0]\n",
      "[2912/5004] final loss [0.023046819493174553] accuracy[90.91] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[2913/5004] final loss [0.1154971569776535] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2914/5004] final loss [0.019862042739987373] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2915/5004] final loss [0.10840485990047455] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[2916/5004] final loss [0.21143746376037598] accuracy[92.19] precision[11.11] recall[33.33] specificity[93.6] F1 score[0.17]\n",
      "[2917/5004] final loss [0.21817328035831451] accuracy[84.15] precision[0.0] recall[0.0] specificity[93.24] F1 score[0]\n",
      "[2918/5004] final loss [0.06730227917432785] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[2919/5004] final loss [0.23297177255153656] accuracy[93.42] precision[0.0] recall[0.0] specificity[94.67] F1 score[0]\n",
      "[2920/5004] final loss [0.17633174359798431] accuracy[88.5] precision[11.76] recall[20.0] specificity[92.11] F1 score[0.15]\n",
      "[2921/5004] final loss [0.10343403369188309] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2922/5004] final loss [0.0994635820388794] accuracy[92.68] precision[20.0] recall[33.33] specificity[94.94] F1 score[0.25]\n",
      "[2923/5004] final loss [0.1730894297361374] accuracy[94.81] precision[20.0] recall[100.0] specificity[94.74] F1 score[0.33]\n",
      "[2924/5004] final loss [0.6507329344749451] accuracy[93.85] precision[0.0] recall[0] specificity[93.85] F1 score[0]\n",
      "[2925/5004] final loss [0.10244542360305786] accuracy[84.52] precision[20.0] recall[10.0] specificity[94.59] F1 score[0.13]\n",
      "[2926/5004] final loss [0.3284018635749817] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[2927/5004] final loss [0.15990662574768066] accuracy[89.97] precision[0.0] recall[0.0] specificity[93.53] F1 score[0]\n",
      "[2928/5004] final loss [0.23100730776786804] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[2929/5004] final loss [0.3487400412559509] accuracy[80.39] precision[25.0] recall[12.5] specificity[93.02] F1 score[0.17]\n",
      "[2930/5004] final loss [0.13940612971782684] accuracy[91.53] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[2931/5004] final loss [0.10894247889518738] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[2932/5004] final loss [0.015451437793672085] accuracy[82.43] precision[0.0] recall[0.0] specificity[98.39] F1 score[0]\n",
      "[2933/5004] final loss [0.18239720165729523] accuracy[96.08] precision[0.0] recall[0.0] specificity[98.0] F1 score[0]\n",
      "[2934/5004] final loss [0.14356736838817596] accuracy[93.33] precision[50.0] recall[42.86] specificity[96.94] F1 score[0.46]\n",
      "[2935/5004] final loss [0.03390802815556526] accuracy[90.32] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[2936/5004] final loss [0.07554800063371658] accuracy[90.4] precision[0.0] recall[0.0] specificity[91.87] F1 score[0]\n",
      "[2937/5004] final loss [0.09425140917301178] accuracy[87.06] precision[25.0] recall[11.11] specificity[96.05] F1 score[0.15]\n",
      "[2938/5004] final loss [0.08244907110929489] accuracy[94.52] precision[0.0] recall[0] specificity[94.52] F1 score[0]\n",
      "[2939/5004] final loss [0.16397547721862793] accuracy[83.33] precision[50.0] recall[27.27] specificity[94.55] F1 score[0.35]\n",
      "[2940/5004] final loss [0.058014877140522] accuracy[76.92] precision[50.0] recall[16.67] specificity[95.0] F1 score[0.25]\n",
      "[2941/5004] final loss [0.09366108477115631] accuracy[96.84] precision[0.0] recall[0] specificity[96.84] F1 score[0]\n",
      "[2942/5004] final loss [0.10695023834705353] accuracy[96.1] precision[0.0] recall[0] specificity[96.1] F1 score[0]\n",
      "[2943/5004] final loss [0.19479571282863617] accuracy[93.88] precision[0.0] recall[0.0] specificity[94.85] F1 score[0]\n",
      "[2944/5004] final loss [0.257443368434906] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2945/5004] final loss [0.14297066628932953] accuracy[97.32] precision[0.0] recall[0] specificity[97.32] F1 score[0]\n",
      "[2946/5004] final loss [0.09404446929693222] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[2947/5004] final loss [0.05633498728275299] accuracy[95.59] precision[0.0] recall[0] specificity[95.59] F1 score[0]\n",
      "[2948/5004] final loss [0.018463410437107086] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2949/5004] final loss [0.11957123130559921] accuracy[93.6] precision[0.0] recall[0] specificity[93.6] F1 score[0]\n",
      "[2950/5004] final loss [0.07035881280899048] accuracy[93.17] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[2951/5004] final loss [0.25374636054039] accuracy[94.38] precision[33.33] recall[66.67] specificity[95.35] F1 score[0.44]\n",
      "[2952/5004] final loss [0.13988396525382996] accuracy[89.38] precision[28.57] recall[36.36] specificity[93.29] F1 score[0.32]\n",
      "[2953/5004] final loss [0.211593896150589] accuracy[88.95] precision[3.23] recall[8.33] specificity[91.64] F1 score[0.05]\n",
      "[2954/5004] final loss [0.060838088393211365] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2955/5004] final loss [0.22403094172477722] accuracy[81.65] precision[12.5] recall[7.14] specificity[92.63] F1 score[0.09]\n",
      "[2956/5004] final loss [0.1084088683128357] accuracy[96.34] precision[0.0] recall[0] specificity[96.34] F1 score[0]\n",
      "[2957/5004] final loss [0.0762360543012619] accuracy[91.04] precision[25.0] recall[25.0] specificity[95.24] F1 score[0.25]\n",
      "[2958/5004] final loss [0.012875225394964218] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2959/5004] final loss [0.09460792690515518] accuracy[84.78] precision[0.0] recall[0.0] specificity[90.7] F1 score[0]\n",
      "[2960/5004] final loss [0.14136473834514618] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[2961/5004] final loss [0.17837852239608765] accuracy[89.66] precision[0.0] recall[0.0] specificity[91.23] F1 score[0]\n",
      "[2962/5004] final loss [0.21689967811107635] accuracy[92.45] precision[0.0] recall[0] specificity[92.45] F1 score[0]\n",
      "[2963/5004] final loss [0.1955280303955078] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[2964/5004] final loss [0.28887680172920227] accuracy[91.03] precision[0.0] recall[0.0] specificity[94.04] F1 score[0]\n",
      "[2965/5004] final loss [0.04686496779322624] accuracy[91.67] precision[0.0] recall[0.0] specificity[93.9] F1 score[0]\n",
      "[2966/5004] final loss [0.19718021154403687] accuracy[93.65] precision[0.0] recall[0] specificity[93.65] F1 score[0]\n",
      "[2967/5004] final loss [0.19109851121902466] accuracy[92.36] precision[0.0] recall[0] specificity[92.36] F1 score[0]\n",
      "[2968/5004] final loss [0.045031387358903885] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2969/5004] final loss [0.21248464286327362] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[2970/5004] final loss [0.03333336487412453] accuracy[93.94] precision[50.0] recall[50.0] specificity[96.77] F1 score[0.5]\n",
      "[2971/5004] final loss [0.1963067352771759] accuracy[95.92] precision[33.33] recall[100.0] specificity[95.83] F1 score[0.5]\n",
      "[2972/5004] final loss [0.14311082661151886] accuracy[91.2] precision[11.11] recall[25.0] specificity[93.39] F1 score[0.15]\n",
      "[2973/5004] final loss [0.12815441191196442] accuracy[93.27] precision[0.0] recall[0.0] specificity[94.17] F1 score[0]\n",
      "[2974/5004] final loss [0.175517275929451] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[2975/5004] final loss [0.10235392302274704] accuracy[85.71] precision[60.0] recall[16.67] specificity[98.02] F1 score[0.26]\n",
      "[2976/5004] final loss [0.1633816808462143] accuracy[89.57] precision[0.0] recall[0.0] specificity[92.79] F1 score[0]\n",
      "[2977/5004] final loss [0.06694183498620987] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2978/5004] final loss [0.037434473633766174] accuracy[96.1] precision[25.0] recall[100.0] specificity[96.05] F1 score[0.4]\n",
      "[2979/5004] final loss [0.26061633229255676] accuracy[93.44] precision[0.0] recall[0] specificity[93.44] F1 score[0]\n",
      "[2980/5004] final loss [0.014301379211246967] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2981/5004] final loss [0.10941968113183975] accuracy[93.42] precision[7.14] recall[33.33] specificity[94.22] F1 score[0.12]\n",
      "[2982/5004] final loss [0.08899667859077454] accuracy[95.36] precision[0.0] recall[0] specificity[95.36] F1 score[0]\n",
      "[2983/5004] final loss [0.03207627683877945] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[2984/5004] final loss [0.10423682630062103] accuracy[85.19] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[2985/5004] final loss [0.13751842081546783] accuracy[89.66] precision[0.0] recall[0.0] specificity[98.11] F1 score[0]\n",
      "[2986/5004] final loss [0.08428353816270828] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[2987/5004] final loss [0.1318577080965042] accuracy[93.49] precision[5.0] recall[11.11] specificity[95.32] F1 score[0.07]\n",
      "[2988/5004] final loss [0.1839379072189331] accuracy[94.85] precision[0.0] recall[0] specificity[94.85] F1 score[0]\n",
      "[2989/5004] final loss [0.1403469443321228] accuracy[82.95] precision[45.45] recall[35.71] specificity[91.89] F1 score[0.4]\n",
      "[2990/5004] final loss [0.18814773857593536] accuracy[87.89] precision[0.0] recall[0.0] specificity[90.76] F1 score[0]\n",
      "[2991/5004] final loss [0.35344818234443665] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[2992/5004] final loss [0.16946600377559662] accuracy[88.0] precision[0.0] recall[0.0] specificity[90.72] F1 score[0]\n",
      "[2993/5004] final loss [0.08861014246940613] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[2994/5004] final loss [0.0367254801094532] accuracy[90.91] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[2995/5004] final loss [0.10548797994852066] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[2996/5004] final loss [0.08051576465368271] accuracy[95.6] precision[20.0] recall[100.0] specificity[95.56] F1 score[0.33]\n",
      "[2997/5004] final loss [0.005076877772808075] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[2998/5004] final loss [0.08990155905485153] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[2999/5004] final loss [0.01774076372385025] accuracy[84.68] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[3000/5004] final loss [0.02857840619981289] accuracy[75.0] precision[0.0] recall[0] specificity[75.0] F1 score[0]\n",
      "[3001/5004] final loss [0.01269981823861599] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3002/5004] final loss [0.08119048923254013] accuracy[90.0] precision[0.0] recall[0.0] specificity[98.44] F1 score[0]\n",
      "[3003/5004] final loss [0.04681894928216934] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3004/5004] final loss [0.11912478506565094] accuracy[82.09] precision[0.0] recall[0] specificity[82.09] F1 score[0]\n",
      "[3005/5004] final loss [0.028195928782224655] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[3006/5004] final loss [0.07210680842399597] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3007/5004] final loss [0.14091730117797852] accuracy[95.52] precision[0.0] recall[0] specificity[95.52] F1 score[0]\n",
      "[3008/5004] final loss [0.10952190309762955] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[3009/5004] final loss [0.16830562055110931] accuracy[85.52] precision[16.67] recall[5.88] specificity[96.09] F1 score[0.09]\n",
      "[3010/5004] final loss [0.0664433017373085] accuracy[91.67] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[3011/5004] final loss [0.05628344416618347] accuracy[89.12] precision[20.0] recall[20.0] specificity[94.16] F1 score[0.2]\n",
      "[3012/5004] final loss [0.11798837780952454] accuracy[91.19] precision[0.0] recall[0.0] specificity[96.17] F1 score[0]\n",
      "[3013/5004] final loss [0.07480102777481079] accuracy[92.96] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[3014/5004] final loss [0.2304062843322754] accuracy[90.83] precision[0.0] recall[0.0] specificity[93.16] F1 score[0]\n",
      "[3015/5004] final loss [0.011822906322777271] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3016/5004] final loss [0.09687332063913345] accuracy[92.0] precision[11.11] recall[100.0] specificity[91.92] F1 score[0.2]\n",
      "[3017/5004] final loss [0.15608152747154236] accuracy[88.57] precision[33.33] recall[14.29] specificity[96.83] F1 score[0.2]\n",
      "[3018/5004] final loss [0.07832564413547516] accuracy[91.04] precision[33.33] recall[20.0] specificity[96.77] F1 score[0.25]\n",
      "[3019/5004] final loss [0.1453763246536255] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3020/5004] final loss [0.16301229596138] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[3021/5004] final loss [0.16129562258720398] accuracy[90.48] precision[0.0] recall[0.0] specificity[92.68] F1 score[0]\n",
      "[3022/5004] final loss [0.13846799731254578] accuracy[78.81] precision[0.0] recall[0.0] specificity[86.11] F1 score[0]\n",
      "[3023/5004] final loss [0.1279842108488083] accuracy[94.33] precision[22.22] recall[33.33] specificity[96.28] F1 score[0.27]\n",
      "[3024/5004] final loss [0.05938445031642914] accuracy[97.73] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3025/5004] final loss [0.08648201823234558] accuracy[91.43] precision[0.0] recall[0.0] specificity[92.75] F1 score[0]\n",
      "[3026/5004] final loss [0.00027708662673830986] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3027/5004] final loss [0.06036720797419548] accuracy[92.88] precision[7.14] recall[11.11] specificity[95.45] F1 score[0.09]\n",
      "[3028/5004] final loss [0.04330587014555931] accuracy[93.75] precision[33.33] recall[50.0] specificity[95.65] F1 score[0.4]\n",
      "[3029/5004] final loss [0.1327531933784485] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[3030/5004] final loss [0.15520823001861572] accuracy[90.28] precision[0.0] recall[0.0] specificity[94.2] F1 score[0]\n",
      "[3031/5004] final loss [0.10007771849632263] accuracy[91.2] precision[0.0] recall[0.0] specificity[91.94] F1 score[0]\n",
      "[3032/5004] final loss [0.2014368325471878] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3033/5004] final loss [0.19621209800243378] accuracy[82.05] precision[0.0] recall[0.0] specificity[90.14] F1 score[0]\n",
      "[3034/5004] final loss [0.18969278037548065] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[3035/5004] final loss [0.17220795154571533] accuracy[95.78] precision[16.67] recall[16.67] specificity[97.84] F1 score[0.17]\n",
      "[3036/5004] final loss [0.1289953887462616] accuracy[91.0] precision[16.67] recall[20.0] specificity[94.74] F1 score[0.18]\n",
      "[3037/5004] final loss [0.10288982093334198] accuracy[97.3] precision[0.0] recall[0] specificity[97.3] F1 score[0]\n",
      "[3038/5004] final loss [0.06683220714330673] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3039/5004] final loss [0.10348518192768097] accuracy[93.75] precision[25.0] recall[50.0] specificity[95.16] F1 score[0.33]\n",
      "[3040/5004] final loss [0.04835188761353493] accuracy[68.85] precision[37.5] recall[17.65] specificity[88.64] F1 score[0.24]\n",
      "[3041/5004] final loss [0.07007212191820145] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[3042/5004] final loss [0.15978924930095673] accuracy[90.29] precision[50.0] recall[40.0] specificity[95.7] F1 score[0.44]\n",
      "[3043/5004] final loss [0.15475976467132568] accuracy[96.36] precision[0.0] recall[0] specificity[96.36] F1 score[0]\n",
      "[3044/5004] final loss [0.2921305000782013] accuracy[92.31] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[3045/5004] final loss [0.20402000844478607] accuracy[91.89] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[3046/5004] final loss [0.12954950332641602] accuracy[89.08] precision[0.0] recall[0.0] specificity[92.98] F1 score[0]\n",
      "[3047/5004] final loss [0.12699167430400848] accuracy[93.83] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[3048/5004] final loss [0.10323525220155716] accuracy[86.29] precision[10.0] recall[11.11] specificity[92.17] F1 score[0.11]\n",
      "[3049/5004] final loss [0.04293446987867355] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3050/5004] final loss [0.11386186629533768] accuracy[93.28] precision[0.0] recall[0.0] specificity[95.14] F1 score[0]\n",
      "[3051/5004] final loss [0.15198957920074463] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[3052/5004] final loss [0.14116735756397247] accuracy[93.51] precision[50.0] recall[40.0] specificity[97.22] F1 score[0.44]\n",
      "[3053/5004] final loss [0.0599583275616169] accuracy[95.0] precision[100.0] recall[66.67] specificity[100.0] F1 score[0.8]\n",
      "[3054/5004] final loss [0.055336833000183105] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[3055/5004] final loss [0.1417037546634674] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3056/5004] final loss [0.10995380580425262] accuracy[81.2] precision[15.38] recall[15.38] specificity[89.42] F1 score[0.15]\n",
      "[3057/5004] final loss [0.0536918006837368] accuracy[86.67] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[3058/5004] final loss [0.21317529678344727] accuracy[92.09] precision[33.33] recall[37.5] specificity[95.42] F1 score[0.35]\n",
      "[3059/5004] final loss [0.14012615382671356] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[3060/5004] final loss [0.022200021892786026] accuracy[95.0] precision[0.0] recall[0.0] specificity[96.2] F1 score[0]\n",
      "[3061/5004] final loss [0.07307671755552292] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[3062/5004] final loss [0.04367370530962944] accuracy[90.7] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[3063/5004] final loss [0.10497640818357468] accuracy[92.0] precision[0.0] recall[0.0] specificity[92.93] F1 score[0]\n",
      "[3064/5004] final loss [0.11558257043361664] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[3065/5004] final loss [0.12415046244859695] accuracy[89.8] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[3066/5004] final loss [0.06252506375312805] accuracy[91.67] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[3067/5004] final loss [0.15545772016048431] accuracy[81.79] precision[12.9] recall[10.0] specificity[91.18] F1 score[0.11]\n",
      "[3068/5004] final loss [0.1620408147573471] accuracy[92.13] precision[0.0] recall[0] specificity[92.13] F1 score[0]\n",
      "[3069/5004] final loss [0.021173980087041855] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3070/5004] final loss [0.08961640298366547] accuracy[90.2] precision[0.0] recall[0.0] specificity[92.93] F1 score[0]\n",
      "[3071/5004] final loss [0.021057715639472008] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3072/5004] final loss [0.31078359484672546] accuracy[87.67] precision[33.33] recall[35.0] specificity[92.96] F1 score[0.34]\n",
      "[3073/5004] final loss [0.0871366560459137] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[3074/5004] final loss [0.09080992639064789] accuracy[93.02] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[3075/5004] final loss [0.27167293429374695] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[3076/5004] final loss [0.09439782053232193] accuracy[95.45] precision[0.0] recall[0.0] specificity[96.92] F1 score[0]\n",
      "[3077/5004] final loss [0.04145412892103195] accuracy[85.71] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[3078/5004] final loss [0.17397795617580414] accuracy[94.87] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[3079/5004] final loss [0.05661914870142937] accuracy[97.22] precision[0.0] recall[0] specificity[97.22] F1 score[0]\n",
      "[3080/5004] final loss [0.11975564062595367] accuracy[93.41] precision[20.0] recall[33.33] specificity[95.45] F1 score[0.25]\n",
      "[3081/5004] final loss [0.012388589791953564] accuracy[95.0] precision[100.0] recall[20.0] specificity[100.0] F1 score[0.33]\n",
      "[3082/5004] final loss [0.11490423232316971] accuracy[85.25] precision[50.0] recall[11.11] specificity[98.08] F1 score[0.18]\n",
      "[3083/5004] final loss [0.07872606068849564] accuracy[93.88] precision[0.0] recall[0.0] specificity[97.87] F1 score[0]\n",
      "[3084/5004] final loss [0.1594880223274231] accuracy[91.18] precision[11.11] recall[50.0] specificity[92.0] F1 score[0.18]\n",
      "[3085/5004] final loss [0.2048214077949524] accuracy[88.89] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[3086/5004] final loss [0.10433787852525711] accuracy[97.56] precision[0.0] recall[0] specificity[97.56] F1 score[0]\n",
      "[3087/5004] final loss [0.3139609098434448] accuracy[69.23] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3088/5004] final loss [0.1312730312347412] accuracy[63.49] precision[16.67] recall[5.26] specificity[88.64] F1 score[0.08]\n",
      "[3089/5004] final loss [0.016370534896850586] accuracy[91.18] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[3090/5004] final loss [0.07476980984210968] accuracy[96.1] precision[0.0] recall[0.0] specificity[98.67] F1 score[0]\n",
      "[3091/5004] final loss [0.19014349579811096] accuracy[90.18] precision[5.56] recall[16.67] specificity[92.2] F1 score[0.08]\n",
      "[3092/5004] final loss [0.05839608609676361] accuracy[98.04] precision[0.0] recall[0] specificity[98.04] F1 score[0]\n",
      "[3093/5004] final loss [0.14333347976207733] accuracy[97.22] precision[0.0] recall[0] specificity[97.22] F1 score[0]\n",
      "[3094/5004] final loss [0.16290657222270966] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[3095/5004] final loss [0.0958707332611084] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[3096/5004] final loss [0.11307541280984879] accuracy[89.09] precision[0.0] recall[0.0] specificity[89.91] F1 score[0]\n",
      "[3097/5004] final loss [0.16623008251190186] accuracy[84.85] precision[57.14] recall[25.0] specificity[96.39] F1 score[0.35]\n",
      "[3098/5004] final loss [0.06135419011116028] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3099/5004] final loss [0.03321295976638794] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3100/5004] final loss [0.16651518642902374] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3101/5004] final loss [0.11052296310663223] accuracy[91.49] precision[20.0] recall[20.0] specificity[95.51] F1 score[0.2]\n",
      "[3102/5004] final loss [0.0917326882481575] accuracy[89.74] precision[25.0] recall[16.67] specificity[95.83] F1 score[0.2]\n",
      "[3103/5004] final loss [0.08728762716054916] accuracy[74.58] precision[25.0] recall[7.69] specificity[93.48] F1 score[0.12]\n",
      "[3104/5004] final loss [0.0321882925927639] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3105/5004] final loss [0.059732697904109955] accuracy[96.92] precision[0.0] recall[0] specificity[96.92] F1 score[0]\n",
      "[3106/5004] final loss [0.16862066090106964] accuracy[87.5] precision[18.18] recall[20.0] specificity[92.86] F1 score[0.19]\n",
      "[3107/5004] final loss [0.16173456609249115] accuracy[92.78] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[3108/5004] final loss [0.018595602363348007] accuracy[90.38] precision[0.0] recall[0.0] specificity[94.0] F1 score[0]\n",
      "[3109/5004] final loss [0.07239744067192078] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[3110/5004] final loss [0.056584011763334274] accuracy[93.51] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[3111/5004] final loss [0.1353091299533844] accuracy[96.27] precision[10.0] recall[100.0] specificity[96.25] F1 score[0.18]\n",
      "[3112/5004] final loss [0.16311705112457275] accuracy[86.87] precision[0.0] recall[0.0] specificity[90.53] F1 score[0]\n",
      "[3113/5004] final loss [0.1563141793012619] accuracy[92.75] precision[20.0] recall[50.0] specificity[94.03] F1 score[0.29]\n",
      "[3114/5004] final loss [0.03537341579794884] accuracy[98.78] precision[0.0] recall[0] specificity[98.78] F1 score[0]\n",
      "[3115/5004] final loss [0.14720776677131653] accuracy[93.33] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3116/5004] final loss [0.05472760275006294] accuracy[92.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3117/5004] final loss [0.12460935860872269] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[3118/5004] final loss [0.32754212617874146] accuracy[92.86] precision[11.11] recall[11.11] specificity[96.28] F1 score[0.11]\n",
      "[3119/5004] final loss [0.06558041274547577] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[3120/5004] final loss [0.016364408656954765] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3121/5004] final loss [0.023380810394883156] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3122/5004] final loss [0.09536417573690414] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[3123/5004] final loss [0.18765249848365784] accuracy[86.96] precision[0.0] recall[0.0] specificity[91.95] F1 score[0]\n",
      "[3124/5004] final loss [0.0944659486413002] accuracy[88.7] precision[12.5] recall[14.29] specificity[93.52] F1 score[0.13]\n",
      "[3125/5004] final loss [0.11285300552845001] accuracy[81.77] precision[30.77] recall[29.63] specificity[89.77] F1 score[0.3]\n",
      "[3126/5004] final loss [0.22859381139278412] accuracy[95.05] precision[33.33] recall[80.0] specificity[95.48] F1 score[0.47]\n",
      "[3127/5004] final loss [0.14443698525428772] accuracy[90.09] precision[0.0] recall[0.0] specificity[91.74] F1 score[0]\n",
      "[3128/5004] final loss [0.29081472754478455] accuracy[90.69] precision[0.0] recall[0.0] specificity[93.43] F1 score[0]\n",
      "[3129/5004] final loss [0.15362201631069183] accuracy[70.24] precision[25.0] recall[15.79] specificity[86.15] F1 score[0.19]\n",
      "[3130/5004] final loss [0.19055569171905518] accuracy[88.89] precision[20.0] recall[11.11] specificity[95.96] F1 score[0.14]\n",
      "[3131/5004] final loss [0.27405762672424316] accuracy[93.55] precision[0.0] recall[0.0] specificity[94.77] F1 score[0]\n",
      "[3132/5004] final loss [0.10961925983428955] accuracy[82.35] precision[33.33] recall[12.5] specificity[95.35] F1 score[0.18]\n",
      "[3133/5004] final loss [0.0973336398601532] accuracy[85.37] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[3134/5004] final loss [0.1773495227098465] accuracy[92.62] precision[0.0] recall[0.0] specificity[95.17] F1 score[0]\n",
      "[3135/5004] final loss [0.3861306309700012] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[3136/5004] final loss [0.15288887917995453] accuracy[93.28] precision[0.0] recall[0] specificity[93.28] F1 score[0]\n",
      "[3137/5004] final loss [0.0921546146273613] accuracy[93.48] precision[0.0] recall[0.0] specificity[95.56] F1 score[0]\n",
      "[3138/5004] final loss [0.3043476343154907] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3139/5004] final loss [0.21396569907665253] accuracy[88.97] precision[10.53] recall[12.5] specificity[93.58] F1 score[0.11]\n",
      "[3140/5004] final loss [0.13537584245204926] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3141/5004] final loss [0.13519373536109924] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3142/5004] final loss [0.046656034886837006] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[3143/5004] final loss [0.03507872670888901] accuracy[92.66] precision[0.0] recall[0] specificity[92.66] F1 score[0]\n",
      "[3144/5004] final loss [0.16839422285556793] accuracy[94.61] precision[0.0] recall[0.0] specificity[95.54] F1 score[0]\n",
      "[3145/5004] final loss [0.08003281056880951] accuracy[92.66] precision[0.0] recall[0] specificity[92.66] F1 score[0]\n",
      "[3146/5004] final loss [0.01986653171479702] accuracy[92.0] precision[50.0] recall[50.0] specificity[95.65] F1 score[0.5]\n",
      "[3147/5004] final loss [0.13606655597686768] accuracy[85.86] precision[21.05] recall[25.0] specificity[91.43] F1 score[0.23]\n",
      "[3148/5004] final loss [0.19374477863311768] accuracy[95.18] precision[0.0] recall[0.0] specificity[96.34] F1 score[0]\n",
      "[3149/5004] final loss [0.12825657427310944] accuracy[94.96] precision[12.5] recall[100.0] specificity[94.93] F1 score[0.22]\n",
      "[3150/5004] final loss [0.16673602163791656] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3151/5004] final loss [0.16179011762142181] accuracy[87.5] precision[50.0] recall[25.0] specificity[96.43] F1 score[0.33]\n",
      "[3152/5004] final loss [0.09853294491767883] accuracy[86.11] precision[8.33] recall[10.0] specificity[91.79] F1 score[0.09]\n",
      "[3153/5004] final loss [0.19485144317150116] accuracy[75.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3154/5004] final loss [0.15611129999160767] accuracy[94.47] precision[0.0] recall[0] specificity[94.47] F1 score[0]\n",
      "[3155/5004] final loss [0.13795767724514008] accuracy[89.81] precision[7.69] recall[20.0] specificity[92.11] F1 score[0.11]\n",
      "[3156/5004] final loss [0.19452588260173798] accuracy[94.14] precision[0.0] recall[0.0] specificity[94.31] F1 score[0]\n",
      "[3157/5004] final loss [0.04742688313126564] accuracy[93.01] precision[0.0] recall[0] specificity[93.01] F1 score[0]\n",
      "[3158/5004] final loss [0.17707103490829468] accuracy[94.35] precision[0.0] recall[0] specificity[94.35] F1 score[0]\n",
      "[3159/5004] final loss [0.09231813997030258] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3160/5004] final loss [0.06658968329429626] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3161/5004] final loss [0.2987346053123474] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[3162/5004] final loss [0.07099391520023346] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3163/5004] final loss [0.26490122079849243] accuracy[84.81] precision[40.0] recall[18.18] specificity[95.59] F1 score[0.25]\n",
      "[3164/5004] final loss [0.042046912014484406] accuracy[90.48] precision[0.0] recall[0.0] specificity[92.68] F1 score[0]\n",
      "[3165/5004] final loss [0.16576090455055237] accuracy[92.96] precision[0.0] recall[0] specificity[92.96] F1 score[0]\n",
      "[3166/5004] final loss [0.23327121138572693] accuracy[91.95] precision[0.0] recall[0.0] specificity[92.52] F1 score[0]\n",
      "[3167/5004] final loss [0.1556372046470642] accuracy[92.08] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[3168/5004] final loss [0.07231641560792923] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[3169/5004] final loss [0.14295843243598938] accuracy[76.0] precision[0.0] recall[0.0] specificity[90.48] F1 score[0]\n",
      "[3170/5004] final loss [0.24492469429969788] accuracy[93.0] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[3171/5004] final loss [0.12360293418169022] accuracy[96.43] precision[0.0] recall[0.0] specificity[97.12] F1 score[0]\n",
      "[3172/5004] final loss [0.16245296597480774] accuracy[84.54] precision[33.33] recall[15.38] specificity[95.24] F1 score[0.21]\n",
      "[3173/5004] final loss [0.007422640919685364] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3174/5004] final loss [0.10149025917053223] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[3175/5004] final loss [0.2131539285182953] accuracy[89.36] precision[25.0] recall[18.18] specificity[95.38] F1 score[0.21]\n",
      "[3176/5004] final loss [0.16751328110694885] accuracy[93.12] precision[0.0] recall[0.0] specificity[93.71] F1 score[0]\n",
      "[3177/5004] final loss [0.08923180401325226] accuracy[94.92] precision[50.0] recall[33.33] specificity[98.21] F1 score[0.4]\n",
      "[3178/5004] final loss [0.08028316497802734] accuracy[86.79] precision[0.0] recall[0.0] specificity[90.2] F1 score[0]\n",
      "[3179/5004] final loss [0.17812000215053558] accuracy[82.83] precision[50.0] recall[29.41] specificity[93.9] F1 score[0.37]\n",
      "[3180/5004] final loss [0.27109241485595703] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3181/5004] final loss [0.14207296073436737] accuracy[93.64] precision[0.0] recall[0] specificity[93.64] F1 score[0]\n",
      "[3182/5004] final loss [0.19062843918800354] accuracy[75.0] precision[0.0] recall[0] specificity[75.0] F1 score[0]\n",
      "[3183/5004] final loss [0.21026240289211273] accuracy[80.41] precision[14.29] recall[7.14] specificity[92.77] F1 score[0.1]\n",
      "[3184/5004] final loss [0.32020965218544006] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3185/5004] final loss [0.0674206018447876] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[3186/5004] final loss [0.049833811819553375] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[3187/5004] final loss [0.041109349578619] accuracy[92.94] precision[12.5] recall[16.67] specificity[95.73] F1 score[0.14]\n",
      "[3188/5004] final loss [0.02264753170311451] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[3189/5004] final loss [0.09306735545396805] accuracy[86.41] precision[14.29] recall[11.11] specificity[93.62] F1 score[0.13]\n",
      "[3190/5004] final loss [0.11869659274816513] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[3191/5004] final loss [0.07958860695362091] accuracy[91.94] precision[0.0] recall[0.0] specificity[93.44] F1 score[0]\n",
      "[3192/5004] final loss [0.1283448487520218] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3193/5004] final loss [0.05074804276227951] accuracy[89.58] precision[0.0] recall[0.0] specificity[92.81] F1 score[0]\n",
      "[3194/5004] final loss [0.0011483123525977135] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3195/5004] final loss [0.1303347796201706] accuracy[90.91] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[3196/5004] final loss [0.05975464731454849] accuracy[90.0] precision[0.0] recall[0.0] specificity[95.74] F1 score[0]\n",
      "[3197/5004] final loss [0.13637816905975342] accuracy[93.4] precision[12.5] recall[100.0] specificity[93.33] F1 score[0.22]\n",
      "[3198/5004] final loss [0.09815149009227753] accuracy[89.69] precision[7.14] recall[12.5] specificity[93.01] F1 score[0.09]\n",
      "[3199/5004] final loss [0.07227316498756409] accuracy[81.93] precision[0.0] recall[0.0] specificity[90.67] F1 score[0]\n",
      "[3200/5004] final loss [0.18098442256450653] accuracy[93.07] precision[0.0] recall[0] specificity[93.07] F1 score[0]\n",
      "[3201/5004] final loss [0.020565183833241463] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3202/5004] final loss [0.030854882672429085] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[3203/5004] final loss [0.10562361031770706] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3204/5004] final loss [0.22844266891479492] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3205/5004] final loss [0.04117703437805176] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3206/5004] final loss [0.08561921119689941] accuracy[66.67] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[3207/5004] final loss [0.13999401032924652] accuracy[90.48] precision[0.0] recall[0.0] specificity[98.28] F1 score[0]\n",
      "[3208/5004] final loss [0.2094152867794037] accuracy[90.2] precision[30.0] recall[27.27] specificity[95.07] F1 score[0.29]\n",
      "[3209/5004] final loss [0.13813135027885437] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3210/5004] final loss [0.021304527297616005] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[3211/5004] final loss [0.07004553824663162] accuracy[90.62] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[3212/5004] final loss [0.0395176000893116] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3213/5004] final loss [0.3263956606388092] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[3214/5004] final loss [0.0694890096783638] accuracy[91.49] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3215/5004] final loss [0.18060359358787537] accuracy[93.59] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[3216/5004] final loss [0.05405716598033905] accuracy[95.29] precision[0.0] recall[0.0] specificity[96.43] F1 score[0]\n",
      "[3217/5004] final loss [0.1544148027896881] accuracy[94.94] precision[50.0] recall[50.0] specificity[97.33] F1 score[0.5]\n",
      "[3218/5004] final loss [0.13945652544498444] accuracy[81.44] precision[17.65] recall[15.0] specificity[90.48] F1 score[0.16]\n",
      "[3219/5004] final loss [0.08036164939403534] accuracy[92.86] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[3220/5004] final loss [0.1304023116827011] accuracy[93.2] precision[25.0] recall[20.0] specificity[96.94] F1 score[0.22]\n",
      "[3221/5004] final loss [0.05820919945836067] accuracy[92.55] precision[0.0] recall[0] specificity[92.55] F1 score[0]\n",
      "[3222/5004] final loss [0.2050003707408905] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[3223/5004] final loss [0.048284515738487244] accuracy[88.15] precision[10.0] recall[5.88] specificity[95.36] F1 score[0.07]\n",
      "[3224/5004] final loss [0.18130125105381012] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[3225/5004] final loss [0.01536467857658863] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3226/5004] final loss [0.16889671981334686] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[3227/5004] final loss [0.1271033138036728] accuracy[93.51] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[3228/5004] final loss [0.07124774903059006] accuracy[93.33] precision[20.0] recall[25.0] specificity[96.04] F1 score[0.22]\n",
      "[3229/5004] final loss [0.05159172788262367] accuracy[90.7] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[3230/5004] final loss [0.09235825389623642] accuracy[96.2] precision[0.0] recall[0] specificity[96.2] F1 score[0]\n",
      "[3231/5004] final loss [0.06944648176431656] accuracy[93.65] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[3232/5004] final loss [0.06845123320817947] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[3233/5004] final loss [0.07552222907543182] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3234/5004] final loss [0.15327616035938263] accuracy[91.79] precision[0.0] recall[0.0] specificity[93.89] F1 score[0]\n",
      "[3235/5004] final loss [0.28804221749305725] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3236/5004] final loss [0.0304142776876688] accuracy[95.79] precision[0.0] recall[0] specificity[95.79] F1 score[0]\n",
      "[3237/5004] final loss [0.013814023695886135] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3238/5004] final loss [0.21766695380210876] accuracy[95.08] precision[0.0] recall[0.0] specificity[96.67] F1 score[0]\n",
      "[3239/5004] final loss [0.09963701665401459] accuracy[92.0] precision[10.0] recall[50.0] specificity[92.68] F1 score[0.17]\n",
      "[3240/5004] final loss [0.08712177723646164] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[3241/5004] final loss [0.2775729298591614] accuracy[89.04] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[3242/5004] final loss [0.21170145273208618] accuracy[85.71] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[3243/5004] final loss [0.28763630986213684] accuracy[76.23] precision[37.5] recall[11.11] specificity[94.74] F1 score[0.17]\n",
      "[3244/5004] final loss [0.11215738207101822] accuracy[95.95] precision[0.0] recall[0] specificity[95.95] F1 score[0]\n",
      "[3245/5004] final loss [0.07429724186658859] accuracy[96.0] precision[25.0] recall[100.0] specificity[95.95] F1 score[0.4]\n",
      "[3246/5004] final loss [0.0359194278717041] accuracy[92.0] precision[0.0] recall[0.0] specificity[93.24] F1 score[0]\n",
      "[3247/5004] final loss [0.07109877467155457] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[3248/5004] final loss [0.030405471101403236] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3249/5004] final loss [0.2531987428665161] accuracy[90.79] precision[16.67] recall[33.33] specificity[93.15] F1 score[0.22]\n",
      "[3250/5004] final loss [0.13394507765769958] accuracy[93.08] precision[0.0] recall[0.0] specificity[93.8] F1 score[0]\n",
      "[3251/5004] final loss [0.05233344808220863] accuracy[90.66] precision[0.0] recall[0.0] specificity[98.8] F1 score[0]\n",
      "[3252/5004] final loss [0.06164159998297691] accuracy[98.68] precision[0.0] recall[0] specificity[98.68] F1 score[0]\n",
      "[3253/5004] final loss [0.12588074803352356] accuracy[97.78] precision[0.0] recall[0] specificity[97.78] F1 score[0]\n",
      "[3254/5004] final loss [0.016704246401786804] accuracy[90.48] precision[0.0] recall[0] specificity[90.48] F1 score[0]\n",
      "[3255/5004] final loss [0.11906877905130386] accuracy[90.0] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[3256/5004] final loss [0.04859229549765587] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[3257/5004] final loss [0.13722841441631317] accuracy[88.93] precision[28.57] recall[19.05] specificity[95.52] F1 score[0.23]\n",
      "[3258/5004] final loss [0.2578916847705841] accuracy[85.5] precision[18.75] recall[10.71] specificity[94.44] F1 score[0.14]\n",
      "[3259/5004] final loss [0.17460720241069794] accuracy[94.47] precision[0.0] recall[0] specificity[94.47] F1 score[0]\n",
      "[3260/5004] final loss [0.12451465427875519] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3261/5004] final loss [0.01885458081960678] accuracy[94.92] precision[33.33] recall[20.0] specificity[98.23] F1 score[0.25]\n",
      "[3262/5004] final loss [0.05758756771683693] accuracy[93.42] precision[25.0] recall[33.33] specificity[95.89] F1 score[0.29]\n",
      "[3263/5004] final loss [0.08131051063537598] accuracy[91.06] precision[16.67] recall[14.29] specificity[95.69] F1 score[0.15]\n",
      "[3264/5004] final loss [0.0065775467082858086] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3265/5004] final loss [0.033467791974544525] accuracy[75.0] precision[0.0] recall[0.0] specificity[96.43] F1 score[0]\n",
      "[3266/5004] final loss [0.14014987647533417] accuracy[94.56] precision[11.76] recall[25.0] specificity[96.03] F1 score[0.16]\n",
      "[3267/5004] final loss [0.06223488599061966] accuracy[94.78] precision[0.0] recall[0] specificity[94.78] F1 score[0]\n",
      "[3268/5004] final loss [0.07410943508148193] accuracy[97.35] precision[0.0] recall[0] specificity[97.35] F1 score[0]\n",
      "[3269/5004] final loss [0.1982787847518921] accuracy[88.89] precision[0.0] recall[0.0] specificity[91.14] F1 score[0]\n",
      "[3270/5004] final loss [0.09834164381027222] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[3271/5004] final loss [0.142436683177948] accuracy[92.77] precision[0.0] recall[0] specificity[92.77] F1 score[0]\n",
      "[3272/5004] final loss [0.04374580457806587] accuracy[87.72] precision[50.0] recall[28.57] specificity[96.0] F1 score[0.36]\n",
      "[3273/5004] final loss [0.09259618073701859] accuracy[85.45] precision[0.0] recall[0.0] specificity[94.95] F1 score[0]\n",
      "[3274/5004] final loss [0.15283526480197906] accuracy[94.7] precision[0.0] recall[0.0] specificity[95.06] F1 score[0]\n",
      "[3275/5004] final loss [0.05386222526431084] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3276/5004] final loss [0.06043744832277298] accuracy[95.57] precision[0.0] recall[0.0] specificity[97.42] F1 score[0]\n",
      "[3277/5004] final loss [0.007861155085265636] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3278/5004] final loss [0.09226460009813309] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3279/5004] final loss [0.07987052947282791] accuracy[94.34] precision[0.0] recall[0] specificity[94.34] F1 score[0]\n",
      "[3280/5004] final loss [0.02372056618332863] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[3281/5004] final loss [0.008414904586970806] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3282/5004] final loss [0.10849220305681229] accuracy[93.62] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[3283/5004] final loss [0.11850167065858841] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3284/5004] final loss [0.2164354771375656] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3285/5004] final loss [0.16371573507785797] accuracy[89.47] precision[25.0] recall[20.0] specificity[95.12] F1 score[0.22]\n",
      "[3286/5004] final loss [0.11502368748188019] accuracy[93.75] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[3287/5004] final loss [0.06011655181646347] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[3288/5004] final loss [0.10673068463802338] accuracy[91.8] precision[0.0] recall[0] specificity[91.8] F1 score[0]\n",
      "[3289/5004] final loss [0.12384633719921112] accuracy[69.23] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[3290/5004] final loss [0.18702611327171326] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3291/5004] final loss [0.22123298048973083] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.03] F1 score[0]\n",
      "[3292/5004] final loss [0.04426240921020508] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[3293/5004] final loss [0.171549454331398] accuracy[83.33] precision[50.0] recall[22.22] specificity[95.56] F1 score[0.31]\n",
      "[3294/5004] final loss [0.0843837559223175] accuracy[66.67] precision[0.0] recall[0.0] specificity[85.71] F1 score[0]\n",
      "[3295/5004] final loss [0.08471784740686417] accuracy[91.67] precision[0.0] recall[0.0] specificity[97.78] F1 score[0]\n",
      "[3296/5004] final loss [0.11089741438627243] accuracy[91.92] precision[16.67] recall[25.0] specificity[94.74] F1 score[0.2]\n",
      "[3297/5004] final loss [0.1692168414592743] accuracy[93.89] precision[0.0] recall[0.0] specificity[94.41] F1 score[0]\n",
      "[3298/5004] final loss [0.011075157672166824] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[3299/5004] final loss [0.21781937777996063] accuracy[92.82] precision[0.0] recall[0] specificity[92.82] F1 score[0]\n",
      "[3300/5004] final loss [0.029287083074450493] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[3301/5004] final loss [0.27240902185440063] accuracy[97.22] precision[50.0] recall[100.0] specificity[97.14] F1 score[0.67]\n",
      "[3302/5004] final loss [0.11723385006189346] accuracy[66.67] precision[0.0] recall[0] specificity[66.67] F1 score[0]\n",
      "[3303/5004] final loss [0.24869734048843384] accuracy[94.2] precision[0.0] recall[0] specificity[94.2] F1 score[0]\n",
      "[3304/5004] final loss [0.25164344906806946] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[3305/5004] final loss [0.23203399777412415] accuracy[95.8] precision[0.0] recall[0] specificity[95.8] F1 score[0]\n",
      "[3306/5004] final loss [0.12229739129543304] accuracy[85.5] precision[15.38] recall[20.0] specificity[90.91] F1 score[0.17]\n",
      "[3307/5004] final loss [0.1093669980764389] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3308/5004] final loss [0.09655772149562836] accuracy[85.17] precision[33.33] recall[22.86] specificity[93.73] F1 score[0.27]\n",
      "[3309/5004] final loss [0.07804886996746063] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3310/5004] final loss [0.05870016664266586] accuracy[92.68] precision[0.0] recall[0] specificity[92.68] F1 score[0]\n",
      "[3311/5004] final loss [0.08225373178720474] accuracy[88.19] precision[0.0] recall[0.0] specificity[95.73] F1 score[0]\n",
      "[3312/5004] final loss [0.12501715123653412] accuracy[95.9] precision[0.0] recall[0.0] specificity[96.69] F1 score[0]\n",
      "[3313/5004] final loss [0.04680661857128143] accuracy[84.21] precision[100.0] recall[40.0] specificity[100.0] F1 score[0.57]\n",
      "[[3314/10000]] loop skipped\n",
      "[3315/5005] final loss [0.025935238227248192] accuracy[98.51] precision[0.0] recall[0] specificity[98.51] F1 score[0]\n",
      "[3316/5005] final loss [0.25064969062805176] accuracy[96.3] precision[0.0] recall[0.0] specificity[98.11] F1 score[0]\n",
      "[3317/5005] final loss [0.13865967094898224] accuracy[92.73] precision[50.0] recall[25.0] specificity[98.04] F1 score[0.33]\n",
      "[3318/5005] final loss [0.08814894407987595] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[3319/5005] final loss [0.0848601683974266] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3320/5005] final loss [0.3220422565937042] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3321/5005] final loss [0.20865017175674438] accuracy[92.09] precision[0.0] recall[0] specificity[92.09] F1 score[0]\n",
      "[3322/5005] final loss [0.04804568365216255] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[3323/5005] final loss [0.07307890802621841] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[3324/5005] final loss [0.098923459649086] accuracy[97.26] precision[0.0] recall[0] specificity[97.26] F1 score[0]\n",
      "[3325/5005] final loss [0.00796377845108509] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[3326/5005] final loss [0.3337761461734772] accuracy[95.47] precision[0.0] recall[0] specificity[95.47] F1 score[0]\n",
      "[3327/5005] final loss [0.1505821794271469] accuracy[90.12] precision[0.0] recall[0.0] specificity[93.59] F1 score[0]\n",
      "[3328/5005] final loss [0.0570426881313324] accuracy[95.0] precision[0.0] recall[0.0] specificity[98.96] F1 score[0]\n",
      "[3329/5005] final loss [0.05521102622151375] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[3330/5005] final loss [0.09892088919878006] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3331/5005] final loss [0.02902044914662838] accuracy[98.21] precision[0.0] recall[0] specificity[98.21] F1 score[0]\n",
      "[3332/5005] final loss [0.06888412684202194] accuracy[78.38] precision[50.0] recall[12.5] specificity[96.55] F1 score[0.2]\n",
      "[3333/5005] final loss [0.04099072888493538] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[3334/5005] final loss [0.22248904407024384] accuracy[95.15] precision[0.0] recall[0] specificity[95.15] F1 score[0]\n",
      "[3335/5005] final loss [0.22581155598163605] accuracy[94.09] precision[0.0] recall[0] specificity[94.09] F1 score[0]\n",
      "[3336/5005] final loss [0.09596904367208481] accuracy[95.95] precision[0.0] recall[0] specificity[95.95] F1 score[0]\n",
      "[3337/5005] final loss [0.2810569405555725] accuracy[80.8] precision[20.0] recall[11.11] specificity[92.52] F1 score[0.14]\n",
      "[3338/5005] final loss [0.3019254803657532] accuracy[94.54] precision[0.0] recall[0.0] specificity[95.58] F1 score[0]\n",
      "[3339/5005] final loss [0.09330325573682785] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.92] F1 score[0]\n",
      "[3340/5005] final loss [0.15859262645244598] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[3341/5005] final loss [0.04305148869752884] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3342/5005] final loss [0.08633258938789368] accuracy[92.59] precision[14.29] recall[100.0] specificity[92.5] F1 score[0.25]\n",
      "[3343/5005] final loss [0.03545641154050827] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3344/5005] final loss [0.10200075060129166] accuracy[85.11] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[3345/5005] final loss [0.4361611306667328] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[3346/5005] final loss [0.1238492876291275] accuracy[95.1] precision[0.0] recall[0] specificity[95.1] F1 score[0]\n",
      "[3347/5005] final loss [0.1548675298690796] accuracy[91.8] precision[16.67] recall[28.57] specificity[94.32] F1 score[0.21]\n",
      "[3348/5005] final loss [0.045692671090364456] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3349/5005] final loss [0.13955174386501312] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3350/5005] final loss [0.1241973266005516] accuracy[94.87] precision[0.0] recall[0] specificity[94.87] F1 score[0]\n",
      "[3351/5005] final loss [0.11953899264335632] accuracy[98.39] precision[0.0] recall[0] specificity[98.39] F1 score[0]\n",
      "[3352/5005] final loss [0.11611396074295044] accuracy[95.7] precision[0.0] recall[0] specificity[95.7] F1 score[0]\n",
      "[3353/5005] final loss [0.15993668138980865] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.2] F1 score[0]\n",
      "[3354/5005] final loss [0.06414873152971268] accuracy[94.81] precision[0.0] recall[0] specificity[94.81] F1 score[0]\n",
      "[3355/5005] final loss [0.021570971235632896] accuracy[95.12] precision[0.0] recall[0.0] specificity[97.5] F1 score[0]\n",
      "[3356/5005] final loss [0.0870608389377594] accuracy[87.8] precision[0.0] recall[0.0] specificity[88.89] F1 score[0]\n",
      "[3357/5005] final loss [0.1511019468307495] accuracy[93.96] precision[25.0] recall[40.0] specificity[95.83] F1 score[0.31]\n",
      "[3358/5005] final loss [0.16696344316005707] accuracy[95.72] precision[0.0] recall[0] specificity[95.72] F1 score[0]\n",
      "[3359/5005] final loss [0.2637910544872284] accuracy[89.47] precision[28.57] recall[18.18] specificity[95.9] F1 score[0.22]\n",
      "[3360/5005] final loss [0.10566019266843796] accuracy[92.5] precision[12.5] recall[11.11] specificity[96.34] F1 score[0.12]\n",
      "[3361/5005] final loss [0.16915582120418549] accuracy[95.79] precision[0.0] recall[0] specificity[95.79] F1 score[0]\n",
      "[3362/5005] final loss [0.0973990187048912] accuracy[89.47] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[3363/5005] final loss [0.1725015789270401] accuracy[95.0] precision[0.0] recall[0.0] specificity[95.53] F1 score[0]\n",
      "[3364/5005] final loss [0.19542363286018372] accuracy[91.18] precision[0.0] recall[0] specificity[91.18] F1 score[0]\n",
      "[3365/5005] final loss [0.07800526916980743] accuracy[95.38] precision[0.0] recall[0] specificity[95.38] F1 score[0]\n",
      "[3366/5005] final loss [0.03915177658200264] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3367/5005] final loss [0.1957070380449295] accuracy[81.98] precision[16.67] recall[3.7] specificity[96.55] F1 score[0.06]\n",
      "[3368/5005] final loss [0.11482866108417511] accuracy[93.02] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[3369/5005] final loss [0.004554798826575279] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3370/5005] final loss [0.03322981297969818] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3371/5005] final loss [0.14020311832427979] accuracy[86.6] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[3372/5005] final loss [0.04106861725449562] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3373/5005] final loss [0.015390091575682163] accuracy[97.78] precision[0.0] recall[0] specificity[97.78] F1 score[0]\n",
      "[3374/5005] final loss [0.06225239858031273] accuracy[90.0] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[3375/5005] final loss [0.11233080923557281] accuracy[92.5] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[3376/5005] final loss [0.07375070452690125] accuracy[93.24] precision[33.33] recall[66.67] specificity[94.37] F1 score[0.44]\n",
      "[3377/5005] final loss [0.1770075112581253] accuracy[87.65] precision[10.71] recall[15.79] specificity[92.01] F1 score[0.13]\n",
      "[3378/5005] final loss [0.049681197851896286] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[3379/5005] final loss [0.13563251495361328] accuracy[85.71] precision[11.54] recall[16.67] specificity[90.73] F1 score[0.14]\n",
      "[3380/5005] final loss [0.1492813527584076] accuracy[89.47] precision[0.0] recall[0.0] specificity[96.23] F1 score[0]\n",
      "[3381/5005] final loss [0.09547115862369537] accuracy[82.26] precision[25.0] recall[11.11] specificity[94.34] F1 score[0.15]\n",
      "[3382/5005] final loss [0.16039550304412842] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.79] F1 score[0]\n",
      "[3383/5005] final loss [0.06263221055269241] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[3384/5005] final loss [0.09004418551921844] accuracy[94.36] precision[0.0] recall[0.0] specificity[96.34] F1 score[0]\n",
      "[3385/5005] final loss [0.036138344556093216] accuracy[97.6] precision[0.0] recall[0] specificity[97.6] F1 score[0]\n",
      "[3386/5005] final loss [0.12402448803186417] accuracy[95.65] precision[50.0] recall[100.0] specificity[95.45] F1 score[0.67]\n",
      "[3387/5005] final loss [0.21635666489601135] accuracy[92.92] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[3388/5005] final loss [0.025038139894604683] accuracy[88.89] precision[33.33] recall[14.29] specificity[96.92] F1 score[0.2]\n",
      "[3389/5005] final loss [0.10160627961158752] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[3390/5005] final loss [0.1628515124320984] accuracy[89.66] precision[0.0] recall[0.0] specificity[91.23] F1 score[0]\n",
      "[3391/5005] final loss [0.0678110271692276] accuracy[91.67] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[3392/5005] final loss [0.20789365470409393] accuracy[88.07] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[3393/5005] final loss [0.17005322873592377] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3394/5005] final loss [0.008883350528776646] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3395/5005] final loss [0.06382544338703156] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3396/5005] final loss [0.04625286906957626] accuracy[95.59] precision[0.0] recall[0.0] specificity[97.01] F1 score[0]\n",
      "[3397/5005] final loss [0.06306528300046921] accuracy[91.46] precision[0.0] recall[0.0] specificity[95.29] F1 score[0]\n",
      "[3398/5005] final loss [0.11873945593833923] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.59] F1 score[0]\n",
      "[3399/5005] final loss [0.18097397685050964] accuracy[91.8] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[3400/5005] final loss [0.21476973593235016] accuracy[95.67] precision[0.0] recall[0.0] specificity[96.09] F1 score[0]\n",
      "[3401/5005] final loss [0.037580907344818115] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[3402/5005] final loss [0.08224596828222275] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[3403/5005] final loss [0.09651109576225281] accuracy[91.4] precision[0.0] recall[0] specificity[91.4] F1 score[0]\n",
      "[3404/5005] final loss [0.17086981236934662] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[3405/5005] final loss [0.03567695617675781] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3406/5005] final loss [0.07805380970239639] accuracy[92.71] precision[42.86] recall[50.0] specificity[95.56] F1 score[0.46]\n",
      "[3407/5005] final loss [0.24647025763988495] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[3408/5005] final loss [0.11375346034765244] accuracy[93.85] precision[0.0] recall[0.0] specificity[95.31] F1 score[0]\n",
      "[3409/5005] final loss [0.03436451405286789] accuracy[94.44] precision[0.0] recall[0.0] specificity[96.23] F1 score[0]\n",
      "[3410/5005] final loss [0.10644162446260452] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3411/5005] final loss [0.046462398022413254] accuracy[90.7] precision[0.0] recall[0] specificity[90.7] F1 score[0]\n",
      "[3412/5005] final loss [0.11596839129924774] accuracy[89.06] precision[10.53] recall[15.38] specificity[93.0] F1 score[0.13]\n",
      "[3413/5005] final loss [0.10460631549358368] accuracy[95.08] precision[50.0] recall[33.33] specificity[98.28] F1 score[0.4]\n",
      "[3414/5005] final loss [0.14144933223724365] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[3415/5005] final loss [0.40745988488197327] accuracy[89.8] precision[33.33] recall[25.0] specificity[95.56] F1 score[0.29]\n",
      "[3416/5005] final loss [0.16730643808841705] accuracy[90.13] precision[7.69] recall[25.0] specificity[91.89] F1 score[0.12]\n",
      "[3417/5005] final loss [0.2003438025712967] accuracy[94.44] precision[0.0] recall[0.0] specificity[96.23] F1 score[0]\n",
      "[3418/5005] final loss [0.12910068035125732] accuracy[94.74] precision[50.0] recall[50.0] specificity[97.22] F1 score[0.5]\n",
      "[3419/5005] final loss [0.14807157218456268] accuracy[90.3] precision[25.0] recall[22.22] specificity[95.2] F1 score[0.24]\n",
      "[3420/5005] final loss [0.0198875330388546] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3421/5005] final loss [0.13455995917320251] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[3422/5005] final loss [0.160047248005867] accuracy[78.62] precision[41.18] recall[22.58] specificity[92.19] F1 score[0.29]\n",
      "[3423/5005] final loss [0.08959557861089706] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3424/5005] final loss [0.17231249809265137] accuracy[93.78] precision[0.0] recall[0.0] specificity[94.69] F1 score[0]\n",
      "[3425/5005] final loss [0.18180270493030548] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[3426/5005] final loss [0.2436554878950119] accuracy[92.06] precision[27.27] recall[30.0] specificity[95.53] F1 score[0.29]\n",
      "[3427/5005] final loss [0.07288258522748947] accuracy[93.17] precision[0.0] recall[0.0] specificity[94.34] F1 score[0]\n",
      "[3428/5005] final loss [0.11625289171934128] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3429/5005] final loss [0.024830063804984093] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3430/5005] final loss [0.3047843277454376] accuracy[91.46] precision[5.88] recall[16.67] specificity[93.33] F1 score[0.09]\n",
      "[3431/5005] final loss [0.16234824061393738] accuracy[93.0] precision[0.0] recall[0.0] specificity[94.47] F1 score[0]\n",
      "[3432/5005] final loss [0.18898136913776398] accuracy[95.17] precision[0.0] recall[0.0] specificity[95.63] F1 score[0]\n",
      "[3433/5005] final loss [0.2597441077232361] accuracy[94.55] precision[0.0] recall[0] specificity[94.55] F1 score[0]\n",
      "[3434/5005] final loss [0.17119213938713074] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3435/5005] final loss [0.1490705907344818] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3436/5005] final loss [0.11514641344547272] accuracy[95.33] precision[20.0] recall[50.0] specificity[96.19] F1 score[0.29]\n",
      "[3437/5005] final loss [0.0996503233909607] accuracy[84.31] precision[0.0] recall[0.0] specificity[89.58] F1 score[0]\n",
      "[3438/5005] final loss [0.06942825019359589] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[3439/5005] final loss [0.11191736161708832] accuracy[92.45] precision[14.29] recall[33.33] specificity[94.17] F1 score[0.2]\n",
      "[3440/5005] final loss [0.17278413474559784] accuracy[90.32] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[3441/5005] final loss [0.23241186141967773] accuracy[84.51] precision[10.0] recall[11.76] specificity[90.82] F1 score[0.11]\n",
      "[3442/5005] final loss [0.18018192052841187] accuracy[86.71] precision[0.0] recall[0.0] specificity[91.18] F1 score[0]\n",
      "[3443/5005] final loss [0.09011805057525635] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[3444/5005] final loss [0.19492755830287933] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[3445/5005] final loss [0.08050272613763809] accuracy[95.92] precision[0.0] recall[0] specificity[95.92] F1 score[0]\n",
      "[3446/5005] final loss [0.03442586213350296] accuracy[96.12] precision[0.0] recall[0] specificity[96.12] F1 score[0]\n",
      "[3447/5005] final loss [0.014870218001306057] accuracy[93.69] precision[12.5] recall[100.0] specificity[93.64] F1 score[0.22]\n",
      "[3448/5005] final loss [0.060728318989276886] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3449/5005] final loss [0.03330137953162193] accuracy[83.05] precision[25.0] recall[12.5] specificity[94.12] F1 score[0.17]\n",
      "[3450/5005] final loss [0.0235453974455595] accuracy[95.4] precision[0.0] recall[0] specificity[95.4] F1 score[0]\n",
      "[3451/5005] final loss [0.06133219972252846] accuracy[90.41] precision[0.0] recall[0.0] specificity[92.96] F1 score[0]\n",
      "[3452/5005] final loss [0.09654013067483902] accuracy[94.44] precision[14.29] recall[50.0] specificity[95.16] F1 score[0.22]\n",
      "[3453/5005] final loss [0.06193982809782028] accuracy[95.08] precision[0.0] recall[0] specificity[95.08] F1 score[0]\n",
      "[3454/5005] final loss [0.18613019585609436] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3455/5005] final loss [0.11596934497356415] accuracy[94.9] precision[16.67] recall[100.0] specificity[94.85] F1 score[0.29]\n",
      "[3456/5005] final loss [0.19266217947006226] accuracy[93.06] precision[0.0] recall[0] specificity[93.06] F1 score[0]\n",
      "[3457/5005] final loss [0.1299573928117752] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3458/5005] final loss [0.16540971398353577] accuracy[93.33] precision[16.67] recall[20.0] specificity[96.15] F1 score[0.18]\n",
      "[3459/5005] final loss [0.11381729692220688] accuracy[92.5] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[3460/5005] final loss [0.023613812401890755] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3461/5005] final loss [0.1579563021659851] accuracy[90.48] precision[0.0] recall[0] specificity[90.48] F1 score[0]\n",
      "[3462/5005] final loss [0.07789166271686554] accuracy[89.87] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[3463/5005] final loss [0.1586550623178482] accuracy[94.62] precision[0.0] recall[0] specificity[94.62] F1 score[0]\n",
      "[3464/5005] final loss [0.016225991770625114] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[3465/5005] final loss [0.14769808948040009] accuracy[87.62] precision[15.38] recall[50.0] specificity[89.11] F1 score[0.24]\n",
      "[3466/5005] final loss [0.08519421517848969] accuracy[92.54] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[3467/5005] final loss [0.10306379944086075] accuracy[87.69] precision[0.0] recall[0.0] specificity[92.43] F1 score[0]\n",
      "[3468/5005] final loss [0.06764960289001465] accuracy[86.36] precision[0.0] recall[0.0] specificity[97.44] F1 score[0]\n",
      "[3469/5005] final loss [0.1330179125070572] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[3470/5005] final loss [0.08260205388069153] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[3471/5005] final loss [0.15573914349079132] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3472/5005] final loss [0.30639663338661194] accuracy[87.86] precision[4.17] recall[33.33] specificity[88.67] F1 score[0.07]\n",
      "[3473/5005] final loss [0.13553877174854279] accuracy[92.23] precision[0.0] recall[0] specificity[92.23] F1 score[0]\n",
      "[3474/5005] final loss [0.1365438550710678] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3475/5005] final loss [0.0609302744269371] accuracy[91.09] precision[0.0] recall[0.0] specificity[96.84] F1 score[0]\n",
      "[3476/5005] final loss [0.06053826957941055] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[3477/5005] final loss [0.2752114236354828] accuracy[94.24] precision[0.0] recall[0] specificity[94.24] F1 score[0]\n",
      "[3478/5005] final loss [0.03188060596585274] accuracy[98.15] precision[66.67] recall[100.0] specificity[98.08] F1 score[0.8]\n",
      "[3479/5005] final loss [0.1487238109111786] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3480/5005] final loss [0.0737171545624733] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[3481/5005] final loss [0.2407199591398239] accuracy[92.67] precision[22.22] recall[33.33] specificity[95.14] F1 score[0.27]\n",
      "[3482/5005] final loss [0.043164025992155075] accuracy[73.87] precision[0.0] recall[0.0] specificity[93.18] F1 score[0]\n",
      "[3483/5005] final loss [0.2396962195634842] accuracy[88.17] precision[4.55] recall[7.69] specificity[92.11] F1 score[0.06]\n",
      "[3484/5005] final loss [0.104311503469944] accuracy[91.07] precision[0.0] recall[0.0] specificity[92.73] F1 score[0]\n",
      "[3485/5005] final loss [0.11274965852499008] accuracy[92.89] precision[0.0] recall[0.0] specificity[94.33] F1 score[0]\n",
      "[3486/5005] final loss [0.10808724164962769] accuracy[75.93] precision[100.0] recall[7.14] specificity[100.0] F1 score[0.13]\n",
      "[3487/5005] final loss [0.07254530489444733] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3488/5005] final loss [0.12434785813093185] accuracy[92.48] precision[0.0] recall[0.0] specificity[93.18] F1 score[0]\n",
      "[3489/5005] final loss [0.08240088075399399] accuracy[93.48] precision[0.0] recall[0.0] specificity[97.73] F1 score[0]\n",
      "[3490/5005] final loss [0.07251249998807907] accuracy[86.11] precision[0.0] recall[0.0] specificity[91.18] F1 score[0]\n",
      "[3491/5005] final loss [0.022320818156003952] accuracy[88.57] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[3492/5005] final loss [0.19973275065422058] accuracy[91.58] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[3493/5005] final loss [0.1185653880238533] accuracy[92.25] precision[28.57] recall[28.57] specificity[95.9] F1 score[0.29]\n",
      "[3494/5005] final loss [0.07831490784883499] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[3495/5005] final loss [0.02795729786157608] accuracy[83.08] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[3496/5005] final loss [0.08141204714775085] accuracy[87.93] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[3497/5005] final loss [0.11172991245985031] accuracy[92.98] precision[20.0] recall[20.0] specificity[96.33] F1 score[0.2]\n",
      "[3498/5005] final loss [0.12952715158462524] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3499/5005] final loss [0.13304150104522705] accuracy[93.59] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[3500/5005] final loss [0.22599735856056213] accuracy[92.0] precision[0.0] recall[0.0] specificity[93.88] F1 score[0]\n",
      "[3501/5005] final loss [0.210127055644989] accuracy[90.24] precision[0.0] recall[0] specificity[90.24] F1 score[0]\n",
      "[3502/5005] final loss [0.14095145463943481] accuracy[94.29] precision[20.0] recall[100.0] specificity[94.2] F1 score[0.33]\n",
      "[3503/5005] final loss [0.19214214384555817] accuracy[85.38] precision[6.67] recall[5.56] specificity[92.78] F1 score[0.06]\n",
      "[3504/5005] final loss [0.21957974135875702] accuracy[87.08] precision[21.74] recall[22.73] specificity[92.77] F1 score[0.22]\n",
      "[3505/5005] final loss [0.052138157188892365] accuracy[88.89] precision[0.0] recall[0.0] specificity[91.43] F1 score[0]\n",
      "[3506/5005] final loss [0.0126962224021554] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3507/5005] final loss [0.15705332159996033] accuracy[91.94] precision[0.0] recall[0] specificity[91.94] F1 score[0]\n",
      "[3508/5005] final loss [0.299954891204834] accuracy[78.99] precision[12.5] recall[7.5] specificity[91.1] F1 score[0.09]\n",
      "[3509/5005] final loss [0.052219875156879425] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3510/5005] final loss [0.13857224583625793] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[3511/5005] final loss [0.25770455598831177] accuracy[86.49] precision[10.0] recall[8.33] specificity[93.38] F1 score[0.09]\n",
      "[3512/5005] final loss [0.14617840945720673] accuracy[90.13] precision[12.5] recall[11.11] specificity[95.1] F1 score[0.12]\n",
      "[3513/5005] final loss [0.08473395556211472] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[3514/5005] final loss [0.12487958371639252] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[3515/5005] final loss [0.02759716473519802] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3516/5005] final loss [0.13985170423984528] accuracy[91.01] precision[33.33] recall[33.33] specificity[95.18] F1 score[0.33]\n",
      "[3517/5005] final loss [0.1128220409154892] accuracy[86.1] precision[37.5] recall[12.5] specificity[96.93] F1 score[0.19]\n",
      "[3518/5005] final loss [0.41439133882522583] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[3519/5005] final loss [0.02122313529253006] accuracy[96.47] precision[0.0] recall[0] specificity[96.47] F1 score[0]\n",
      "[3520/5005] final loss [0.1367584615945816] accuracy[93.52] precision[0.0] recall[0] specificity[93.52] F1 score[0]\n",
      "[3521/5005] final loss [0.18391096591949463] accuracy[80.0] precision[12.5] recall[7.69] specificity[91.46] F1 score[0.1]\n",
      "[3522/5005] final loss [0.07450640946626663] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3523/5005] final loss [0.07522313296794891] accuracy[93.57] precision[20.0] recall[16.67] specificity[97.01] F1 score[0.18]\n",
      "[3524/5005] final loss [0.018850181251764297] accuracy[85.0] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[3525/5005] final loss [0.08506462723016739] accuracy[96.43] precision[33.33] recall[100.0] specificity[96.36] F1 score[0.5]\n",
      "[3526/5005] final loss [0.1793033480644226] accuracy[90.11] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[3527/5005] final loss [0.024114402011036873] accuracy[91.92] precision[0.0] recall[0.0] specificity[93.81] F1 score[0]\n",
      "[3528/5005] final loss [0.10570160299539566] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[3529/5005] final loss [0.07075484842061996] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3530/5005] final loss [0.04302798584103584] accuracy[93.44] precision[0.0] recall[0] specificity[93.44] F1 score[0]\n",
      "[3531/5005] final loss [0.1616905927658081] accuracy[91.18] precision[0.0] recall[0.0] specificity[94.9] F1 score[0]\n",
      "[3532/5005] final loss [0.06321132928133011] accuracy[95.52] precision[0.0] recall[0] specificity[95.52] F1 score[0]\n",
      "[3533/5005] final loss [0.0770859643816948] accuracy[91.4] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[3534/5005] final loss [0.1417173445224762] accuracy[90.45] precision[6.25] recall[100.0] specificity[90.38] F1 score[0.12]\n",
      "[3535/5005] final loss [0.1405729353427887] accuracy[93.68] precision[38.46] recall[62.5] specificity[95.18] F1 score[0.48]\n",
      "[3536/5005] final loss [0.15728822350502014] accuracy[89.69] precision[0.0] recall[0.0] specificity[91.4] F1 score[0]\n",
      "[3537/5005] final loss [0.16893769800662994] accuracy[91.74] precision[14.29] recall[20.0] specificity[94.83] F1 score[0.17]\n",
      "[3538/5005] final loss [0.07083913683891296] accuracy[93.48] precision[0.0] recall[0.0] specificity[95.56] F1 score[0]\n",
      "[3539/5005] final loss [0.043571699410676956] accuracy[94.37] precision[25.0] recall[50.0] specificity[95.65] F1 score[0.33]\n",
      "[3540/5005] final loss [0.1807071715593338] accuracy[80.0] precision[9.09] recall[9.09] specificity[88.76] F1 score[0.09]\n",
      "[3541/5005] final loss [0.1511445790529251] accuracy[89.43] precision[14.29] recall[23.53] specificity[92.79] F1 score[0.18]\n",
      "[3542/5005] final loss [0.12125786393880844] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[3543/5005] final loss [0.1210641860961914] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3544/5005] final loss [0.08317158371210098] accuracy[81.29] precision[7.14] recall[5.88] specificity[90.58] F1 score[0.06]\n",
      "[3545/5005] final loss [0.022634267807006836] accuracy[92.86] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[3546/5005] final loss [0.1782287061214447] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[3547/5005] final loss [0.02801143191754818] accuracy[93.06] precision[0.0] recall[0.0] specificity[95.71] F1 score[0]\n",
      "[3548/5005] final loss [0.10022827237844467] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[3549/5005] final loss [0.13266631960868835] accuracy[89.29] precision[0.0] recall[0.0] specificity[93.28] F1 score[0]\n",
      "[3550/5005] final loss [0.206297367811203] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3551/5005] final loss [0.09603310376405716] accuracy[87.88] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[3552/5005] final loss [0.2104826718568802] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[3553/5005] final loss [0.13888022303581238] accuracy[93.26] precision[0.0] recall[0.0] specificity[95.4] F1 score[0]\n",
      "[3554/5005] final loss [0.009093728847801685] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3555/5005] final loss [0.05950452387332916] accuracy[90.78] precision[0.0] recall[0.0] specificity[93.36] F1 score[0]\n",
      "[3556/5005] final loss [0.06396570801734924] accuracy[96.32] precision[16.67] recall[100.0] specificity[96.3] F1 score[0.29]\n",
      "[3557/5005] final loss [0.1018291786313057] accuracy[86.67] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[3558/5005] final loss [0.14466971158981323] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[3559/5005] final loss [0.18583399057388306] accuracy[89.71] precision[5.0] recall[10.0] specificity[92.75] F1 score[0.07]\n",
      "[3560/5005] final loss [0.33044344186782837] accuracy[91.61] precision[0.0] recall[0.0] specificity[92.81] F1 score[0]\n",
      "[3561/5005] final loss [0.07509640604257584] accuracy[94.87] precision[14.29] recall[100.0] specificity[94.83] F1 score[0.25]\n",
      "[3562/5005] final loss [0.030034905299544334] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[3563/5005] final loss [0.1316358894109726] accuracy[94.67] precision[0.0] recall[0] specificity[94.67] F1 score[0]\n",
      "[3564/5005] final loss [0.14794513583183289] accuracy[87.77] precision[10.0] recall[11.11] specificity[93.08] F1 score[0.11]\n",
      "[3565/5005] final loss [0.010180785320699215] accuracy[95.52] precision[0.0] recall[0] specificity[95.52] F1 score[0]\n",
      "[3566/5005] final loss [0.05373123660683632] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3567/5005] final loss [0.19050143659114838] accuracy[84.73] precision[41.67] recall[37.04] specificity[92.05] F1 score[0.39]\n",
      "[3568/5005] final loss [0.03567010909318924] accuracy[91.67] precision[0.0] recall[0.0] specificity[92.96] F1 score[0]\n",
      "[3569/5005] final loss [0.04266816005110741] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3570/5005] final loss [0.01082141324877739] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3571/5005] final loss [0.0008804008248262107] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3572/5005] final loss [0.14048004150390625] accuracy[93.94] precision[0.0] recall[0.0] specificity[94.51] F1 score[0]\n",
      "[3573/5005] final loss [0.21641121804714203] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3574/5005] final loss [0.13116104900836945] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3575/5005] final loss [0.15057280659675598] accuracy[94.38] precision[0.0] recall[0.0] specificity[96.55] F1 score[0]\n",
      "[3576/5005] final loss [0.20040231943130493] accuracy[95.06] precision[0.0] recall[0.0] specificity[96.25] F1 score[0]\n",
      "[3577/5005] final loss [0.18277689814567566] accuracy[91.95] precision[0.0] recall[0.0] specificity[96.48] F1 score[0]\n",
      "[3578/5005] final loss [0.024008657783269882] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[3579/5005] final loss [0.054099492728710175] accuracy[91.14] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[3580/5005] final loss [0.0933496430516243] accuracy[91.95] precision[0.0] recall[0.0] specificity[93.02] F1 score[0]\n",
      "[3581/5005] final loss [0.022726861760020256] accuracy[97.06] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3582/5005] final loss [0.20018820464611053] accuracy[94.92] precision[0.0] recall[0.0] specificity[98.25] F1 score[0]\n",
      "[3583/5005] final loss [0.1667037010192871] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3584/5005] final loss [0.05512470752000809] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3585/5005] final loss [0.12630842626094818] accuracy[93.65] precision[0.0] recall[0] specificity[93.65] F1 score[0]\n",
      "[3586/5005] final loss [0.09277532994747162] accuracy[88.28] precision[0.0] recall[0.0] specificity[92.09] F1 score[0]\n",
      "[3587/5005] final loss [0.045537739992141724] accuracy[93.75] precision[20.0] recall[20.0] specificity[96.75] F1 score[0.2]\n",
      "[3588/5005] final loss [0.15674833953380585] accuracy[91.82] precision[20.0] recall[16.67] specificity[96.15] F1 score[0.18]\n",
      "[3589/5005] final loss [0.11370932310819626] accuracy[92.8] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[3590/5005] final loss [0.16113346815109253] accuracy[90.59] precision[60.0] recall[33.33] specificity[97.37] F1 score[0.43]\n",
      "[3591/5005] final loss [0.1603662520647049] accuracy[84.75] precision[40.0] recall[25.0] specificity[94.12] F1 score[0.31]\n",
      "[3592/5005] final loss [0.07462450861930847] accuracy[89.15] precision[50.0] recall[21.43] specificity[97.39] F1 score[0.3]\n",
      "[3593/5005] final loss [0.10638625174760818] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3594/5005] final loss [0.0801771879196167] accuracy[90.91] precision[0.0] recall[0.0] specificity[96.39] F1 score[0]\n",
      "[3595/5005] final loss [0.13830652832984924] accuracy[94.96] precision[0.0] recall[0] specificity[94.96] F1 score[0]\n",
      "[3596/5005] final loss [0.1058434545993805] accuracy[91.91] precision[12.5] recall[20.0] specificity[94.66] F1 score[0.15]\n",
      "[3597/5005] final loss [0.15074829757213593] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[3598/5005] final loss [0.2211255133152008] accuracy[91.1] precision[27.27] recall[37.5] specificity[94.2] F1 score[0.32]\n",
      "[3599/5005] final loss [0.2725923955440521] accuracy[90.21] precision[28.57] recall[30.77] specificity[94.48] F1 score[0.3]\n",
      "[3600/5005] final loss [0.06353932619094849] accuracy[80.0] precision[0.0] recall[0] specificity[80.0] F1 score[0]\n",
      "[3601/5005] final loss [0.06993132829666138] accuracy[86.21] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[3602/5005] final loss [0.19818121194839478] accuracy[91.61] precision[9.09] recall[33.33] specificity[92.86] F1 score[0.14]\n",
      "[3603/5005] final loss [0.09230977296829224] accuracy[89.4] precision[0.0] recall[0.0] specificity[92.82] F1 score[0]\n",
      "[3604/5005] final loss [0.14061306416988373] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[3605/5005] final loss [0.12305400520563126] accuracy[90.73] precision[45.45] recall[27.78] specificity[96.79] F1 score[0.34]\n",
      "[3606/5005] final loss [0.11084239184856415] accuracy[89.13] precision[0.0] recall[0.0] specificity[92.13] F1 score[0]\n",
      "[3607/5005] final loss [0.24987894296646118] accuracy[96.67] precision[0.0] recall[0.0] specificity[98.31] F1 score[0]\n",
      "[3608/5005] final loss [0.17506106197834015] accuracy[95.88] precision[0.0] recall[0] specificity[95.88] F1 score[0]\n",
      "[3609/5005] final loss [0.1721488982439041] accuracy[95.73] precision[0.0] recall[0] specificity[95.73] F1 score[0]\n",
      "[3610/5005] final loss [0.08888184279203415] accuracy[89.61] precision[0.0] recall[0.0] specificity[94.52] F1 score[0]\n",
      "[3611/5005] final loss [0.014464070089161396] accuracy[91.3] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[3612/5005] final loss [0.10068421065807343] accuracy[82.76] precision[0.0] recall[0.0] specificity[88.89] F1 score[0]\n",
      "[3613/5005] final loss [0.020136352628469467] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3614/5005] final loss [0.21371205151081085] accuracy[92.5] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[3615/5005] final loss [0.3682402968406677] accuracy[70.37] precision[0.0] recall[0.0] specificity[90.48] F1 score[0]\n",
      "[3616/5005] final loss [0.053846877068281174] accuracy[93.62] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[3617/5005] final loss [0.033779043704271317] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[3618/5005] final loss [0.11288543045520782] accuracy[88.24] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[3619/5005] final loss [0.10523857176303864] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[3620/5005] final loss [0.1492125391960144] accuracy[91.89] precision[28.57] recall[33.33] specificity[95.24] F1 score[0.31]\n",
      "[3621/5005] final loss [0.04621046036481857] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[3622/5005] final loss [0.10085027664899826] accuracy[95.16] precision[12.5] recall[33.33] specificity[96.17] F1 score[0.18]\n",
      "[3623/5005] final loss [0.19694207608699799] accuracy[92.73] precision[0.0] recall[0.0] specificity[94.1] F1 score[0]\n",
      "[3624/5005] final loss [0.13663530349731445] accuracy[84.27] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[3625/5005] final loss [0.2036350965499878] accuracy[88.62] precision[0.0] recall[0.0] specificity[89.34] F1 score[0]\n",
      "[3626/5005] final loss [0.33201542496681213] accuracy[75.61] precision[0.0] recall[0.0] specificity[88.57] F1 score[0]\n",
      "[3627/5005] final loss [0.0010086450492963195] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3628/5005] final loss [0.11045534163713455] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3629/5005] final loss [0.025416091084480286] accuracy[87.32] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[3630/5005] final loss [0.1737479418516159] accuracy[92.71] precision[0.0] recall[0.0] specificity[94.68] F1 score[0]\n",
      "[3631/5005] final loss [0.08987610042095184] accuracy[90.79] precision[0.0] recall[0.0] specificity[93.24] F1 score[0]\n",
      "[3632/5005] final loss [0.09116340428590775] accuracy[91.45] precision[0.0] recall[0.0] specificity[93.37] F1 score[0]\n",
      "[3633/5005] final loss [0.0966779887676239] accuracy[97.78] precision[0.0] recall[0] specificity[97.78] F1 score[0]\n",
      "[3634/5005] final loss [0.27441996335983276] accuracy[92.31] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[3635/5005] final loss [0.02291991375386715] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3636/5005] final loss [0.014731064438819885] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3637/5005] final loss [0.23168379068374634] accuracy[93.22] precision[0.0] recall[0] specificity[93.22] F1 score[0]\n",
      "[3638/5005] final loss [0.0389571450650692] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[3639/5005] final loss [0.3245169520378113] accuracy[96.83] precision[0.0] recall[0] specificity[96.83] F1 score[0]\n",
      "[3640/5005] final loss [0.17520280182361603] accuracy[95.11] precision[0.0] recall[0] specificity[95.11] F1 score[0]\n",
      "[3641/5005] final loss [0.031786248087882996] accuracy[86.84] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[3642/5005] final loss [0.04061306640505791] accuracy[77.78] precision[0.0] recall[0.0] specificity[96.55] F1 score[0]\n",
      "[3643/5005] final loss [0.18068276345729828] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[3644/5005] final loss [0.09528443962335587] accuracy[88.24] precision[0.0] recall[0.0] specificity[94.94] F1 score[0]\n",
      "[3645/5005] final loss [0.08908902853727341] accuracy[93.83] precision[16.67] recall[100.0] specificity[93.75] F1 score[0.29]\n",
      "[3646/5005] final loss [0.18932731449604034] accuracy[86.67] precision[66.67] recall[40.0] specificity[96.0] F1 score[0.5]\n",
      "[3647/5005] final loss [0.1779002696275711] accuracy[86.62] precision[33.33] recall[26.67] specificity[93.7] F1 score[0.3]\n",
      "[3648/5005] final loss [0.07329113781452179] accuracy[93.2] precision[25.0] recall[20.0] specificity[96.94] F1 score[0.22]\n",
      "[3649/5005] final loss [0.233214870095253] accuracy[86.18] precision[0.0] recall[0.0] specificity[92.17] F1 score[0]\n",
      "[3650/5005] final loss [0.2023317813873291] accuracy[95.71] precision[40.0] recall[80.0] specificity[96.2] F1 score[0.53]\n",
      "[3651/5005] final loss [0.16224275529384613] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[3652/5005] final loss [0.10528632998466492] accuracy[95.42] precision[0.0] recall[0.0] specificity[96.69] F1 score[0]\n",
      "[3653/5005] final loss [0.044455718249082565] accuracy[95.35] precision[0.0] recall[0.0] specificity[97.62] F1 score[0]\n",
      "[3654/5005] final loss [0.19140838086605072] accuracy[93.98] precision[0.0] recall[0] specificity[93.98] F1 score[0]\n",
      "[3655/5005] final loss [0.12038294225931168] accuracy[95.32] precision[20.0] recall[100.0] specificity[95.27] F1 score[0.33]\n",
      "[3656/5005] final loss [0.21366634964942932] accuracy[83.78] precision[0.0] recall[0.0] specificity[91.18] F1 score[0]\n",
      "[3657/5005] final loss [0.199217289686203] accuracy[93.4] precision[33.33] recall[40.0] specificity[96.04] F1 score[0.36]\n",
      "[3658/5005] final loss [0.11058863252401352] accuracy[93.15] precision[20.0] recall[50.0] specificity[94.37] F1 score[0.29]\n",
      "[3659/5005] final loss [0.30165886878967285] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[3660/5005] final loss [0.15908804535865784] accuracy[94.42] precision[0.0] recall[0.0] specificity[94.8] F1 score[0]\n",
      "[3661/5005] final loss [0.032074637711048126] accuracy[90.7] precision[33.33] recall[33.33] specificity[95.0] F1 score[0.33]\n",
      "[3662/5005] final loss [0.11703038960695267] accuracy[89.36] precision[0.0] recall[0.0] specificity[96.55] F1 score[0]\n",
      "[3663/5005] final loss [0.1270023137331009] accuracy[94.74] precision[0.0] recall[0.0] specificity[96.64] F1 score[0]\n",
      "[3664/5005] final loss [0.08396497368812561] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3665/5005] final loss [0.08659190684556961] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3666/5005] final loss [0.19839097559452057] accuracy[81.82] precision[22.22] recall[13.33] specificity[92.63] F1 score[0.17]\n",
      "[3667/5005] final loss [0.13023683428764343] accuracy[90.14] precision[100.0] recall[22.22] specificity[100.0] F1 score[0.36]\n",
      "[3668/5005] final loss [0.055671557784080505] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3669/5005] final loss [0.06436145305633545] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[3670/5005] final loss [0.12947753071784973] accuracy[85.0] precision[0.0] recall[0.0] specificity[89.47] F1 score[0]\n",
      "[3671/5005] final loss [0.10457940399646759] accuracy[89.6] precision[27.27] recall[28.57] specificity[94.22] F1 score[0.28]\n",
      "[3672/5005] final loss [0.1736946702003479] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[3673/5005] final loss [0.1307460516691208] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[3674/5005] final loss [0.0822586864233017] accuracy[92.5] precision[0.0] recall[0] specificity[92.5] F1 score[0]\n",
      "[3675/5005] final loss [0.20983438193798065] accuracy[86.78] precision[0.0] recall[0.0] specificity[88.98] F1 score[0]\n",
      "[3676/5005] final loss [0.031593091785907745] accuracy[95.24] precision[0.0] recall[0.0] specificity[98.04] F1 score[0]\n",
      "[3677/5005] final loss [0.10639984905719757] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[3678/5005] final loss [0.1892833411693573] accuracy[91.3] precision[0.0] recall[0.0] specificity[94.03] F1 score[0]\n",
      "[3679/5005] final loss [0.15533661842346191] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3680/5005] final loss [0.05464697629213333] accuracy[93.85] precision[0.0] recall[0] specificity[93.85] F1 score[0]\n",
      "[3681/5005] final loss [0.07346304506063461] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3682/5005] final loss [0.11052262037992477] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[3683/5005] final loss [0.06487772613763809] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3684/5005] final loss [0.22723960876464844] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[3685/5005] final loss [0.1206548810005188] accuracy[93.17] precision[0.0] recall[0] specificity[93.17] F1 score[0]\n",
      "[3686/5005] final loss [0.13792066276073456] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[3687/5005] final loss [0.0808064192533493] accuracy[95.08] precision[50.0] recall[33.33] specificity[98.28] F1 score[0.4]\n",
      "[3688/5005] final loss [0.100509874522686] accuracy[90.54] precision[20.0] recall[25.0] specificity[94.29] F1 score[0.22]\n",
      "[3689/5005] final loss [0.3400709927082062] accuracy[92.68] precision[0.0] recall[0] specificity[92.68] F1 score[0]\n",
      "[3690/5005] final loss [0.14968886971473694] accuracy[85.67] precision[40.0] recall[26.32] specificity[94.27] F1 score[0.32]\n",
      "[3691/5005] final loss [0.20368948578834534] accuracy[81.98] precision[25.0] recall[12.5] specificity[93.68] F1 score[0.17]\n",
      "[3692/5005] final loss [0.04808106645941734] accuracy[89.66] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[3693/5005] final loss [0.03897488862276077] accuracy[97.44] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3694/5005] final loss [0.1727258563041687] accuracy[94.37] precision[0.0] recall[0] specificity[94.37] F1 score[0]\n",
      "[3695/5005] final loss [0.191098153591156] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3696/5005] final loss [0.018162954598665237] accuracy[97.78] precision[0.0] recall[0] specificity[97.78] F1 score[0]\n",
      "[3697/5005] final loss [0.08143563568592072] accuracy[92.92] precision[12.5] recall[50.0] specificity[93.69] F1 score[0.2]\n",
      "[3698/5005] final loss [0.08435152471065521] accuracy[92.39] precision[16.67] recall[33.33] specificity[94.38] F1 score[0.22]\n",
      "[3699/5005] final loss [0.003237287513911724] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3700/5005] final loss [0.1141471415758133] accuracy[91.57] precision[20.0] recall[25.0] specificity[94.94] F1 score[0.22]\n",
      "[3701/5005] final loss [0.049869075417518616] accuracy[77.78] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[3702/5005] final loss [0.05499604344367981] accuracy[96.36] precision[0.0] recall[0] specificity[96.36] F1 score[0]\n",
      "[3703/5005] final loss [0.029173986986279488] accuracy[96.43] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3704/5005] final loss [0.2811047434806824] accuracy[77.66] precision[20.0] recall[8.57] specificity[92.59] F1 score[0.12]\n",
      "[3705/5005] final loss [0.1314336359500885] accuracy[85.26] precision[0.0] recall[0.0] specificity[92.36] F1 score[0]\n",
      "[3706/5005] final loss [0.11180554330348969] accuracy[94.81] precision[33.33] recall[33.33] specificity[97.3] F1 score[0.33]\n",
      "[3707/5005] final loss [0.07406184822320938] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[3708/5005] final loss [0.016537297517061234] accuracy[90.91] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[3709/5005] final loss [0.5386835336685181] accuracy[93.98] precision[0.0] recall[0] specificity[93.98] F1 score[0]\n",
      "[3710/5005] final loss [0.3439229726791382] accuracy[78.41] precision[0.0] recall[0.0] specificity[90.79] F1 score[0]\n",
      "[3711/5005] final loss [0.03634596988558769] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3712/5005] final loss [0.0595959834754467] accuracy[92.73] precision[0.0] recall[0.0] specificity[98.08] F1 score[0]\n",
      "[3713/5005] final loss [0.03930884599685669] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[3714/5005] final loss [0.1068434789776802] accuracy[87.76] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[3715/5005] final loss [0.022522706538438797] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3716/5005] final loss [0.2843587100505829] accuracy[96.2] precision[0.0] recall[0] specificity[96.2] F1 score[0]\n",
      "[3717/5005] final loss [0.11464764922857285] accuracy[95.16] precision[0.0] recall[0] specificity[95.16] F1 score[0]\n",
      "[3718/5005] final loss [0.16931061446666718] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[3719/5005] final loss [0.10054769366979599] accuracy[92.0] precision[100.0] recall[20.0] specificity[100.0] F1 score[0.33]\n",
      "[3720/5005] final loss [0.05482282489538193] accuracy[91.01] precision[0.0] recall[0.0] specificity[92.05] F1 score[0]\n",
      "[3721/5005] final loss [0.12884414196014404] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[3722/5005] final loss [0.17457661032676697] accuracy[93.59] precision[0.0] recall[0.0] specificity[93.89] F1 score[0]\n",
      "[3723/5005] final loss [0.13177186250686646] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3724/5005] final loss [0.0845828726887703] accuracy[69.09] precision[20.0] recall[7.14] specificity[90.24] F1 score[0.11]\n",
      "[3725/5005] final loss [0.016230138018727303] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[3726/5005] final loss [0.017041616141796112] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[3727/5005] final loss [0.16319581866264343] accuracy[94.7] precision[0.0] recall[0] specificity[94.7] F1 score[0]\n",
      "[[3728/10000]] loop skipped\n",
      "[3729/5006] final loss [0.1109367311000824] accuracy[86.39] precision[28.57] recall[11.76] specificity[96.15] F1 score[0.17]\n",
      "[3730/5006] final loss [0.18685844540596008] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3731/5006] final loss [0.204732745885849] accuracy[90.65] precision[0.0] recall[0.0] specificity[93.72] F1 score[0]\n",
      "[3732/5006] final loss [0.01572709158062935] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[3733/5006] final loss [0.09362594038248062] accuracy[91.94] precision[0.0] recall[0.0] specificity[93.44] F1 score[0]\n",
      "[3734/5006] final loss [0.12971331179141998] accuracy[91.53] precision[25.0] recall[33.33] specificity[94.64] F1 score[0.29]\n",
      "[3735/5006] final loss [0.10684605687856674] accuracy[96.49] precision[0.0] recall[0.0] specificity[98.21] F1 score[0]\n",
      "[3736/5006] final loss [0.07869864255189896] accuracy[86.42] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[3737/5006] final loss [0.016930919140577316] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[3738/5006] final loss [0.03209300711750984] accuracy[90.48] precision[0.0] recall[0] specificity[90.48] F1 score[0]\n",
      "[3739/5006] final loss [0.14232981204986572] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[3740/5006] final loss [0.15381541848182678] accuracy[94.03] precision[0.0] recall[0] specificity[94.03] F1 score[0]\n",
      "[3741/5006] final loss [0.04770385101437569] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3742/5006] final loss [0.043153028935194016] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3743/5006] final loss [0.08647587150335312] accuracy[92.73] precision[0.0] recall[0.0] specificity[93.58] F1 score[0]\n",
      "[3744/5006] final loss [0.06125868484377861] accuracy[93.64] precision[0.0] recall[0] specificity[93.64] F1 score[0]\n",
      "[3745/5006] final loss [0.15967275202274323] accuracy[94.17] precision[0.0] recall[0] specificity[94.17] F1 score[0]\n",
      "[3746/5006] final loss [0.03396487608551979] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[3747/5006] final loss [0.1486586183309555] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[3748/5006] final loss [0.14807315170764923] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[3749/5006] final loss [0.11890611052513123] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[3750/5006] final loss [0.06576155126094818] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[3751/5006] final loss [0.09946605563163757] accuracy[93.75] precision[33.33] recall[25.0] specificity[97.37] F1 score[0.29]\n",
      "[3752/5006] final loss [0.19060470163822174] accuracy[90.54] precision[6.06] recall[10.0] specificity[93.78] F1 score[0.08]\n",
      "[3753/5006] final loss [0.07833593338727951] accuracy[92.94] precision[0.0] recall[0] specificity[92.94] F1 score[0]\n",
      "[3754/5006] final loss [0.025490645319223404] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3755/5006] final loss [0.02137107215821743] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[3756/5006] final loss [0.15673531591892242] accuracy[91.6] precision[22.22] recall[33.33] specificity[94.4] F1 score[0.27]\n",
      "[3757/5006] final loss [0.20400294661521912] accuracy[85.61] precision[33.33] recall[18.75] specificity[94.83] F1 score[0.24]\n",
      "[3758/5006] final loss [0.22682449221611023] accuracy[88.8] precision[0.0] recall[0.0] specificity[92.5] F1 score[0]\n",
      "[3759/5006] final loss [0.2698492407798767] accuracy[90.24] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[3760/5006] final loss [0.1478084772825241] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3761/5006] final loss [0.09800916910171509] accuracy[92.84] precision[5.26] recall[8.33] specificity[95.42] F1 score[0.06]\n",
      "[3762/5006] final loss [0.052939679473638535] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[3763/5006] final loss [0.09478939324617386] accuracy[89.22] precision[0.0] recall[0.0] specificity[96.81] F1 score[0]\n",
      "[3764/5006] final loss [0.0677124634385109] accuracy[91.67] precision[0.0] recall[0.0] specificity[93.22] F1 score[0]\n",
      "[3765/5006] final loss [0.02683069184422493] accuracy[95.96] precision[0.0] recall[0] specificity[95.96] F1 score[0]\n",
      "[3766/5006] final loss [0.04500068724155426] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3767/5006] final loss [0.08254742622375488] accuracy[85.03] precision[0.0] recall[0.0] specificity[95.42] F1 score[0]\n",
      "[3768/5006] final loss [0.3575878441333771] accuracy[93.62] precision[33.33] recall[50.0] specificity[95.56] F1 score[0.4]\n",
      "[3769/5006] final loss [0.12783552706241608] accuracy[93.22] precision[0.0] recall[0] specificity[93.22] F1 score[0]\n",
      "[3770/5006] final loss [0.05519852787256241] accuracy[90.0] precision[33.33] recall[33.33] specificity[94.59] F1 score[0.33]\n",
      "[3771/5006] final loss [0.0423525869846344] accuracy[92.45] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[3772/5006] final loss [0.0657552033662796] accuracy[94.08] precision[0.0] recall[0.0] specificity[94.7] F1 score[0]\n",
      "[3773/5006] final loss [0.16183719038963318] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[3774/5006] final loss [0.06371116638183594] accuracy[91.18] precision[25.0] recall[25.0] specificity[95.31] F1 score[0.25]\n",
      "[3775/5006] final loss [0.077961765229702] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[3776/5006] final loss [0.03922713175415993] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[3777/5006] final loss [0.19340603053569794] accuracy[94.77] precision[30.0] recall[75.0] specificity[95.3] F1 score[0.43]\n",
      "[3778/5006] final loss [0.09944560378789902] accuracy[94.79] precision[0.0] recall[0] specificity[94.79] F1 score[0]\n",
      "[3779/5006] final loss [0.13635817170143127] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[3780/5006] final loss [0.04375368356704712] accuracy[92.31] precision[0.0] recall[0.0] specificity[95.24] F1 score[0]\n",
      "[3781/5006] final loss [0.014420650899410248] accuracy[98.39] precision[0.0] recall[0] specificity[98.39] F1 score[0]\n",
      "[3782/5006] final loss [0.07652824372053146] accuracy[92.96] precision[0.0] recall[0] specificity[92.96] F1 score[0]\n",
      "[3783/5006] final loss [0.03023933805525303] accuracy[98.99] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3784/5006] final loss [0.18667754530906677] accuracy[93.59] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[3785/5006] final loss [0.24345871806144714] accuracy[62.5] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3786/5006] final loss [0.11034081131219864] accuracy[96.94] precision[0.0] recall[0] specificity[96.94] F1 score[0]\n",
      "[3787/5006] final loss [0.02718590386211872] accuracy[75.0] precision[0.0] recall[0] specificity[75.0] F1 score[0]\n",
      "[3788/5006] final loss [0.1787780225276947] accuracy[89.33] precision[7.69] recall[20.0] specificity[91.72] F1 score[0.11]\n",
      "[3789/5006] final loss [0.012800296768546104] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[3790/5006] final loss [0.11784256249666214] accuracy[93.1] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[3791/5006] final loss [0.10129152983427048] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3792/5006] final loss [0.18435271084308624] accuracy[90.84] precision[25.0] recall[25.0] specificity[95.12] F1 score[0.25]\n",
      "[3793/5006] final loss [0.09865888953208923] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3794/5006] final loss [0.09872467815876007] accuracy[87.0] precision[71.43] recall[31.25] specificity[97.62] F1 score[0.43]\n",
      "[3795/5006] final loss [0.12172532081604004] accuracy[92.8] precision[0.0] recall[0] specificity[92.8] F1 score[0]\n",
      "[3796/5006] final loss [0.15976573526859283] accuracy[96.55] precision[25.0] recall[100.0] specificity[96.51] F1 score[0.4]\n",
      "[3797/5006] final loss [0.184548482298851] accuracy[92.48] precision[5.88] recall[20.0] specificity[93.87] F1 score[0.09]\n",
      "[3798/5006] final loss [0.16154442727565765] accuracy[90.91] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[3799/5006] final loss [0.2133408784866333] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3800/5006] final loss [0.09219871461391449] accuracy[90.38] precision[0.0] recall[0.0] specificity[92.16] F1 score[0]\n",
      "[3801/5006] final loss [0.048025745898485184] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3802/5006] final loss [0.0723443552851677] accuracy[87.8] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[3803/5006] final loss [0.04284314438700676] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3804/5006] final loss [0.07007482647895813] accuracy[92.74] precision[0.0] recall[0.0] specificity[94.61] F1 score[0]\n",
      "[3805/5006] final loss [0.22202111780643463] accuracy[92.95] precision[7.14] recall[20.0] specificity[94.49] F1 score[0.11]\n",
      "[3806/5006] final loss [0.0616227425634861] accuracy[88.44] precision[0.0] recall[0.0] specificity[96.84] F1 score[0]\n",
      "[3807/5006] final loss [0.20221145451068878] accuracy[95.41] precision[16.67] recall[100.0] specificity[95.37] F1 score[0.29]\n",
      "[3808/5006] final loss [0.21315407752990723] accuracy[86.49] precision[100.0] recall[28.57] specificity[100.0] F1 score[0.44]\n",
      "[3809/5006] final loss [0.21157412230968475] accuracy[87.1] precision[10.0] recall[25.0] specificity[89.89] F1 score[0.14]\n",
      "[3810/5006] final loss [0.17397886514663696] accuracy[87.84] precision[0.0] recall[0] specificity[87.84] F1 score[0]\n",
      "[3811/5006] final loss [0.12136631458997726] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3812/5006] final loss [0.2522154748439789] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[3813/5006] final loss [0.09569592028856277] accuracy[96.72] precision[0.0] recall[0] specificity[96.72] F1 score[0]\n",
      "[3814/5006] final loss [0.0739777460694313] accuracy[92.45] precision[25.0] recall[50.0] specificity[94.12] F1 score[0.33]\n",
      "[3815/5006] final loss [0.42069894075393677] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[3816/5006] final loss [0.009564933367073536] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3817/5006] final loss [0.06998008489608765] accuracy[93.18] precision[25.0] recall[100.0] specificity[93.02] F1 score[0.4]\n",
      "[3818/5006] final loss [0.09918218851089478] accuracy[87.77] precision[40.0] recall[26.67] specificity[95.16] F1 score[0.32]\n",
      "[3819/5006] final loss [0.17580343782901764] accuracy[90.0] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[3820/5006] final loss [0.016874609515070915] accuracy[91.18] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[3821/5006] final loss [0.12707427144050598] accuracy[97.47] precision[0.0] recall[0] specificity[97.47] F1 score[0]\n",
      "[3822/5006] final loss [0.21405115723609924] accuracy[90.56] precision[0.0] recall[0.0] specificity[92.61] F1 score[0]\n",
      "[3823/5006] final loss [0.21559174358844757] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3824/5006] final loss [0.03019672818481922] accuracy[75.0] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[3825/5006] final loss [0.10680997371673584] accuracy[91.82] precision[33.33] recall[28.57] specificity[96.12] F1 score[0.31]\n",
      "[3826/5006] final loss [0.02449052222073078] accuracy[83.33] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[3827/5006] final loss [0.2597867548465729] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[3828/5006] final loss [0.03150566667318344] accuracy[94.44] precision[50.0] recall[50.0] specificity[97.06] F1 score[0.5]\n",
      "[3829/5006] final loss [0.048850759863853455] accuracy[94.59] precision[50.0] recall[50.0] specificity[97.14] F1 score[0.5]\n",
      "[3830/5006] final loss [0.090965136885643] accuracy[88.57] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[3831/5006] final loss [0.16769558191299438] accuracy[91.53] precision[0.0] recall[0] specificity[91.53] F1 score[0]\n",
      "[3832/5006] final loss [0.20005598664283752] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[3833/5006] final loss [0.014850706793367863] accuracy[92.31] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[3834/5006] final loss [0.06453917920589447] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3835/5006] final loss [0.15293757617473602] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[3836/5006] final loss [0.055178526788949966] accuracy[94.69] precision[0.0] recall[0] specificity[94.69] F1 score[0]\n",
      "[3837/5006] final loss [0.11091377586126328] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3838/5006] final loss [0.16222745180130005] accuracy[84.96] precision[20.0] recall[14.29] specificity[93.28] F1 score[0.17]\n",
      "[3839/5006] final loss [0.1085125133395195] accuracy[92.31] precision[42.86] recall[50.0] specificity[95.29] F1 score[0.46]\n",
      "[3840/5006] final loss [0.009576806798577309] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[3841/5006] final loss [0.13669966161251068] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[3842/5006] final loss [0.03899414464831352] accuracy[93.42] precision[0.0] recall[0.0] specificity[98.61] F1 score[0]\n",
      "[3843/5006] final loss [0.06054621562361717] accuracy[93.98] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[3844/5006] final loss [0.09822554141283035] accuracy[83.33] precision[0.0] recall[0.0] specificity[86.96] F1 score[0]\n",
      "[3845/5006] final loss [0.044673480093479156] accuracy[91.36] precision[25.0] recall[20.0] specificity[96.05] F1 score[0.22]\n",
      "[3846/5006] final loss [0.12009762227535248] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3847/5006] final loss [0.01660871133208275] accuracy[77.78] precision[0.0] recall[0.0] specificity[91.3] F1 score[0]\n",
      "[3848/5006] final loss [0.0930778756737709] accuracy[93.15] precision[28.57] recall[100.0] specificity[92.96] F1 score[0.44]\n",
      "[3849/5006] final loss [0.17305150628089905] accuracy[96.13] precision[0.0] recall[0] specificity[96.13] F1 score[0]\n",
      "[3850/5006] final loss [0.10274933278560638] accuracy[89.29] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[3851/5006] final loss [0.20352807641029358] accuracy[89.56] precision[10.71] recall[33.33] specificity[91.32] F1 score[0.16]\n",
      "[3852/5006] final loss [0.19680745899677277] accuracy[95.31] precision[25.0] recall[100.0] specificity[95.24] F1 score[0.4]\n",
      "[3853/5006] final loss [0.21440455317497253] accuracy[84.62] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[3854/5006] final loss [0.06350778788328171] accuracy[88.24] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[3855/5006] final loss [0.12760980427265167] accuracy[92.0] precision[8.33] recall[25.0] specificity[93.57] F1 score[0.12]\n",
      "[3856/5006] final loss [0.06894443929195404] accuracy[96.63] precision[0.0] recall[0] specificity[96.63] F1 score[0]\n",
      "[3857/5006] final loss [0.2601509988307953] accuracy[85.88] precision[11.76] recall[18.75] specificity[90.45] F1 score[0.14]\n",
      "[3858/5006] final loss [0.21373362839221954] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[3859/5006] final loss [0.03855007141828537] accuracy[94.29] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[3860/5006] final loss [0.15177924931049347] accuracy[92.2] precision[15.38] recall[25.0] specificity[94.76] F1 score[0.19]\n",
      "[3861/5006] final loss [0.07656539231538773] accuracy[95.83] precision[20.0] recall[100.0] specificity[95.79] F1 score[0.33]\n",
      "[3862/5006] final loss [0.05775042995810509] accuracy[93.33] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[3863/5006] final loss [0.19111640751361847] accuracy[92.64] precision[0.0] recall[0] specificity[92.64] F1 score[0]\n",
      "[3864/5006] final loss [0.07846764475107193] accuracy[91.43] precision[0.0] recall[0.0] specificity[95.52] F1 score[0]\n",
      "[3865/5006] final loss [0.09095001220703125] accuracy[87.43] precision[0.0] recall[0.0] specificity[92.49] F1 score[0]\n",
      "[3866/5006] final loss [0.15718460083007812] accuracy[92.42] precision[0.0] recall[0.0] specificity[93.85] F1 score[0]\n",
      "[3867/5006] final loss [0.16828519105911255] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3868/5006] final loss [0.17584113776683807] accuracy[88.78] precision[16.67] recall[14.29] specificity[94.51] F1 score[0.15]\n",
      "[3869/5006] final loss [0.10633676499128342] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3870/5006] final loss [0.06638070195913315] accuracy[94.55] precision[50.0] recall[66.67] specificity[96.15] F1 score[0.57]\n",
      "[3871/5006] final loss [0.5743957161903381] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[3872/5006] final loss [0.03196097910404205] accuracy[87.18] precision[50.0] recall[20.0] specificity[97.06] F1 score[0.29]\n",
      "[3873/5006] final loss [0.038805365562438965] accuracy[98.48] precision[0.0] recall[0] specificity[98.48] F1 score[0]\n",
      "[3874/5006] final loss [0.20661146938800812] accuracy[92.11] precision[100.0] recall[25.0] specificity[100.0] F1 score[0.4]\n",
      "[3875/5006] final loss [0.21132192015647888] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3876/5006] final loss [0.2911215126514435] accuracy[89.86] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[3877/5006] final loss [0.5417723059654236] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[3878/5006] final loss [0.03288194537162781] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[3879/5006] final loss [0.1557595282793045] accuracy[90.94] precision[22.22] recall[60.0] specificity[92.11] F1 score[0.32]\n",
      "[3880/5006] final loss [0.17625515162944794] accuracy[93.41] precision[0.0] recall[0.0] specificity[96.59] F1 score[0]\n",
      "[3881/5006] final loss [0.18218156695365906] accuracy[85.79] precision[13.73] recall[14.29] specificity[92.09] F1 score[0.14]\n",
      "[3882/5006] final loss [0.10819410532712936] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[3883/5006] final loss [0.13369911909103394] accuracy[88.46] precision[0.0] recall[0.0] specificity[95.83] F1 score[0]\n",
      "[3884/5006] final loss [0.33178311586380005] accuracy[93.59] precision[0.0] recall[0] specificity[93.59] F1 score[0]\n",
      "[3885/5006] final loss [0.18059083819389343] accuracy[82.44] precision[16.67] recall[13.33] specificity[91.38] F1 score[0.15]\n",
      "[3886/5006] final loss [0.03354477882385254] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[3887/5006] final loss [0.08805010467767715] accuracy[93.24] precision[0.0] recall[0.0] specificity[93.88] F1 score[0]\n",
      "[3888/5006] final loss [0.08014878630638123] accuracy[93.94] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[3889/5006] final loss [0.13803738355636597] accuracy[92.82] precision[0.0] recall[0.0] specificity[93.78] F1 score[0]\n",
      "[3890/5006] final loss [0.1525445282459259] accuracy[91.42] precision[0.0] recall[0.0] specificity[91.76] F1 score[0]\n",
      "[3891/5006] final loss [0.13452279567718506] accuracy[95.92] precision[0.0] recall[0] specificity[95.92] F1 score[0]\n",
      "[3892/5006] final loss [0.1800084263086319] accuracy[95.3] precision[0.0] recall[0.0] specificity[96.96] F1 score[0]\n",
      "[3893/5006] final loss [0.15626566112041473] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[3894/5006] final loss [0.14472529292106628] accuracy[88.62] precision[6.67] recall[16.67] specificity[91.3] F1 score[0.1]\n",
      "[3895/5006] final loss [0.3213806748390198] accuracy[93.85] precision[0.0] recall[0.0] specificity[95.31] F1 score[0]\n",
      "[3896/5006] final loss [0.11613713949918747] accuracy[91.43] precision[0.0] recall[0] specificity[91.43] F1 score[0]\n",
      "[3897/5006] final loss [0.1230899766087532] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3898/5006] final loss [0.299587607383728] accuracy[87.5] precision[50.0] recall[25.0] specificity[96.43] F1 score[0.33]\n",
      "[3899/5006] final loss [0.2742431163787842] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3900/5006] final loss [0.06509815156459808] accuracy[98.21] precision[0.0] recall[0] specificity[98.21] F1 score[0]\n",
      "[3901/5006] final loss [0.1308227777481079] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[3902/5006] final loss [0.06819990277290344] accuracy[95.7] precision[20.0] recall[100.0] specificity[95.65] F1 score[0.33]\n",
      "[3903/5006] final loss [0.013658770360052586] accuracy[95.59] precision[0.0] recall[0] specificity[95.59] F1 score[0]\n",
      "[3904/5006] final loss [0.13799703121185303] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[3905/5006] final loss [0.0938657596707344] accuracy[93.75] precision[16.67] recall[50.0] specificity[94.68] F1 score[0.25]\n",
      "[3906/5006] final loss [0.04030938073992729] accuracy[91.3] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[3907/5006] final loss [0.10652472078800201] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[3908/5006] final loss [0.34822168946266174] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[3909/5006] final loss [0.09723583608865738] accuracy[82.45] precision[20.83] recall[17.24] specificity[91.2] F1 score[0.19]\n",
      "[3910/5006] final loss [0.013466541655361652] accuracy[84.62] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[3911/5006] final loss [0.0817733034491539] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[3912/5006] final loss [0.1937381774187088] accuracy[87.0] precision[10.34] recall[18.75] specificity[90.85] F1 score[0.13]\n",
      "[3913/5006] final loss [0.13774526119232178] accuracy[91.51] precision[0.0] recall[0.0] specificity[93.27] F1 score[0]\n",
      "[3914/5006] final loss [0.010859125293791294] accuracy[97.01] precision[0.0] recall[0] specificity[97.01] F1 score[0]\n",
      "[3915/5006] final loss [0.19989295303821564] accuracy[65.52] precision[50.0] recall[10.0] specificity[94.74] F1 score[0.17]\n",
      "[3916/5006] final loss [0.024596216157078743] accuracy[80.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3917/5006] final loss [0.04340634122490883] accuracy[94.57] precision[0.0] recall[0.0] specificity[95.6] F1 score[0]\n",
      "[3918/5006] final loss [0.05758468434214592] accuracy[92.45] precision[0.0] recall[0] specificity[92.45] F1 score[0]\n",
      "[3919/5006] final loss [0.0873776227235794] accuracy[89.29] precision[0.0] recall[0.0] specificity[94.34] F1 score[0]\n",
      "[3920/5006] final loss [0.0396890752017498] accuracy[83.19] precision[0.0] recall[0.0] specificity[95.92] F1 score[0]\n",
      "[3921/5006] final loss [0.1316457837820053] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[3922/5006] final loss [0.12236656248569489] accuracy[91.19] precision[0.0] recall[0] specificity[91.19] F1 score[0]\n",
      "[3923/5006] final loss [0.03608683869242668] accuracy[95.58] precision[0.0] recall[0] specificity[95.58] F1 score[0]\n",
      "[3924/5006] final loss [0.10711105912923813] accuracy[94.79] precision[0.0] recall[0] specificity[94.79] F1 score[0]\n",
      "[3925/5006] final loss [0.2253008931875229] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3926/5006] final loss [0.019519414752721786] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3927/5006] final loss [0.0633527860045433] accuracy[85.29] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[3928/5006] final loss [0.011738872155547142] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3929/5006] final loss [0.13430778682231903] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[3930/5006] final loss [0.11764626204967499] accuracy[98.11] precision[0.0] recall[0] specificity[98.11] F1 score[0]\n",
      "[3931/5006] final loss [0.04007357731461525] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[3932/5006] final loss [0.14682090282440186] accuracy[87.1] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[3933/5006] final loss [0.09091637283563614] accuracy[87.12] precision[25.0] recall[15.38] specificity[94.96] F1 score[0.19]\n",
      "[3934/5006] final loss [0.13277414441108704] accuracy[88.73] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[3935/5006] final loss [0.032531335949897766] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3936/5006] final loss [0.06037020683288574] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[3937/5006] final loss [0.025127433240413666] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[3938/5006] final loss [0.08844444900751114] accuracy[95.71] precision[0.0] recall[0] specificity[95.71] F1 score[0]\n",
      "[3939/5006] final loss [0.13724790513515472] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[3940/5006] final loss [0.26823580265045166] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3941/5006] final loss [0.014779923483729362] accuracy[86.84] precision[0.0] recall[0.0] specificity[97.06] F1 score[0]\n",
      "[3942/5006] final loss [0.250853031873703] accuracy[82.28] precision[7.41] recall[4.55] specificity[92.51] F1 score[0.06]\n",
      "[3943/5006] final loss [0.0013217239174991846] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3944/5006] final loss [0.22497832775115967] accuracy[93.71] precision[0.0] recall[0.0] specificity[94.9] F1 score[0]\n",
      "[3945/5006] final loss [0.25247442722320557] accuracy[95.0] precision[33.33] recall[100.0] specificity[94.87] F1 score[0.5]\n",
      "[3946/5006] final loss [0.11739645898342133] accuracy[91.78] precision[0.0] recall[0.0] specificity[97.1] F1 score[0]\n",
      "[3947/5006] final loss [0.007303624413907528] accuracy[71.43] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[3948/5006] final loss [0.14745451509952545] accuracy[87.64] precision[30.77] recall[23.53] specificity[94.41] F1 score[0.27]\n",
      "[3949/5006] final loss [0.13617122173309326] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[3950/5006] final loss [0.06966963410377502] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[3951/5006] final loss [0.16261231899261475] accuracy[85.45] precision[0.0] recall[0.0] specificity[90.82] F1 score[0]\n",
      "[3952/5006] final loss [0.19982677698135376] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3953/5006] final loss [0.16123387217521667] accuracy[93.55] precision[7.69] recall[20.0] specificity[95.06] F1 score[0.11]\n",
      "[3954/5006] final loss [0.1832006722688675] accuracy[89.74] precision[8.33] recall[16.67] specificity[92.67] F1 score[0.11]\n",
      "[3955/5006] final loss [0.11986564099788666] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3956/5006] final loss [0.03954817354679108] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[3957/5006] final loss [0.2089623212814331] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3958/5006] final loss [0.11539790779352188] accuracy[88.54] precision[16.67] recall[20.0] specificity[93.2] F1 score[0.18]\n",
      "[3959/5006] final loss [0.07769825309515] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[3960/5006] final loss [0.08939090371131897] accuracy[94.26] precision[0.0] recall[0] specificity[94.26] F1 score[0]\n",
      "[3961/5006] final loss [0.017720263451337814] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[3962/5006] final loss [0.13492220640182495] accuracy[92.97] precision[6.25] recall[25.0] specificity[94.05] F1 score[0.1]\n",
      "[3963/5006] final loss [0.1702626496553421] accuracy[94.92] precision[0.0] recall[0] specificity[94.92] F1 score[0]\n",
      "[3964/5006] final loss [0.2148742824792862] accuracy[92.47] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[3965/5006] final loss [0.14595133066177368] accuracy[80.85] precision[0.0] recall[0.0] specificity[91.57] F1 score[0]\n",
      "[3966/5006] final loss [0.06425934284925461] accuracy[85.71] precision[0.0] recall[0.0] specificity[91.2] F1 score[0]\n",
      "[3967/5006] final loss [0.1098657101392746] accuracy[93.81] precision[0.0] recall[0] specificity[93.81] F1 score[0]\n",
      "[3968/5006] final loss [0.06362376362085342] accuracy[96.92] precision[0.0] recall[0.0] specificity[98.44] F1 score[0]\n",
      "[3969/5006] final loss [0.06273805350065231] accuracy[66.67] precision[0.0] recall[0] specificity[66.67] F1 score[0]\n",
      "[3970/5006] final loss [0.1288531869649887] accuracy[95.97] precision[0.0] recall[0.0] specificity[96.75] F1 score[0]\n",
      "[3971/5006] final loss [0.2423563450574875] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[3972/5006] final loss [0.11120735108852386] accuracy[77.17] precision[22.22] recall[12.5] specificity[90.79] F1 score[0.16]\n",
      "[3973/5006] final loss [0.06874413788318634] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3974/5006] final loss [0.056822653859853745] accuracy[91.73] precision[33.33] recall[37.5] specificity[95.2] F1 score[0.35]\n",
      "[3975/5006] final loss [0.02494528703391552] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[3976/5006] final loss [0.24283578991889954] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[3977/5006] final loss [0.12500129640102386] accuracy[87.71] precision[12.5] recall[20.0] specificity[91.72] F1 score[0.15]\n",
      "[3978/5006] final loss [0.180532306432724] accuracy[89.73] precision[6.67] recall[16.67] specificity[92.18] F1 score[0.1]\n",
      "[3979/5006] final loss [0.12895210087299347] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[3980/5006] final loss [0.26424869894981384] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[3981/5006] final loss [0.13234302401542664] accuracy[94.5] precision[16.67] recall[50.0] specificity[95.33] F1 score[0.25]\n",
      "[3982/5006] final loss [0.1327909678220749] accuracy[89.61] precision[0.0] recall[0] specificity[89.61] F1 score[0]\n",
      "[3983/5006] final loss [0.05485024303197861] accuracy[92.19] precision[0.0] recall[0] specificity[92.19] F1 score[0]\n",
      "[3984/5006] final loss [0.12672536075115204] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[3985/5006] final loss [0.08954513072967529] accuracy[95.79] precision[0.0] recall[0.0] specificity[97.33] F1 score[0]\n",
      "[3986/5006] final loss [0.05601073056459427] accuracy[94.74] precision[0.0] recall[0.0] specificity[97.3] F1 score[0]\n",
      "[3987/5006] final loss [0.200181782245636] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[3988/5006] final loss [0.17508918046951294] accuracy[78.07] precision[20.0] recall[26.09] specificity[85.37] F1 score[0.23]\n",
      "[3989/5006] final loss [0.13913586735725403] accuracy[95.92] precision[20.0] recall[100.0] specificity[95.88] F1 score[0.33]\n",
      "[3990/5006] final loss [0.17379671335220337] accuracy[90.32] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[3991/5006] final loss [0.10044387727975845] accuracy[90.65] precision[20.0] recall[14.29] specificity[96.0] F1 score[0.17]\n",
      "[3992/5006] final loss [0.16366448998451233] accuracy[94.23] precision[0.0] recall[0.0] specificity[95.15] F1 score[0]\n",
      "[3993/5006] final loss [0.0834636315703392] accuracy[90.0] precision[66.67] recall[33.33] specificity[97.73] F1 score[0.44]\n",
      "[3994/5006] final loss [0.1725088208913803] accuracy[96.72] precision[0.0] recall[0.0] specificity[98.33] F1 score[0]\n",
      "[3995/5006] final loss [0.3059026002883911] accuracy[90.8] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[3996/5006] final loss [0.016853539273142815] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[3997/5006] final loss [0.4959729015827179] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[3998/5006] final loss [0.1115851178765297] accuracy[96.19] precision[0.0] recall[0] specificity[96.19] F1 score[0]\n",
      "[3999/5006] final loss [0.0837106704711914] accuracy[94.5] precision[28.57] recall[66.67] specificity[95.28] F1 score[0.4]\n",
      "[4000/5006] final loss [0.12250500172376633] accuracy[96.39] precision[0.0] recall[0] specificity[96.39] F1 score[0]\n",
      "[4001/5006] final loss [0.25262218713760376] accuracy[90.65] precision[0.0] recall[0.0] specificity[94.17] F1 score[0]\n",
      "[4002/5006] final loss [0.21791474521160126] accuracy[66.67] precision[0.0] recall[0.0] specificity[85.71] F1 score[0]\n",
      "[4003/5006] final loss [0.042515892535448074] accuracy[99.2] precision[0.0] recall[0] specificity[99.2] F1 score[0]\n",
      "[4004/5006] final loss [0.06686844676733017] accuracy[88.06] precision[25.0] recall[16.67] specificity[95.08] F1 score[0.2]\n",
      "[4005/5006] final loss [0.060539361089468] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[4006/5006] final loss [0.04830346629023552] accuracy[92.22] precision[0.0] recall[0.0] specificity[96.51] F1 score[0]\n",
      "[4007/5006] final loss [0.08814050257205963] accuracy[89.83] precision[12.5] recall[16.67] specificity[93.75] F1 score[0.14]\n",
      "[4008/5006] final loss [0.009934759698808193] accuracy[94.95] precision[0.0] recall[0] specificity[94.95] F1 score[0]\n",
      "[4009/5006] final loss [0.0180442463606596] accuracy[97.44] precision[0.0] recall[0] specificity[97.44] F1 score[0]\n",
      "[4010/5006] final loss [0.009772403165698051] accuracy[92.45] precision[0.0] recall[0.0] specificity[94.23] F1 score[0]\n",
      "[4011/5006] final loss [0.12520134449005127] accuracy[80.28] precision[33.33] recall[16.67] specificity[93.22] F1 score[0.22]\n",
      "[4012/5006] final loss [0.08972764015197754] accuracy[83.13] precision[11.11] recall[14.29] specificity[89.47] F1 score[0.13]\n",
      "[4013/5006] final loss [0.02444399520754814] accuracy[89.09] precision[0.0] recall[0.0] specificity[96.08] F1 score[0]\n",
      "[4014/5006] final loss [0.06395260244607925] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4015/5006] final loss [0.036845363676548004] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4016/5006] final loss [0.1944853961467743] accuracy[93.55] precision[10.0] recall[50.0] specificity[94.12] F1 score[0.17]\n",
      "[4017/5006] final loss [0.12343154102563858] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[4018/5006] final loss [0.05374002084136009] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[4019/5006] final loss [0.06676124036312103] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[4020/5006] final loss [0.10809370875358582] accuracy[93.2] precision[0.0] recall[0.0] specificity[95.14] F1 score[0]\n",
      "[4021/5006] final loss [0.5427016019821167] accuracy[95.04] precision[0.0] recall[0.0] specificity[95.83] F1 score[0]\n",
      "[4022/5006] final loss [0.06018306687474251] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4023/5006] final loss [0.07318238168954849] accuracy[92.0] precision[50.0] recall[50.0] specificity[95.65] F1 score[0.5]\n",
      "[4024/5006] final loss [0.25500819087028503] accuracy[90.36] precision[3.45] recall[10.0] specificity[92.51] F1 score[0.05]\n",
      "[4025/5006] final loss [0.0516197569668293] accuracy[93.65] precision[0.0] recall[0] specificity[93.65] F1 score[0]\n",
      "[4026/5006] final loss [0.038211386650800705] accuracy[85.0] precision[0.0] recall[0.0] specificity[89.47] F1 score[0]\n",
      "[4027/5006] final loss [0.20291444659233093] accuracy[86.67] precision[0.0] recall[0] specificity[86.67] F1 score[0]\n",
      "[4028/5006] final loss [0.12678200006484985] accuracy[91.67] precision[0.0] recall[0.0] specificity[97.06] F1 score[0]\n",
      "[4029/5006] final loss [0.035998012870550156] accuracy[92.86] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[4030/5006] final loss [0.23590180277824402] accuracy[89.36] precision[33.33] recall[31.58] specificity[94.44] F1 score[0.32]\n",
      "[4031/5006] final loss [0.1350056529045105] accuracy[80.53] precision[20.0] recall[12.5] specificity[91.75] F1 score[0.15]\n",
      "[4032/5006] final loss [0.1312185823917389] accuracy[86.25] precision[25.0] recall[11.11] specificity[95.77] F1 score[0.15]\n",
      "[4033/5006] final loss [0.06127403303980827] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[4034/5006] final loss [0.03186870366334915] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[4035/5006] final loss [0.15253326296806335] accuracy[90.7] precision[0.0] recall[0] specificity[90.7] F1 score[0]\n",
      "[4036/5006] final loss [0.21320925652980804] accuracy[88.07] precision[25.0] recall[11.76] specificity[96.23] F1 score[0.16]\n",
      "[4037/5006] final loss [0.10180375725030899] accuracy[92.91] precision[16.67] recall[100.0] specificity[92.81] F1 score[0.29]\n",
      "[4038/5006] final loss [0.0824778601527214] accuracy[91.89] precision[0.0] recall[0] specificity[91.89] F1 score[0]\n",
      "[4039/5006] final loss [0.021442368626594543] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[4040/5006] final loss [0.09661123901605606] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4041/5006] final loss [0.041011422872543335] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4042/5006] final loss [0.016955774277448654] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4043/5006] final loss [0.10279665142297745] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4044/5006] final loss [0.2149057239294052] accuracy[90.62] precision[0.0] recall[0.0] specificity[94.57] F1 score[0]\n",
      "[4045/5006] final loss [0.09140429645776749] accuracy[75.0] precision[75.0] recall[21.43] specificity[97.06] F1 score[0.33]\n",
      "[4046/5006] final loss [0.08847181499004364] accuracy[90.99] precision[0.0] recall[0.0] specificity[97.12] F1 score[0]\n",
      "[4047/5006] final loss [0.3459356129169464] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[4048/5006] final loss [0.10117536038160324] accuracy[91.8] precision[0.0] recall[0] specificity[91.8] F1 score[0]\n",
      "[4049/5006] final loss [0.013191765174269676] accuracy[91.37] precision[11.11] recall[10.0] specificity[95.72] F1 score[0.11]\n",
      "[4050/5006] final loss [0.05506192147731781] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4051/5006] final loss [0.0294319037348032] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[4052/5006] final loss [0.03463977202773094] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4053/5006] final loss [0.07901226729154587] accuracy[92.2] precision[10.0] recall[12.5] specificity[95.43] F1 score[0.11]\n",
      "[4054/5006] final loss [0.17541158199310303] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[4055/5006] final loss [0.24391517043113708] accuracy[86.36] precision[0.0] recall[0.0] specificity[91.57] F1 score[0]\n",
      "[4056/5006] final loss [0.17361974716186523] accuracy[88.73] precision[0.0] recall[0.0] specificity[92.65] F1 score[0]\n",
      "[4057/5006] final loss [0.1550416201353073] accuracy[84.96] precision[50.0] recall[35.0] specificity[93.81] F1 score[0.41]\n",
      "[4058/5006] final loss [0.06336275488138199] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[4059/5006] final loss [0.0004993543843738735] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4060/5006] final loss [0.019366474822163582] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[4061/5006] final loss [0.09407223761081696] accuracy[85.0] precision[0.0] recall[0] specificity[85.0] F1 score[0]\n",
      "[4062/5006] final loss [0.11637052893638611] accuracy[87.39] precision[0.0] recall[0.0] specificity[91.23] F1 score[0]\n",
      "[4063/5006] final loss [0.025692176073789597] accuracy[94.55] precision[0.0] recall[0.0] specificity[96.3] F1 score[0]\n",
      "[4064/5006] final loss [0.24612294137477875] accuracy[94.51] precision[33.33] recall[66.67] specificity[95.45] F1 score[0.44]\n",
      "[4065/5006] final loss [0.13933874666690826] accuracy[86.59] precision[0.0] recall[0.0] specificity[91.03] F1 score[0]\n",
      "[4066/5006] final loss [0.10466354340314865] accuracy[80.58] precision[16.67] recall[6.25] specificity[94.25] F1 score[0.09]\n",
      "[4067/5006] final loss [0.07405292987823486] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[4068/5006] final loss [0.153029203414917] accuracy[95.89] precision[0.0] recall[0] specificity[95.89] F1 score[0]\n",
      "[4069/5006] final loss [0.10166486352682114] accuracy[85.37] precision[37.5] recall[18.75] specificity[95.33] F1 score[0.25]\n",
      "[4070/5006] final loss [0.015687115490436554] accuracy[93.18] precision[0.0] recall[0.0] specificity[95.35] F1 score[0]\n",
      "[4071/5006] final loss [0.041592299938201904] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[4072/5006] final loss [0.09415123611688614] accuracy[90.0] precision[0.0] recall[0.0] specificity[93.1] F1 score[0]\n",
      "[4073/5006] final loss [0.1809944361448288] accuracy[89.86] precision[0.0] recall[0.0] specificity[92.54] F1 score[0]\n",
      "[4074/5006] final loss [0.026214947924017906] accuracy[88.89] precision[0.0] recall[0.0] specificity[96.7] F1 score[0]\n",
      "[4075/5006] final loss [0.1409032642841339] accuracy[85.6] precision[12.5] recall[8.33] specificity[93.81] F1 score[0.1]\n",
      "[4076/5006] final loss [0.3275274932384491] accuracy[89.29] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[4077/5006] final loss [0.0442156046628952] accuracy[92.75] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[4078/5006] final loss [0.10637830197811127] accuracy[90.62] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[4079/5006] final loss [0.10740072280168533] accuracy[95.59] precision[0.0] recall[0] specificity[95.59] F1 score[0]\n",
      "[4080/5006] final loss [0.024946179240942] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4081/5006] final loss [0.22358821332454681] accuracy[93.98] precision[16.67] recall[100.0] specificity[93.9] F1 score[0.29]\n",
      "[4082/5006] final loss [0.10724984109401703] accuracy[77.78] precision[0.0] recall[0.0] specificity[87.5] F1 score[0]\n",
      "[4083/5006] final loss [0.046741604804992676] accuracy[94.2] precision[0.0] recall[0] specificity[94.2] F1 score[0]\n",
      "[4084/5006] final loss [0.11755074560642242] accuracy[86.44] precision[20.0] recall[20.0] specificity[92.59] F1 score[0.2]\n",
      "[4085/5006] final loss [0.11201831698417664] accuracy[93.83] precision[0.0] recall[0] specificity[93.83] F1 score[0]\n",
      "[4086/5006] final loss [0.10539980977773666] accuracy[96.67] precision[66.67] recall[50.0] specificity[98.84] F1 score[0.57]\n",
      "[4087/5006] final loss [0.13172028958797455] accuracy[94.48] precision[0.0] recall[0] specificity[94.48] F1 score[0]\n",
      "[4088/5006] final loss [0.10256236791610718] accuracy[88.17] precision[0.0] recall[0.0] specificity[96.47] F1 score[0]\n",
      "[4089/5006] final loss [0.017628125846385956] accuracy[97.92] precision[0.0] recall[0] specificity[97.92] F1 score[0]\n",
      "[4090/5006] final loss [0.13442657887935638] accuracy[87.97] precision[0.0] recall[0.0] specificity[90.85] F1 score[0]\n",
      "[4091/5006] final loss [0.09321712702512741] accuracy[93.4] precision[0.0] recall[0.0] specificity[95.83] F1 score[0]\n",
      "[4092/5006] final loss [0.08170803636312485] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4093/5006] final loss [0.019705835729837418] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[4094/5006] final loss [0.09710400551557541] accuracy[92.93] precision[20.0] recall[25.0] specificity[95.79] F1 score[0.22]\n",
      "[4095/5006] final loss [0.03292383998632431] accuracy[93.75] precision[25.0] recall[50.0] specificity[95.16] F1 score[0.33]\n",
      "[4096/5006] final loss [0.1158677488565445] accuracy[88.61] precision[0.0] recall[0.0] specificity[92.11] F1 score[0]\n",
      "[4097/5006] final loss [0.24864362180233002] accuracy[92.57] precision[28.57] recall[25.0] specificity[96.43] F1 score[0.27]\n",
      "[4098/5006] final loss [0.009791436605155468] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[4099/5006] final loss [0.003908257000148296] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4100/5006] final loss [0.2580116391181946] accuracy[96.61] precision[0.0] recall[0] specificity[96.61] F1 score[0]\n",
      "[4101/5006] final loss [0.04188651219010353] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[4102/5006] final loss [0.3639770448207855] accuracy[90.21] precision[0.0] recall[0.0] specificity[94.09] F1 score[0]\n",
      "[4103/5006] final loss [0.14952953159809113] accuracy[86.86] precision[35.0] recall[58.33] specificity[89.6] F1 score[0.44]\n",
      "[4104/5006] final loss [0.1270247995853424] accuracy[92.04] precision[0.0] recall[0.0] specificity[95.41] F1 score[0]\n",
      "[4105/5006] final loss [0.2531680762767792] accuracy[84.02] precision[18.75] recall[17.65] specificity[91.45] F1 score[0.18]\n",
      "[4106/5006] final loss [0.03845055401325226] accuracy[97.87] precision[0.0] recall[0] specificity[97.87] F1 score[0]\n",
      "[4107/5006] final loss [0.04874151200056076] accuracy[95.06] precision[0.0] recall[0] specificity[95.06] F1 score[0]\n",
      "[4108/5006] final loss [0.045258015394210815] accuracy[83.33] precision[33.33] recall[16.67] specificity[94.44] F1 score[0.22]\n",
      "[4109/5006] final loss [0.014439092949032784] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4110/5006] final loss [0.03707178682088852] accuracy[94.34] precision[0.0] recall[0] specificity[94.34] F1 score[0]\n",
      "[4111/5006] final loss [0.181559219956398] accuracy[90.37] precision[0.0] recall[0] specificity[90.37] F1 score[0]\n",
      "[4112/5006] final loss [0.06597652286291122] accuracy[91.18] precision[0.0] recall[0] specificity[91.18] F1 score[0]\n",
      "[4113/5006] final loss [0.16066394746303558] accuracy[86.33] precision[23.08] recall[25.0] specificity[92.13] F1 score[0.24]\n",
      "[4114/5006] final loss [0.10028409957885742] accuracy[90.48] precision[100.0] recall[33.33] specificity[100.0] F1 score[0.5]\n",
      "[4115/5006] final loss [0.028744980692863464] accuracy[79.73] precision[16.67] recall[9.09] specificity[92.06] F1 score[0.12]\n",
      "[4116/5006] final loss [0.09234942495822906] accuracy[94.17] precision[0.0] recall[0] specificity[94.17] F1 score[0]\n",
      "[4117/5006] final loss [0.10521995276212692] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4118/5006] final loss [0.18546566367149353] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[4119/5006] final loss [0.24978844821453094] accuracy[94.83] precision[0.0] recall[0] specificity[94.83] F1 score[0]\n",
      "[4120/5006] final loss [0.0033331045415252447] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[4121/5006] final loss [0.11079438030719757] accuracy[98.63] precision[0.0] recall[0] specificity[98.63] F1 score[0]\n",
      "[4122/5006] final loss [0.1588035225868225] accuracy[95.18] precision[0.0] recall[0] specificity[95.18] F1 score[0]\n",
      "[4123/5006] final loss [0.19335319101810455] accuracy[87.93] precision[14.29] recall[18.18] specificity[92.64] F1 score[0.16]\n",
      "[4124/5006] final loss [0.16110694408416748] accuracy[86.36] precision[8.33] recall[20.0] specificity[89.52] F1 score[0.12]\n",
      "[4125/5006] final loss [0.13303253054618835] accuracy[94.52] precision[0.0] recall[0.0] specificity[95.83] F1 score[0]\n",
      "[4126/5006] final loss [0.13486994802951813] accuracy[94.08] precision[0.0] recall[0.0] specificity[95.33] F1 score[0]\n",
      "[4127/5006] final loss [0.18242689967155457] accuracy[87.93] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[4128/5006] final loss [0.07429174333810806] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[4129/5006] final loss [0.1357228308916092] accuracy[94.67] precision[25.0] recall[50.0] specificity[95.89] F1 score[0.33]\n",
      "[4130/5006] final loss [0.08033740520477295] accuracy[92.54] precision[0.0] recall[0] specificity[92.54] F1 score[0]\n",
      "[4131/5006] final loss [0.1639004796743393] accuracy[90.68] precision[18.18] recall[50.0] specificity[92.11] F1 score[0.27]\n",
      "[4132/5006] final loss [0.1430901437997818] accuracy[93.02] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[4133/5006] final loss [0.022186925634741783] accuracy[93.75] precision[0.0] recall[0.0] specificity[96.77] F1 score[0]\n",
      "[4134/5006] final loss [0.05834499001502991] accuracy[95.18] precision[0.0] recall[0] specificity[95.18] F1 score[0]\n",
      "[4135/5006] final loss [0.29928335547447205] accuracy[96.83] precision[0.0] recall[0.0] specificity[98.39] F1 score[0]\n",
      "[4136/5006] final loss [0.14508205652236938] accuracy[90.54] precision[0.0] recall[0.0] specificity[97.1] F1 score[0]\n",
      "[4137/5006] final loss [0.0803297907114029] accuracy[84.25] precision[33.33] recall[17.65] specificity[94.55] F1 score[0.23]\n",
      "[4138/5006] final loss [0.16474585235118866] accuracy[93.98] precision[0.0] recall[0.0] specificity[95.12] F1 score[0]\n",
      "[4139/5006] final loss [0.03836850821971893] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[4140/5006] final loss [0.0004999293596483767] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4141/5006] final loss [0.1740735024213791] accuracy[89.32] precision[26.32] recall[31.25] specificity[93.58] F1 score[0.29]\n",
      "[4142/5006] final loss [0.04677484184503555] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4143/5006] final loss [0.08794675022363663] accuracy[95.87] precision[0.0] recall[0] specificity[95.87] F1 score[0]\n",
      "[4144/5006] final loss [0.04653435945510864] accuracy[97.73] precision[0.0] recall[0] specificity[97.73] F1 score[0]\n",
      "[4145/5006] final loss [0.13674068450927734] accuracy[86.17] precision[0.0] recall[0.0] specificity[94.19] F1 score[0]\n",
      "[4146/5006] final loss [0.01587766408920288] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[4147/5006] final loss [0.16814255714416504] accuracy[92.94] precision[0.0] recall[0.0] specificity[94.7] F1 score[0]\n",
      "[4148/5006] final loss [0.08101785182952881] accuracy[93.88] precision[25.0] recall[100.0] specificity[93.75] F1 score[0.4]\n",
      "[4149/5006] final loss [0.16474442183971405] accuracy[87.3] precision[50.0] recall[18.75] specificity[97.27] F1 score[0.27]\n",
      "[4150/5006] final loss [0.08532235771417618] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[4151/5006] final loss [0.18318073451519012] accuracy[89.47] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[4152/5006] final loss [0.13008594512939453] accuracy[76.64] precision[20.0] recall[20.0] specificity[86.32] F1 score[0.2]\n",
      "[4153/5006] final loss [0.047087594866752625] accuracy[94.2] precision[0.0] recall[0.0] specificity[94.89] F1 score[0]\n",
      "[4154/5006] final loss [0.12242425233125687] accuracy[97.06] precision[50.0] recall[100.0] specificity[96.97] F1 score[0.67]\n",
      "[4155/5006] final loss [0.17331793904304504] accuracy[96.61] precision[20.0] recall[100.0] specificity[96.58] F1 score[0.33]\n",
      "[4156/5006] final loss [0.08014792948961258] accuracy[94.68] precision[6.67] recall[100.0] specificity[94.66] F1 score[0.13]\n",
      "[4157/5006] final loss [0.17631128430366516] accuracy[91.35] precision[15.38] recall[22.22] specificity[94.47] F1 score[0.18]\n",
      "[4158/5006] final loss [0.08048161119222641] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[4159/5006] final loss [0.12719197571277618] accuracy[95.74] precision[33.33] recall[100.0] specificity[95.65] F1 score[0.5]\n",
      "[4160/5006] final loss [0.16855329275131226] accuracy[83.33] precision[25.0] recall[12.5] specificity[94.23] F1 score[0.17]\n",
      "[4161/5006] final loss [0.35029399394989014] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4162/5006] final loss [0.08890508860349655] accuracy[94.67] precision[0.0] recall[0] specificity[94.67] F1 score[0]\n",
      "[4163/5006] final loss [0.03873613104224205] accuracy[95.83] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4164/5006] final loss [0.07518818229436874] accuracy[89.58] precision[0.0] recall[0.0] specificity[91.49] F1 score[0]\n",
      "[4165/5006] final loss [0.04724351689219475] accuracy[95.38] precision[0.0] recall[0] specificity[95.38] F1 score[0]\n",
      "[4166/5006] final loss [0.03728054463863373] accuracy[96.15] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[4167/5006] final loss [0.1047038733959198] accuracy[91.96] precision[0.0] recall[0.0] specificity[94.6] F1 score[0]\n",
      "[4168/5006] final loss [0.05959899351000786] accuracy[93.46] precision[0.0] recall[0] specificity[93.46] F1 score[0]\n",
      "[4169/5006] final loss [0.16433849930763245] accuracy[96.59] precision[0.0] recall[0] specificity[96.59] F1 score[0]\n",
      "[4170/5006] final loss [0.116043321788311] accuracy[95.96] precision[20.0] recall[100.0] specificity[95.92] F1 score[0.33]\n",
      "[4171/5006] final loss [0.11414775997400284] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[4172/5006] final loss [0.052144888788461685] accuracy[85.48] precision[0.0] recall[0.0] specificity[96.36] F1 score[0]\n",
      "[4173/5006] final loss [0.034315597265958786] accuracy[95.1] precision[12.5] recall[100.0] specificity[95.07] F1 score[0.22]\n",
      "[4174/5006] final loss [0.19718104600906372] accuracy[90.24] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[4175/5006] final loss [0.06575603038072586] accuracy[80.85] precision[8.33] recall[5.88] specificity[91.13] F1 score[0.07]\n",
      "[4176/5006] final loss [0.15242327749729156] accuracy[92.42] precision[0.0] recall[0] specificity[92.42] F1 score[0]\n",
      "[4177/5006] final loss [0.07024090737104416] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4178/5006] final loss [0.1362774819135666] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[4179/5006] final loss [0.03740750625729561] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4180/5006] final loss [0.08104921132326126] accuracy[89.02] precision[0.0] recall[0.0] specificity[96.05] F1 score[0]\n",
      "[4181/5006] final loss [0.15834949910640717] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4182/5006] final loss [0.19182457029819489] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[4183/5006] final loss [0.09259530901908875] accuracy[95.83] precision[0.0] recall[0.0] specificity[96.84] F1 score[0]\n",
      "[4184/5006] final loss [0.04655923694372177] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4185/5006] final loss [0.11634403467178345] accuracy[95.38] precision[0.0] recall[0] specificity[95.38] F1 score[0]\n",
      "[4186/5006] final loss [0.15547733008861542] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[4187/5006] final loss [0.07802557200193405] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[4188/5006] final loss [0.16504202783107758] accuracy[94.4] precision[0.0] recall[0] specificity[94.4] F1 score[0]\n",
      "[4189/5006] final loss [0.09544754773378372] accuracy[93.1] precision[14.29] recall[100.0] specificity[93.02] F1 score[0.25]\n",
      "[4190/5006] final loss [0.05173344165086746] accuracy[86.11] precision[0.0] recall[0.0] specificity[95.38] F1 score[0]\n",
      "[4191/5006] final loss [0.1797691136598587] accuracy[91.84] precision[0.0] recall[0.0] specificity[93.26] F1 score[0]\n",
      "[4192/5006] final loss [0.1779973804950714] accuracy[91.43] precision[0.0] recall[0] specificity[91.43] F1 score[0]\n",
      "[4193/5006] final loss [0.16424649953842163] accuracy[94.0] precision[33.33] recall[50.0] specificity[95.83] F1 score[0.4]\n",
      "[4194/5006] final loss [0.06263545155525208] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4195/5006] final loss [0.2617265582084656] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[4196/5006] final loss [0.11456083506345749] accuracy[93.15] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[4197/5006] final loss [0.055558111518621445] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4198/5006] final loss [0.06760454177856445] accuracy[96.81] precision[40.0] recall[100.0] specificity[96.74] F1 score[0.57]\n",
      "[4199/5006] final loss [0.17345385253429413] accuracy[92.65] precision[0.0] recall[0] specificity[92.65] F1 score[0]\n",
      "[4200/5006] final loss [0.6877799034118652] accuracy[94.64] precision[0.0] recall[0] specificity[94.64] F1 score[0]\n",
      "[4201/5006] final loss [0.04569936543703079] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[4202/5006] final loss [0.20047257840633392] accuracy[91.46] precision[0.0] recall[0] specificity[91.46] F1 score[0]\n",
      "[4203/5006] final loss [0.13893984258174896] accuracy[92.54] precision[12.5] recall[25.0] specificity[94.62] F1 score[0.17]\n",
      "[4204/5006] final loss [0.07047758996486664] accuracy[88.46] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[4205/5006] final loss [0.1114557608962059] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4206/5006] final loss [0.10063046216964722] accuracy[90.2] precision[0.0] recall[0.0] specificity[93.88] F1 score[0]\n",
      "[4207/5006] final loss [0.0657874345779419] accuracy[93.63] precision[0.0] recall[0.0] specificity[95.43] F1 score[0]\n",
      "[4208/5006] final loss [0.1833559274673462] accuracy[88.1] precision[0.0] recall[0.0] specificity[90.24] F1 score[0]\n",
      "[4209/5006] final loss [0.031995564699172974] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4210/5006] final loss [0.19261175394058228] accuracy[85.45] precision[18.18] recall[11.76] specificity[93.92] F1 score[0.14]\n",
      "[4211/5006] final loss [0.1898890882730484] accuracy[92.9] precision[0.0] recall[0] specificity[92.9] F1 score[0]\n",
      "[4212/5006] final loss [0.2808387577533722] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[4213/5006] final loss [0.036039676517248154] accuracy[92.68] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[4214/5006] final loss [0.08178772777318954] accuracy[87.93] precision[0.0] recall[0.0] specificity[91.89] F1 score[0]\n",
      "[4215/5006] final loss [0.18089964985847473] accuracy[87.65] precision[0.0] recall[0.0] specificity[91.03] F1 score[0]\n",
      "[4216/5006] final loss [0.046429164707660675] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4217/5006] final loss [0.1675913780927658] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[4218/5006] final loss [0.16568297147750854] accuracy[96.49] precision[50.0] recall[100.0] specificity[96.36] F1 score[0.67]\n",
      "[4219/5006] final loss [0.2613212764263153] accuracy[97.35] precision[0.0] recall[0] specificity[97.35] F1 score[0]\n",
      "[4220/5006] final loss [0.07865487784147263] accuracy[89.71] precision[25.0] recall[20.0] specificity[95.24] F1 score[0.22]\n",
      "[4221/5006] final loss [0.022221330553293228] accuracy[88.68] precision[0.0] recall[0.0] specificity[95.92] F1 score[0]\n",
      "[4222/5006] final loss [0.12220755219459534] accuracy[93.94] precision[0.0] recall[0] specificity[93.94] F1 score[0]\n",
      "[4223/5006] final loss [0.0335966981947422] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[4224/5006] final loss [0.05936598777770996] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4225/5006] final loss [0.09501675516366959] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[4226/5006] final loss [0.1983630210161209] accuracy[86.38] precision[6.67] recall[6.25] specificity[92.89] F1 score[0.06]\n",
      "[4227/5006] final loss [0.020646613091230392] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[4228/5006] final loss [0.041017793118953705] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4229/5006] final loss [0.08741872012615204] accuracy[98.28] precision[0.0] recall[0] specificity[98.28] F1 score[0]\n",
      "[4230/5006] final loss [0.0786198079586029] accuracy[94.66] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[4231/5006] final loss [0.20017006993293762] accuracy[91.36] precision[0.0] recall[0.0] specificity[93.67] F1 score[0]\n",
      "[4232/5006] final loss [0.2846865653991699] accuracy[96.51] precision[0.0] recall[0] specificity[96.51] F1 score[0]\n",
      "[4233/5006] final loss [0.10735734552145004] accuracy[86.54] precision[23.08] recall[14.29] specificity[94.65] F1 score[0.18]\n",
      "[4234/5006] final loss [0.046865541487932205] accuracy[97.47] precision[50.0] recall[100.0] specificity[97.4] F1 score[0.67]\n",
      "[4235/5006] final loss [0.07109947502613068] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[4236/5006] final loss [0.11913485825061798] accuracy[88.8] precision[0.0] recall[0.0] specificity[91.74] F1 score[0]\n",
      "[4237/5006] final loss [0.2566535472869873] accuracy[85.75] precision[13.51] recall[19.23] specificity[90.75] F1 score[0.16]\n",
      "[4238/5006] final loss [0.13378563523292542] accuracy[95.0] precision[20.0] recall[33.33] specificity[96.58] F1 score[0.25]\n",
      "[4239/5006] final loss [0.1644735038280487] accuracy[87.86] precision[0.0] recall[0.0] specificity[92.82] F1 score[0]\n",
      "[4240/5006] final loss [0.21920643746852875] accuracy[89.66] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[4241/5006] final loss [0.0402701273560524] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[4242/5006] final loss [0.17834262549877167] accuracy[82.76] precision[33.33] recall[15.38] specificity[94.59] F1 score[0.21]\n",
      "[4243/5006] final loss [0.20991726219654083] accuracy[91.03] precision[0.0] recall[0] specificity[91.03] F1 score[0]\n",
      "[4244/5006] final loss [0.16693712770938873] accuracy[93.39] precision[23.08] recall[37.5] specificity[95.43] F1 score[0.29]\n",
      "[4245/5006] final loss [0.049563586711883545] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[4246/5006] final loss [0.10821224749088287] accuracy[84.52] precision[0.0] recall[0.0] specificity[89.87] F1 score[0]\n",
      "[4247/5006] final loss [0.05629170686006546] accuracy[89.47] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[4248/5006] final loss [0.278854638338089] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[4249/5006] final loss [0.08315706253051758] accuracy[86.59] precision[0.0] recall[0.0] specificity[95.3] F1 score[0]\n",
      "[4250/5006] final loss [0.20132751762866974] accuracy[93.04] precision[0.0] recall[0.0] specificity[94.69] F1 score[0]\n",
      "[4251/5006] final loss [0.02902091108262539] accuracy[95.33] precision[0.0] recall[0] specificity[95.33] F1 score[0]\n",
      "[4252/5006] final loss [0.12159460783004761] accuracy[97.37] precision[0.0] recall[0] specificity[97.37] F1 score[0]\n",
      "[4253/5006] final loss [0.030661245808005333] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4254/5006] final loss [0.09288714826107025] accuracy[86.16] precision[14.29] recall[16.67] specificity[91.84] F1 score[0.15]\n",
      "[4255/5006] final loss [0.15999770164489746] accuracy[92.81] precision[0.0] recall[0.0] specificity[94.67] F1 score[0]\n",
      "[4256/5006] final loss [0.2657124698162079] accuracy[94.35] precision[0.0] recall[0] specificity[94.35] F1 score[0]\n",
      "[4257/5006] final loss [0.03754684329032898] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[4258/5006] final loss [0.11934817582368851] accuracy[92.47] precision[0.0] recall[0.0] specificity[94.51] F1 score[0]\n",
      "[4259/5006] final loss [0.12759612500667572] accuracy[88.46] precision[25.0] recall[14.29] specificity[95.77] F1 score[0.18]\n",
      "[4260/5006] final loss [0.024493107572197914] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4261/5006] final loss [0.05757002532482147] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4262/5006] final loss [0.1320820152759552] accuracy[92.13] precision[20.0] recall[25.0] specificity[95.29] F1 score[0.22]\n",
      "[4263/5006] final loss [0.09809200465679169] accuracy[91.15] precision[12.5] recall[25.0] specificity[93.58] F1 score[0.17]\n",
      "[4264/5006] final loss [0.13814333081245422] accuracy[94.59] precision[0.0] recall[0.0] specificity[96.77] F1 score[0]\n",
      "[4265/5006] final loss [0.14762040972709656] accuracy[88.18] precision[16.67] recall[11.11] specificity[95.05] F1 score[0.13]\n",
      "[4266/5006] final loss [0.10180817544460297] accuracy[96.43] precision[0.0] recall[0] specificity[96.43] F1 score[0]\n",
      "[4267/5006] final loss [0.13918624818325043] accuracy[91.8] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4268/5006] final loss [0.1027795597910881] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[4269/5006] final loss [0.12243305146694183] accuracy[96.49] precision[0.0] recall[0] specificity[96.49] F1 score[0]\n",
      "[4270/5006] final loss [0.0749894455075264] accuracy[95.74] precision[0.0] recall[0] specificity[95.74] F1 score[0]\n",
      "[4271/5006] final loss [0.14355404675006866] accuracy[89.23] precision[11.11] recall[14.29] specificity[93.5] F1 score[0.13]\n",
      "[4272/5006] final loss [0.052879251539707184] accuracy[95.71] precision[0.0] recall[0] specificity[95.71] F1 score[0]\n",
      "[4273/5006] final loss [0.062446478754282] accuracy[96.15] precision[25.0] recall[100.0] specificity[96.1] F1 score[0.4]\n",
      "[4274/5006] final loss [0.1611330211162567] accuracy[96.45] precision[0.0] recall[0] specificity[96.45] F1 score[0]\n",
      "[4275/5006] final loss [0.14293143153190613] accuracy[95.29] precision[0.0] recall[0] specificity[95.29] F1 score[0]\n",
      "[4276/5006] final loss [0.15413692593574524] accuracy[85.55] precision[23.53] recall[25.0] specificity[91.72] F1 score[0.24]\n",
      "[4277/5006] final loss [0.1499137133359909] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[4278/5006] final loss [0.19445332884788513] accuracy[100.0] precision[100.0] recall[100.0] specificity[0] F1 score[1.0]\n",
      "[4279/5006] final loss [0.1965187042951584] accuracy[88.24] precision[12.5] recall[10.71] specificity[94.21] F1 score[0.12]\n",
      "[4280/5006] final loss [0.02412644401192665] accuracy[91.84] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[4281/5006] final loss [0.1039077565073967] accuracy[94.44] precision[20.0] recall[100.0] specificity[94.37] F1 score[0.33]\n",
      "[4282/5006] final loss [0.167448490858078] accuracy[92.94] precision[0.0] recall[0.0] specificity[94.05] F1 score[0]\n",
      "[4283/5006] final loss [0.2581918239593506] accuracy[91.0] precision[0.0] recall[0.0] specificity[91.92] F1 score[0]\n",
      "[4284/5006] final loss [0.07164004445075989] accuracy[94.62] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[4285/5006] final loss [0.08307664841413498] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4286/5006] final loss [0.18864917755126953] accuracy[94.77] precision[0.0] recall[0.0] specificity[96.03] F1 score[0]\n",
      "[4287/5006] final loss [0.20602776110172272] accuracy[91.37] precision[25.0] recall[25.0] specificity[95.42] F1 score[0.25]\n",
      "[4288/5006] final loss [0.1713496893644333] accuracy[92.5] precision[100.0] recall[25.0] specificity[100.0] F1 score[0.4]\n",
      "[4289/5006] final loss [0.05017055571079254] accuracy[95.31] precision[0.0] recall[0.0] specificity[98.39] F1 score[0]\n",
      "[4290/5006] final loss [0.11283372342586517] accuracy[77.32] precision[16.67] recall[14.29] specificity[87.95] F1 score[0.15]\n",
      "[4291/5006] final loss [0.026517236605286598] accuracy[95.83] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4292/5006] final loss [0.03632602095603943] accuracy[94.0] precision[0.0] recall[0] specificity[94.0] F1 score[0]\n",
      "[4293/5006] final loss [0.16163736581802368] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[4294/5006] final loss [0.12915468215942383] accuracy[80.25] precision[17.39] recall[25.0] specificity[86.52] F1 score[0.21]\n",
      "[4295/5006] final loss [0.1537921130657196] accuracy[94.59] precision[0.0] recall[0.0] specificity[97.22] F1 score[0]\n",
      "[4296/5006] final loss [0.08675578981637955] accuracy[94.61] precision[0.0] recall[0.0] specificity[95.76] F1 score[0]\n",
      "[4297/5006] final loss [0.08780056983232498] accuracy[94.74] precision[50.0] recall[33.33] specificity[98.15] F1 score[0.4]\n",
      "[4298/5006] final loss [0.1731930524110794] accuracy[87.76] precision[0.0] recall[0.0] specificity[95.56] F1 score[0]\n",
      "[4299/5006] final loss [0.21279092133045197] accuracy[91.36] precision[28.57] recall[50.0] specificity[93.51] F1 score[0.36]\n",
      "[4300/5006] final loss [0.1674717664718628] accuracy[87.06] precision[0.0] recall[0.0] specificity[93.67] F1 score[0]\n",
      "[4301/5006] final loss [0.20706437528133392] accuracy[91.36] precision[0.0] recall[0.0] specificity[93.67] F1 score[0]\n",
      "[4302/5006] final loss [0.08004262298345566] accuracy[82.72] precision[0.0] recall[0.0] specificity[91.78] F1 score[0]\n",
      "[4303/5006] final loss [0.2231106013059616] accuracy[91.67] precision[0.0] recall[0.0] specificity[92.6] F1 score[0]\n",
      "[4304/5006] final loss [0.07519620656967163] accuracy[94.32] precision[0.0] recall[0.0] specificity[95.4] F1 score[0]\n",
      "[4305/5006] final loss [0.16765113174915314] accuracy[90.83] precision[12.5] recall[20.0] specificity[93.91] F1 score[0.15]\n",
      "[4306/5006] final loss [0.20576810836791992] accuracy[96.15] precision[50.0] recall[100.0] specificity[96.0] F1 score[0.67]\n",
      "[4307/5006] final loss [0.3727644383907318] accuracy[92.11] precision[0.0] recall[0] specificity[92.11] F1 score[0]\n",
      "[4308/5006] final loss [0.18895629048347473] accuracy[95.7] precision[40.0] recall[66.67] specificity[96.67] F1 score[0.5]\n",
      "[4309/5006] final loss [0.13582228124141693] accuracy[91.14] precision[22.22] recall[22.22] specificity[95.3] F1 score[0.22]\n",
      "[4310/5006] final loss [0.0934542715549469] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4311/5006] final loss [0.18677878379821777] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4312/5006] final loss [0.12040552496910095] accuracy[94.0] precision[66.67] recall[50.0] specificity[97.83] F1 score[0.57]\n",
      "[4313/5006] final loss [0.1316029578447342] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4314/5006] final loss [0.12561973929405212] accuracy[87.58] precision[11.11] recall[7.69] specificity[94.59] F1 score[0.09]\n",
      "[4315/5006] final loss [0.22148577868938446] accuracy[92.5] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[4316/5006] final loss [0.5460326075553894] accuracy[90.0] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[4317/5006] final loss [0.04235728457570076] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[4318/5006] final loss [0.09327097237110138] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4319/5006] final loss [0.03217992186546326] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4320/5006] final loss [0.13420456647872925] accuracy[78.57] precision[14.29] recall[7.69] specificity[91.55] F1 score[0.1]\n",
      "[4321/5006] final loss [0.059916093945503235] accuracy[86.61] precision[25.0] recall[44.44] specificity[89.83] F1 score[0.32]\n",
      "[4322/5006] final loss [0.1701703667640686] accuracy[94.4] precision[0.0] recall[0] specificity[94.4] F1 score[0]\n",
      "[4323/5006] final loss [0.12292776256799698] accuracy[92.31] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[4324/5006] final loss [0.14005519449710846] accuracy[88.39] precision[5.88] recall[6.25] specificity[93.63] F1 score[0.06]\n",
      "[4325/5006] final loss [0.15927763283252716] accuracy[96.08] precision[0.0] recall[0] specificity[96.08] F1 score[0]\n",
      "[4326/5006] final loss [0.06271164864301682] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4327/5006] final loss [0.25310200452804565] accuracy[98.15] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4328/5006] final loss [0.11064857244491577] accuracy[91.53] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[4329/5006] final loss [0.04662901908159256] accuracy[92.45] precision[0.0] recall[0] specificity[92.45] F1 score[0]\n",
      "[4330/5006] final loss [0.13682921230793] accuracy[92.64] precision[0.0] recall[0] specificity[92.64] F1 score[0]\n",
      "[4331/5006] final loss [0.07227303832769394] accuracy[89.8] precision[0.0] recall[0.0] specificity[93.62] F1 score[0]\n",
      "[4332/5006] final loss [0.2133007049560547] accuracy[86.36] precision[33.33] recall[50.0] specificity[90.0] F1 score[0.4]\n",
      "[4333/5006] final loss [0.3250559866428375] accuracy[92.65] precision[0.0] recall[0.0] specificity[95.45] F1 score[0]\n",
      "[4334/5006] final loss [0.10993766784667969] accuracy[89.19] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[4335/5006] final loss [0.016319116577506065] accuracy[96.07] precision[0.0] recall[0] specificity[96.07] F1 score[0]\n",
      "[4336/5006] final loss [0.12930724024772644] accuracy[92.22] precision[0.0] recall[0.0] specificity[93.26] F1 score[0]\n",
      "[4337/5006] final loss [0.10688850283622742] accuracy[94.49] precision[12.5] recall[100.0] specificity[94.44] F1 score[0.22]\n",
      "[4338/5006] final loss [0.14966410398483276] accuracy[90.0] precision[11.11] recall[12.5] specificity[94.37] F1 score[0.12]\n",
      "[4339/5006] final loss [0.1844988316297531] accuracy[90.83] precision[0.0] recall[0.0] specificity[92.52] F1 score[0]\n",
      "[4340/5006] final loss [0.3112601041793823] accuracy[93.91] precision[0.0] recall[0] specificity[93.91] F1 score[0]\n",
      "[4341/5006] final loss [0.22302082180976868] accuracy[82.3] precision[31.25] recall[14.71] specificity[94.27] F1 score[0.2]\n",
      "[4342/5006] final loss [0.20941084623336792] accuracy[82.91] precision[11.76] recall[14.29] specificity[89.58] F1 score[0.13]\n",
      "[4343/5006] final loss [0.1514044851064682] accuracy[88.96] precision[0.0] recall[0.0] specificity[92.57] F1 score[0]\n",
      "[4344/5006] final loss [0.1079641804099083] accuracy[88.96] precision[18.18] recall[18.18] specificity[94.08] F1 score[0.18]\n",
      "[4345/5006] final loss [0.11837417632341385] accuracy[90.67] precision[0.0] recall[0.0] specificity[95.77] F1 score[0]\n",
      "[4346/5006] final loss [0.11862455308437347] accuracy[77.78] precision[100.0] recall[20.0] specificity[100.0] F1 score[0.33]\n",
      "[4347/5006] final loss [0.24184900522232056] accuracy[98.41] precision[0.0] recall[0] specificity[98.41] F1 score[0]\n",
      "[4348/5006] final loss [0.036733172833919525] accuracy[96.88] precision[50.0] recall[100.0] specificity[96.77] F1 score[0.67]\n",
      "[4349/5006] final loss [0.15590381622314453] accuracy[91.67] precision[33.33] recall[50.0] specificity[94.12] F1 score[0.4]\n",
      "[4350/5006] final loss [0.16278408467769623] accuracy[87.06] precision[14.29] recall[5.88] specificity[96.08] F1 score[0.08]\n",
      "[4351/5006] final loss [0.050793807953596115] accuracy[92.11] precision[0.0] recall[0.0] specificity[95.89] F1 score[0]\n",
      "[4352/5006] final loss [0.14403663575649261] accuracy[91.94] precision[0.0] recall[0.0] specificity[92.43] F1 score[0]\n",
      "[4353/5006] final loss [0.06957913190126419] accuracy[78.15] precision[28.57] recall[8.7] specificity[94.79] F1 score[0.13]\n",
      "[4354/5006] final loss [0.16508904099464417] accuracy[90.74] precision[30.0] recall[27.27] specificity[95.36] F1 score[0.29]\n",
      "[4355/5006] final loss [0.023511698469519615] accuracy[88.57] precision[50.0] recall[25.0] specificity[96.77] F1 score[0.33]\n",
      "[4356/5006] final loss [0.047620996832847595] accuracy[94.67] precision[0.0] recall[0] specificity[94.67] F1 score[0]\n",
      "[4357/5006] final loss [0.027330154553055763] accuracy[93.67] precision[0.0] recall[0] specificity[93.67] F1 score[0]\n",
      "[4358/5006] final loss [0.17255325615406036] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[4359/5006] final loss [0.14119626581668854] accuracy[90.91] precision[22.22] recall[28.57] specificity[94.4] F1 score[0.25]\n",
      "[4360/5006] final loss [0.2545216679573059] accuracy[86.16] precision[12.5] recall[20.0] specificity[90.6] F1 score[0.15]\n",
      "[4361/5006] final loss [0.06249454244971275] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[4362/5006] final loss [0.16256122291088104] accuracy[86.07] precision[11.11] recall[10.0] specificity[92.86] F1 score[0.11]\n",
      "[4363/5006] final loss [0.11058054864406586] accuracy[84.86] precision[6.67] recall[5.0] specificity[92.93] F1 score[0.06]\n",
      "[4364/5006] final loss [0.0916149690747261] accuracy[93.15] precision[0.0] recall[0.0] specificity[94.01] F1 score[0]\n",
      "[4365/5006] final loss [0.11377187818288803] accuracy[96.08] precision[33.33] recall[100.0] specificity[96.0] F1 score[0.5]\n",
      "[4366/5006] final loss [0.08797524869441986] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4367/5006] final loss [0.06178060173988342] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[4368/5006] final loss [0.06474334001541138] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[4369/5006] final loss [0.031244756653904915] accuracy[66.67] precision[0.0] recall[0] specificity[66.67] F1 score[0]\n",
      "[4370/5006] final loss [0.10701186954975128] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4371/5006] final loss [0.045140814036130905] accuracy[94.17] precision[0.0] recall[0.0] specificity[95.1] F1 score[0]\n",
      "[4372/5006] final loss [0.1385209858417511] accuracy[90.77] precision[0.0] recall[0.0] specificity[94.65] F1 score[0]\n",
      "[4373/5006] final loss [0.17940287292003632] accuracy[93.98] precision[25.0] recall[33.33] specificity[96.25] F1 score[0.29]\n",
      "[4374/5006] final loss [0.06295996159315109] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4375/5006] final loss [0.08362624049186707] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4376/5006] final loss [0.022280722856521606] accuracy[98.77] precision[50.0] recall[100.0] specificity[98.75] F1 score[0.67]\n",
      "[4377/5006] final loss [0.091509148478508] accuracy[91.49] precision[0.0] recall[0.0] specificity[95.56] F1 score[0]\n",
      "[4378/5006] final loss [0.15680217742919922] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[4379/5006] final loss [0.09342215210199356] accuracy[88.75] precision[18.18] recall[13.33] specificity[95.01] F1 score[0.15]\n",
      "[4380/5006] final loss [0.0907653421163559] accuracy[97.5] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[4381/5006] final loss [0.13190056383609772] accuracy[93.98] precision[0.0] recall[0.0] specificity[94.7] F1 score[0]\n",
      "[4382/5006] final loss [0.15693841874599457] accuracy[91.25] precision[9.52] recall[15.38] specificity[94.24] F1 score[0.12]\n",
      "[4383/5006] final loss [0.11487802118062973] accuracy[88.24] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[4384/5006] final loss [0.013343016617000103] accuracy[80.0] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4385/5006] final loss [0.012133914977312088] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[4386/5006] final loss [0.031658660620450974] accuracy[88.72] precision[15.38] recall[15.38] specificity[93.96] F1 score[0.15]\n",
      "[4387/5006] final loss [0.09659052640199661] accuracy[93.25] precision[0.0] recall[0.0] specificity[94.41] F1 score[0]\n",
      "[4388/5006] final loss [0.198477104306221] accuracy[87.5] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4389/5006] final loss [0.010860539972782135] accuracy[92.11] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[4390/5006] final loss [0.15633819997310638] accuracy[88.96] precision[4.0] recall[10.0] specificity[91.7] F1 score[0.06]\n",
      "[4391/5006] final loss [0.11100755631923676] accuracy[92.26] precision[0.0] recall[0.0] specificity[93.37] F1 score[0]\n",
      "[4392/5006] final loss [0.1420118659734726] accuracy[94.34] precision[0.0] recall[0] specificity[94.34] F1 score[0]\n",
      "[4393/5006] final loss [0.03530282527208328] accuracy[95.89] precision[0.0] recall[0] specificity[95.89] F1 score[0]\n",
      "[4394/5006] final loss [0.23372751474380493] accuracy[93.75] precision[0.0] recall[0.0] specificity[94.41] F1 score[0]\n",
      "[4395/5006] final loss [0.016402261331677437] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4396/5006] final loss [0.10752370953559875] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[4397/5006] final loss [0.04422595724463463] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4398/5006] final loss [0.18700993061065674] accuracy[94.44] precision[50.0] recall[25.0] specificity[98.53] F1 score[0.33]\n",
      "[4399/5006] final loss [0.2526223659515381] accuracy[93.04] precision[0.0] recall[0.0] specificity[93.45] F1 score[0]\n",
      "[4400/5006] final loss [0.09595970809459686] accuracy[91.8] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4401/5006] final loss [0.18402889370918274] accuracy[88.0] precision[0.0] recall[0.0] specificity[91.67] F1 score[0]\n",
      "[4402/5006] final loss [0.18078935146331787] accuracy[94.44] precision[11.11] recall[50.0] specificity[95.0] F1 score[0.18]\n",
      "[4403/5006] final loss [0.09033765643835068] accuracy[86.73] precision[28.57] recall[20.0] specificity[94.32] F1 score[0.24]\n",
      "[4404/5006] final loss [0.17526288330554962] accuracy[88.66] precision[0.0] recall[0.0] specificity[94.51] F1 score[0]\n",
      "[4405/5006] final loss [0.024480918422341347] accuracy[92.31] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[4406/5006] final loss [0.1794639676809311] accuracy[82.93] precision[40.0] recall[33.33] specificity[91.43] F1 score[0.36]\n",
      "[4407/5006] final loss [0.14929243922233582] accuracy[85.37] precision[50.0] recall[41.67] specificity[92.86] F1 score[0.45]\n",
      "[4408/5006] final loss [0.012477818876504898] accuracy[97.92] precision[0.0] recall[0] specificity[97.92] F1 score[0]\n",
      "[4409/5006] final loss [0.017556866630911827] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[4410/5006] final loss [0.04948068782687187] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[4411/5006] final loss [0.037883397191762924] accuracy[78.26] precision[100.0] recall[28.57] specificity[100.0] F1 score[0.44]\n",
      "[4412/5006] final loss [0.048947229981422424] accuracy[92.06] precision[0.0] recall[0.0] specificity[95.08] F1 score[0]\n",
      "[4413/5006] final loss [0.1449793428182602] accuracy[90.59] precision[5.56] recall[12.5] specificity[93.12] F1 score[0.08]\n",
      "[4414/5006] final loss [0.16750840842723846] accuracy[94.81] precision[0.0] recall[0] specificity[94.81] F1 score[0]\n",
      "[4415/5006] final loss [0.21005719900131226] accuracy[87.45] precision[12.5] recall[11.11] specificity[93.67] F1 score[0.12]\n",
      "[4416/5006] final loss [0.07543214410543442] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[4417/5006] final loss [0.16715624928474426] accuracy[90.15] precision[0.0] recall[0.0] specificity[92.25] F1 score[0]\n",
      "[4418/5006] final loss [0.09522244334220886] accuracy[92.19] precision[0.0] recall[0] specificity[92.19] F1 score[0]\n",
      "[4419/5006] final loss [0.12065458297729492] accuracy[92.81] precision[12.5] recall[25.0] specificity[94.81] F1 score[0.17]\n",
      "[4420/5006] final loss [0.12681858241558075] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[4421/5006] final loss [0.032628778368234634] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[4422/5006] final loss [0.1203344389796257] accuracy[94.15] precision[0.0] recall[0] specificity[94.15] F1 score[0]\n",
      "[4423/5006] final loss [0.17387498915195465] accuracy[97.14] precision[50.0] recall[100.0] specificity[97.06] F1 score[0.67]\n",
      "[4424/5006] final loss [0.198639377951622] accuracy[92.77] precision[0.0] recall[0] specificity[92.77] F1 score[0]\n",
      "[4425/5006] final loss [0.08393076062202454] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4426/5006] final loss [0.015597020275890827] accuracy[80.49] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[4427/5006] final loss [0.134454146027565] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[4428/5006] final loss [0.15439823269844055] accuracy[87.57] precision[0.0] recall[0.0] specificity[93.67] F1 score[0]\n",
      "[4429/5006] final loss [0.14663510024547577] accuracy[97.65] precision[0.0] recall[0] specificity[97.65] F1 score[0]\n",
      "[4430/5006] final loss [0.058791421353816986] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[4431/5006] final loss [0.24756547808647156] accuracy[90.65] precision[0.0] recall[0.0] specificity[92.38] F1 score[0]\n",
      "[4432/5006] final loss [0.0646844357252121] accuracy[94.0] precision[0.0] recall[0.0] specificity[95.92] F1 score[0]\n",
      "[4433/5006] final loss [0.07298198342323303] accuracy[98.15] precision[0.0] recall[0] specificity[98.15] F1 score[0]\n",
      "[4434/5006] final loss [0.14098408818244934] accuracy[87.34] precision[25.0] recall[33.33] specificity[91.78] F1 score[0.29]\n",
      "[4435/5006] final loss [0.1984066665172577] accuracy[94.89] precision[12.5] recall[100.0] specificity[94.85] F1 score[0.22]\n",
      "[4436/5006] final loss [0.008808108046650887] accuracy[96.15] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4437/5006] final loss [0.15323016047477722] accuracy[79.78] precision[12.5] recall[8.33] specificity[90.91] F1 score[0.1]\n",
      "[4438/5006] final loss [0.25002267956733704] accuracy[98.72] precision[75.0] recall[100.0] specificity[98.67] F1 score[0.86]\n",
      "[4439/5006] final loss [0.10797424614429474] accuracy[93.33] precision[0.0] recall[0.0] specificity[93.96] F1 score[0]\n",
      "[4440/5006] final loss [0.2259557694196701] accuracy[88.35] precision[0.0] recall[0.0] specificity[89.8] F1 score[0]\n",
      "[4441/5006] final loss [0.15549245476722717] accuracy[89.68] precision[10.71] recall[30.0] specificity[91.67] F1 score[0.16]\n",
      "[4442/5006] final loss [0.06913463026285172] accuracy[93.83] precision[0.0] recall[0] specificity[93.83] F1 score[0]\n",
      "[4443/5006] final loss [0.10291822999715805] accuracy[93.07] precision[0.0] recall[0.0] specificity[94.95] F1 score[0]\n",
      "[4444/5006] final loss [0.16523917019367218] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4445/5006] final loss [0.201232448220253] accuracy[95.77] precision[0.0] recall[0.0] specificity[96.45] F1 score[0]\n",
      "[4446/5006] final loss [0.01696348935365677] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[4447/5006] final loss [0.27257344126701355] accuracy[92.75] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[4448/5006] final loss [0.013630841858685017] accuracy[97.92] precision[0.0] recall[0] specificity[97.92] F1 score[0]\n",
      "[4449/5006] final loss [0.06249421834945679] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[4450/5006] final loss [0.08586107939481735] accuracy[91.06] precision[0.0] recall[0.0] specificity[94.77] F1 score[0]\n",
      "[4451/5006] final loss [0.19848434627056122] accuracy[92.0] precision[7.69] recall[20.0] specificity[93.85] F1 score[0.11]\n",
      "[4452/5006] final loss [0.21149630844593048] accuracy[77.88] precision[0.0] recall[0.0] specificity[90.72] F1 score[0]\n",
      "[4453/5006] final loss [0.030165132135152817] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[4454/5006] final loss [0.16041299700737] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4455/5006] final loss [0.056791167706251144] accuracy[88.0] precision[0.0] recall[0.0] specificity[97.78] F1 score[0]\n",
      "[4456/5006] final loss [0.11065470427274704] accuracy[85.71] precision[14.29] recall[14.29] specificity[92.21] F1 score[0.14]\n",
      "[4457/5006] final loss [0.19966855645179749] accuracy[75.86] precision[30.77] recall[13.33] specificity[92.17] F1 score[0.19]\n",
      "[4458/5006] final loss [0.015612568706274033] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4459/5006] final loss [0.1872384250164032] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4460/5006] final loss [0.015386056154966354] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4461/5006] final loss [0.1572389304637909] accuracy[91.94] precision[14.29] recall[20.0] specificity[94.96] F1 score[0.17]\n",
      "[4462/5006] final loss [0.08730504661798477] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[4463/5006] final loss [0.005046080332249403] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4464/5006] final loss [0.14272578060626984] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4465/5006] final loss [0.05315214768052101] accuracy[98.33] precision[50.0] recall[100.0] specificity[98.31] F1 score[0.67]\n",
      "[4466/5006] final loss [0.13071109354496002] accuracy[92.16] precision[0.0] recall[0.0] specificity[95.92] F1 score[0]\n",
      "[4467/5006] final loss [0.05509030073881149] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[4468/5006] final loss [0.050279974937438965] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4469/5006] final loss [0.021577684208750725] accuracy[85.19] precision[0.0] recall[0.0] specificity[97.18] F1 score[0]\n",
      "[4470/5006] final loss [0.14453326165676117] accuracy[91.43] precision[20.0] recall[33.33] specificity[94.03] F1 score[0.25]\n",
      "[4471/5006] final loss [0.018356140702962875] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[4472/5006] final loss [0.02407558262348175] accuracy[97.52] precision[0.0] recall[0] specificity[97.52] F1 score[0]\n",
      "[4473/5006] final loss [0.01227259635925293] accuracy[95.48] precision[0.0] recall[0] specificity[95.48] F1 score[0]\n",
      "[4474/5006] final loss [0.25095951557159424] accuracy[85.48] precision[100.0] recall[25.0] specificity[100.0] F1 score[0.4]\n",
      "[4475/5006] final loss [0.1024610623717308] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[4476/5006] final loss [0.06577301025390625] accuracy[93.24] precision[20.0] recall[50.0] specificity[94.44] F1 score[0.29]\n",
      "[4477/5006] final loss [0.09250006824731827] accuracy[85.0] precision[0.0] recall[0.0] specificity[91.54] F1 score[0]\n",
      "[4478/5006] final loss [0.03590844199061394] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4479/5006] final loss [0.11565057933330536] accuracy[87.5] precision[0.0] recall[0] specificity[87.5] F1 score[0]\n",
      "[4480/5006] final loss [0.1472991704940796] accuracy[90.67] precision[0.0] recall[0.0] specificity[95.33] F1 score[0]\n",
      "[4481/5006] final loss [0.1255577951669693] accuracy[81.86] precision[20.0] recall[13.79] specificity[91.88] F1 score[0.16]\n",
      "[4482/5006] final loss [0.07647557556629181] accuracy[95.83] precision[100.0] recall[50.0] specificity[100.0] F1 score[0.67]\n",
      "[4483/5006] final loss [0.1543092578649521] accuracy[89.05] precision[7.69] recall[8.33] specificity[93.94] F1 score[0.08]\n",
      "[4484/5006] final loss [0.10613706707954407] accuracy[93.51] precision[40.0] recall[50.0] specificity[95.89] F1 score[0.44]\n",
      "[4485/5006] final loss [0.13884411752223969] accuracy[89.72] precision[44.44] recall[40.0] specificity[94.85] F1 score[0.42]\n",
      "[4486/5006] final loss [0.14489616453647614] accuracy[97.22] precision[0.0] recall[0] specificity[97.22] F1 score[0]\n",
      "[4487/5006] final loss [0.23198655247688293] accuracy[90.59] precision[0.0] recall[0] specificity[90.59] F1 score[0]\n",
      "[4488/5006] final loss [0.19383585453033447] accuracy[95.33] precision[20.0] recall[50.0] specificity[96.19] F1 score[0.29]\n",
      "[4489/5006] final loss [0.0931931808590889] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4490/5006] final loss [0.03434567153453827] accuracy[91.3] precision[0.0] recall[0] specificity[91.3] F1 score[0]\n",
      "[4491/5006] final loss [0.11008293181657791] accuracy[89.72] precision[20.0] recall[28.57] specificity[93.31] F1 score[0.24]\n",
      "[4492/5006] final loss [0.09745281934738159] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[4493/5006] final loss [0.27213966846466064] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[4494/5006] final loss [0.1386406123638153] accuracy[91.18] precision[20.0] recall[16.67] specificity[95.83] F1 score[0.18]\n",
      "[4495/5006] final loss [0.0378728024661541] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[4496/5006] final loss [0.08020991086959839] accuracy[86.08] precision[40.0] recall[20.0] specificity[95.65] F1 score[0.27]\n",
      "[4497/5006] final loss [0.08669400960206985] accuracy[98.04] precision[50.0] recall[100.0] specificity[98.0] F1 score[0.67]\n",
      "[4498/5006] final loss [0.2137298285961151] accuracy[87.94] precision[8.33] recall[14.29] specificity[91.79] F1 score[0.11]\n",
      "[4499/5006] final loss [0.06876188516616821] accuracy[96.0] precision[0.0] recall[0.0] specificity[97.3] F1 score[0]\n",
      "[4500/5006] final loss [0.21640004217624664] accuracy[92.66] precision[12.5] recall[50.0] specificity[93.46] F1 score[0.2]\n",
      "[4501/5006] final loss [0.01947817951440811] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4502/5006] final loss [0.06355522572994232] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4503/5006] final loss [0.13155727088451385] accuracy[80.98] precision[25.0] recall[9.09] specificity[94.77] F1 score[0.13]\n",
      "[4504/5006] final loss [0.18948175013065338] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[4505/5006] final loss [0.028443627059459686] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4506/5006] final loss [0.1251419633626938] accuracy[90.0] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[4507/5006] final loss [0.0936480388045311] accuracy[95.53] precision[0.0] recall[0] specificity[95.53] F1 score[0]\n",
      "[4508/5006] final loss [0.2452745884656906] accuracy[87.25] precision[35.29] recall[17.65] specificity[95.96] F1 score[0.24]\n",
      "[4509/5006] final loss [0.21806688606739044] accuracy[94.44] precision[20.0] recall[100.0] specificity[94.37] F1 score[0.33]\n",
      "[4510/5006] final loss [0.05542081594467163] accuracy[93.65] precision[0.0] recall[0.0] specificity[98.33] F1 score[0]\n",
      "[4511/5006] final loss [0.13246342539787292] accuracy[91.89] precision[0.0] recall[0] specificity[91.89] F1 score[0]\n",
      "[4512/5006] final loss [0.09968052059412003] accuracy[89.47] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4513/5006] final loss [0.07105088233947754] accuracy[92.94] precision[0.0] recall[0] specificity[92.94] F1 score[0]\n",
      "[4514/5006] final loss [0.1742282509803772] accuracy[90.44] precision[10.0] recall[20.0] specificity[93.13] F1 score[0.13]\n",
      "[4515/5006] final loss [0.1280575841665268] accuracy[79.68] precision[41.18] recall[20.0] specificity[93.42] F1 score[0.27]\n",
      "[4516/5006] final loss [0.24349510669708252] accuracy[94.67] precision[0.0] recall[0] specificity[94.67] F1 score[0]\n",
      "[4517/5006] final loss [0.12987543642520905] accuracy[83.5] precision[9.09] recall[4.17] specificity[94.32] F1 score[0.06]\n",
      "[4518/5006] final loss [0.11255589127540588] accuracy[90.48] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[4519/5006] final loss [0.05673850327730179] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[4520/5006] final loss [0.14752933382987976] accuracy[95.26] precision[25.0] recall[40.0] specificity[96.76] F1 score[0.31]\n",
      "[4521/5006] final loss [0.10988831520080566] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4522/5006] final loss [0.2614877223968506] accuracy[86.25] precision[12.5] recall[20.0] specificity[90.67] F1 score[0.15]\n",
      "[4523/5006] final loss [0.06584317982196808] accuracy[94.03] precision[0.0] recall[0] specificity[94.03] F1 score[0]\n",
      "[4524/5006] final loss [0.01850055530667305] accuracy[89.47] precision[0.0] recall[0.0] specificity[94.44] F1 score[0]\n",
      "[4525/5006] final loss [0.13480255007743835] accuracy[82.05] precision[0.0] recall[0.0] specificity[96.97] F1 score[0]\n",
      "[4526/5006] final loss [0.09800022840499878] accuracy[88.57] precision[25.0] recall[16.67] specificity[95.31] F1 score[0.2]\n",
      "[4527/5006] final loss [0.176278755068779] accuracy[87.24] precision[0.0] recall[0.0] specificity[91.38] F1 score[0]\n",
      "[4528/5006] final loss [0.07246663421392441] accuracy[87.5] precision[0.0] recall[0.0] specificity[92.45] F1 score[0]\n",
      "[4529/5006] final loss [0.029078662395477295] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4530/5006] final loss [0.15840640664100647] accuracy[90.64] precision[6.25] recall[12.5] specificity[93.39] F1 score[0.08]\n",
      "[4531/5006] final loss [0.10993051528930664] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4532/5006] final loss [0.14329244196414948] accuracy[83.33] precision[0.0] recall[0] specificity[83.33] F1 score[0]\n",
      "[4533/5006] final loss [0.031247373670339584] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[4534/5006] final loss [0.034783534705638885] accuracy[94.9] precision[0.0] recall[0] specificity[94.9] F1 score[0]\n",
      "[4535/5006] final loss [0.0733904168009758] accuracy[92.98] precision[50.0] recall[50.0] specificity[96.23] F1 score[0.5]\n",
      "[4536/5006] final loss [0.2343270480632782] accuracy[96.88] precision[0.0] recall[0] specificity[96.88] F1 score[0]\n",
      "[4537/5006] final loss [0.17515866458415985] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4538/5006] final loss [0.0637969970703125] accuracy[87.78] precision[0.0] recall[0.0] specificity[97.53] F1 score[0]\n",
      "[4539/5006] final loss [0.2645097076892853] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[4540/5006] final loss [0.07455910742282867] accuracy[91.67] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4541/5006] final loss [0.1817276030778885] accuracy[76.92] precision[16.67] recall[7.14] specificity[92.19] F1 score[0.1]\n",
      "[4542/5006] final loss [0.35286304354667664] accuracy[89.9] precision[14.29] recall[20.0] specificity[93.62] F1 score[0.17]\n",
      "[4543/5006] final loss [0.09916521608829498] accuracy[88.89] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[4544/5006] final loss [0.13962934911251068] accuracy[90.0] precision[14.29] recall[20.0] specificity[93.68] F1 score[0.17]\n",
      "[4545/5006] final loss [0.027297087013721466] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4546/5006] final loss [0.09587181359529495] accuracy[95.12] precision[0.0] recall[0] specificity[95.12] F1 score[0]\n",
      "[4547/5006] final loss [0.08236951380968094] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4548/5006] final loss [0.24699386954307556] accuracy[90.7] precision[33.33] recall[33.33] specificity[95.0] F1 score[0.33]\n",
      "[4549/5006] final loss [0.06638049334287643] accuracy[88.3] precision[0.0] recall[0.0] specificity[94.32] F1 score[0]\n",
      "[4550/5006] final loss [0.15367130935192108] accuracy[97.3] precision[0.0] recall[0] specificity[97.3] F1 score[0]\n",
      "[4551/5006] final loss [0.016409607604146004] accuracy[96.91] precision[0.0] recall[0] specificity[96.91] F1 score[0]\n",
      "[4552/5006] final loss [0.27678462862968445] accuracy[92.74] precision[0.0] recall[0] specificity[92.74] F1 score[0]\n",
      "[4553/5006] final loss [0.052539292722940445] accuracy[86.67] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[4554/5006] final loss [0.09586500376462936] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[4555/5006] final loss [0.08793948590755463] accuracy[89.35] precision[25.0] recall[25.0] specificity[94.27] F1 score[0.25]\n",
      "[4556/5006] final loss [0.14398178458213806] accuracy[92.26] precision[11.11] recall[20.0] specificity[94.67] F1 score[0.14]\n",
      "[4557/5006] final loss [0.07039450109004974] accuracy[98.25] precision[0.0] recall[0] specificity[98.25] F1 score[0]\n",
      "[4558/5006] final loss [0.03473226726055145] accuracy[72.41] precision[33.33] recall[14.29] specificity[90.91] F1 score[0.2]\n",
      "[4559/5006] final loss [0.18276335299015045] accuracy[92.81] precision[11.11] recall[33.33] specificity[94.12] F1 score[0.17]\n",
      "[4560/5006] final loss [0.07639378309249878] accuracy[93.9] precision[20.0] recall[50.0] specificity[95.0] F1 score[0.29]\n",
      "[4561/5006] final loss [0.1255754828453064] accuracy[94.96] precision[0.0] recall[0] specificity[94.96] F1 score[0]\n",
      "[4562/5006] final loss [0.23713140189647675] accuracy[88.41] precision[5.56] recall[33.33] specificity[89.44] F1 score[0.1]\n",
      "[4563/5006] final loss [0.07853192090988159] accuracy[73.68] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4564/5006] final loss [0.2368459850549698] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[4565/5006] final loss [0.23535053431987762] accuracy[92.13] precision[9.09] recall[20.0] specificity[94.22] F1 score[0.12]\n",
      "[4566/5006] final loss [0.2884235382080078] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[4567/5006] final loss [0.10225670039653778] accuracy[97.5] precision[0.0] recall[0] specificity[97.5] F1 score[0]\n",
      "[4568/5006] final loss [0.1669994592666626] accuracy[92.05] precision[16.67] recall[33.33] specificity[94.12] F1 score[0.22]\n",
      "[4569/5006] final loss [0.018851516768336296] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[4570/5006] final loss [0.17850704491138458] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4571/5006] final loss [0.06499625742435455] accuracy[91.11] precision[33.33] recall[33.33] specificity[95.24] F1 score[0.33]\n",
      "[4572/5006] final loss [0.047899533063173294] accuracy[98.28] precision[0.0] recall[0] specificity[98.28] F1 score[0]\n",
      "[4573/5006] final loss [0.0006796492962166667] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4574/5006] final loss [0.5185123085975647] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4575/5006] final loss [0.1018349751830101] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[4576/5006] final loss [0.13020041584968567] accuracy[92.06] precision[0.0] recall[0.0] specificity[95.08] F1 score[0]\n",
      "[4577/5006] final loss [0.19809886813163757] accuracy[96.1] precision[25.0] recall[100.0] specificity[96.05] F1 score[0.4]\n",
      "[4578/5006] final loss [0.07659871876239777] accuracy[90.0] precision[0.0] recall[0.0] specificity[94.19] F1 score[0]\n",
      "[4579/5006] final loss [0.034942153841257095] accuracy[93.33] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4580/5006] final loss [0.14490793645381927] accuracy[93.69] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[4581/5006] final loss [0.13214111328125] accuracy[75.0] precision[0.0] recall[0.0] specificity[96.43] F1 score[0]\n",
      "[4582/5006] final loss [0.08241601288318634] accuracy[86.02] precision[0.0] recall[0.0] specificity[89.89] F1 score[0]\n",
      "[4583/5006] final loss [0.1895957887172699] accuracy[93.29] precision[0.0] recall[0.0] specificity[95.21] F1 score[0]\n",
      "[4584/5006] final loss [0.10763447731733322] accuracy[70.67] precision[0.0] recall[0.0] specificity[89.83] F1 score[0]\n",
      "[4585/5006] final loss [0.10521938651800156] accuracy[94.09] precision[9.09] recall[33.33] specificity[95.0] F1 score[0.14]\n",
      "[4586/5006] final loss [0.1267627626657486] accuracy[96.67] precision[0.0] recall[0.0] specificity[97.75] F1 score[0]\n",
      "[4587/5006] final loss [0.11150670796632767] accuracy[93.53] precision[8.33] recall[100.0] specificity[93.49] F1 score[0.15]\n",
      "[4588/5006] final loss [0.055594366043806076] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4589/5006] final loss [0.043231286108493805] accuracy[95.65] precision[50.0] recall[50.0] specificity[97.73] F1 score[0.5]\n",
      "[4590/5006] final loss [0.131559357047081] accuracy[89.27] precision[23.08] recall[16.67] specificity[95.35] F1 score[0.19]\n",
      "[4591/5006] final loss [0.24757295846939087] accuracy[87.23] precision[4.55] recall[6.67] specificity[91.89] F1 score[0.05]\n",
      "[4592/5006] final loss [0.05631978437304497] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4593/5006] final loss [0.09183008223772049] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[4594/5006] final loss [0.1372058242559433] accuracy[96.67] precision[0.0] recall[0] specificity[96.67] F1 score[0]\n",
      "[4595/5006] final loss [0.10883443802595139] accuracy[90.41] precision[10.0] recall[16.67] specificity[93.57] F1 score[0.13]\n",
      "[4596/5006] final loss [0.1098925918340683] accuracy[90.57] precision[25.0] recall[33.33] specificity[94.0] F1 score[0.29]\n",
      "[4597/5006] final loss [0.05515662953257561] accuracy[94.07] precision[0.0] recall[0] specificity[94.07] F1 score[0]\n",
      "[4598/5006] final loss [0.013767480850219727] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4599/5006] final loss [0.0784890204668045] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[4600/5006] final loss [0.18451301753520966] accuracy[91.41] precision[11.11] recall[14.29] specificity[94.87] F1 score[0.13]\n",
      "[4601/5006] final loss [0.17673206329345703] accuracy[88.89] precision[25.0] recall[15.38] specificity[95.71] F1 score[0.19]\n",
      "[4602/5006] final loss [0.2138420194387436] accuracy[95.74] precision[33.33] recall[100.0] specificity[95.65] F1 score[0.5]\n",
      "[4603/5006] final loss [0.13482002913951874] accuracy[92.0] precision[0.0] recall[0] specificity[92.0] F1 score[0]\n",
      "[4604/5006] final loss [0.23686587810516357] accuracy[88.68] precision[0.0] recall[0.0] specificity[92.16] F1 score[0]\n",
      "[4605/5006] final loss [0.048599183559417725] accuracy[90.62] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4606/5006] final loss [0.13756541907787323] accuracy[92.79] precision[0.0] recall[0] specificity[92.79] F1 score[0]\n",
      "[4607/5006] final loss [0.020102273672819138] accuracy[96.97] precision[0.0] recall[0] specificity[96.97] F1 score[0]\n",
      "[4608/5006] final loss [0.18102148175239563] accuracy[89.36] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4609/5006] final loss [0.21981953084468842] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.79] F1 score[0]\n",
      "[4610/5006] final loss [0.0912860706448555] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4611/5006] final loss [0.19378720223903656] accuracy[93.6] precision[0.0] recall[0.0] specificity[94.35] F1 score[0]\n",
      "[4612/5006] final loss [0.11674962192773819] accuracy[88.28] precision[7.69] recall[16.67] specificity[91.37] F1 score[0.11]\n",
      "[4613/5006] final loss [0.03876351937651634] accuracy[80.0] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4614/5006] final loss [0.04855822026729584] accuracy[93.14] precision[14.29] recall[50.0] specificity[94.0] F1 score[0.22]\n",
      "[4615/5006] final loss [0.13812890648841858] accuracy[92.62] precision[11.11] recall[50.0] specificity[93.33] F1 score[0.18]\n",
      "[4616/5006] final loss [0.03805198147892952] accuracy[97.3] precision[0.0] recall[0] specificity[97.3] F1 score[0]\n",
      "[4617/5006] final loss [0.30376818776130676] accuracy[93.06] precision[0.0] recall[0.0] specificity[95.71] F1 score[0]\n",
      "[4618/5006] final loss [0.17005497217178345] accuracy[66.67] precision[20.0] recall[5.88] specificity[90.7] F1 score[0.09]\n",
      "[4619/5006] final loss [0.0501246377825737] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4620/5006] final loss [0.012763679027557373] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4621/5006] final loss [0.08644010871648788] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4622/5006] final loss [0.11999029666185379] accuracy[94.51] precision[16.67] recall[100.0] specificity[94.44] F1 score[0.29]\n",
      "[4623/5006] final loss [0.05742301046848297] accuracy[97.92] precision[0.0] recall[0] specificity[97.92] F1 score[0]\n",
      "[4624/5006] final loss [0.03992002084851265] accuracy[94.74] precision[0.0] recall[0.0] specificity[98.18] F1 score[0]\n",
      "[4625/5006] final loss [0.08041155338287354] accuracy[84.0] precision[0.0] recall[0.0] specificity[92.65] F1 score[0]\n",
      "[4626/5006] final loss [0.1465444415807724] accuracy[87.58] precision[0.0] recall[0.0] specificity[94.37] F1 score[0]\n",
      "[4627/5006] final loss [0.1284102350473404] accuracy[98.15] precision[0.0] recall[0] specificity[98.15] F1 score[0]\n",
      "[4628/5006] final loss [0.09731929749250412] accuracy[93.65] precision[100.0] recall[33.33] specificity[100.0] F1 score[0.5]\n",
      "[4629/5006] final loss [0.05886857956647873] accuracy[81.36] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[4630/5006] final loss [0.2004457712173462] accuracy[81.07] precision[31.03] recall[42.86] specificity[86.49] F1 score[0.36]\n",
      "[4631/5006] final loss [0.08696164190769196] accuracy[86.14] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[4632/5006] final loss [0.05943876504898071] accuracy[94.65] precision[16.67] recall[16.67] specificity[97.24] F1 score[0.17]\n",
      "[4633/5006] final loss [0.07463737577199936] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4634/5006] final loss [0.03319026157259941] accuracy[83.61] precision[33.33] recall[11.11] specificity[96.15] F1 score[0.17]\n",
      "[4635/5006] final loss [0.126707062125206] accuracy[89.41] precision[20.0] recall[66.67] specificity[90.24] F1 score[0.31]\n",
      "[4636/5006] final loss [0.17595607042312622] accuracy[85.71] precision[16.67] recall[9.09] specificity[94.68] F1 score[0.12]\n",
      "[4637/5006] final loss [0.08691205084323883] accuracy[81.95] precision[16.0] recall[20.0] specificity[88.65] F1 score[0.18]\n",
      "[4638/5006] final loss [0.06872905045747757] accuracy[89.83] precision[0.0] recall[0.0] specificity[98.15] F1 score[0]\n",
      "[4639/5006] final loss [0.01621348038315773] accuracy[80.95] precision[0.0] recall[0.0] specificity[89.47] F1 score[0]\n",
      "[4640/5006] final loss [0.01775742881000042] accuracy[95.24] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4641/5006] final loss [0.11326944828033447] accuracy[93.69] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[4642/5006] final loss [0.09694666415452957] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[4643/5006] final loss [0.1238471269607544] accuracy[90.54] precision[0.0] recall[0.0] specificity[94.37] F1 score[0]\n",
      "[4644/5006] final loss [0.06468753516674042] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4645/5006] final loss [0.11831872165203094] accuracy[91.38] precision[33.33] recall[25.0] specificity[96.3] F1 score[0.29]\n",
      "[4646/5006] final loss [0.040643319487571716] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[4647/5006] final loss [0.13545574247837067] accuracy[93.62] precision[25.0] recall[25.0] specificity[96.67] F1 score[0.25]\n",
      "[4648/5006] final loss [0.05843765661120415] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[4649/5006] final loss [0.09885397553443909] accuracy[86.21] precision[50.0] recall[25.0] specificity[96.0] F1 score[0.33]\n",
      "[4650/5006] final loss [0.12666641175746918] accuracy[88.1] precision[0.0] recall[0.0] specificity[92.5] F1 score[0]\n",
      "[4651/5006] final loss [0.07577874511480331] accuracy[86.72] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[4652/5006] final loss [0.1363985240459442] accuracy[75.68] precision[22.73] recall[20.83] specificity[86.29] F1 score[0.22]\n",
      "[4653/5006] final loss [0.10634448379278183] accuracy[82.98] precision[7.69] recall[20.0] specificity[86.52] F1 score[0.11]\n",
      "[4654/5006] final loss [0.008581777103245258] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[4655/5006] final loss [0.13471370935440063] accuracy[82.08] precision[50.0] recall[31.58] specificity[93.1] F1 score[0.39]\n",
      "[4656/5006] final loss [0.07114476710557938] accuracy[94.17] precision[0.0] recall[0.0] specificity[95.1] F1 score[0]\n",
      "[4657/5006] final loss [0.1111624464392662] accuracy[89.55] precision[0.0] recall[0.0] specificity[92.31] F1 score[0]\n",
      "[4658/5006] final loss [0.12650372087955475] accuracy[93.75] precision[16.67] recall[33.33] specificity[95.41] F1 score[0.22]\n",
      "[4659/5006] final loss [0.1362369805574417] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4660/5006] final loss [0.1552346795797348] accuracy[91.21] precision[25.0] recall[16.67] specificity[96.47] F1 score[0.2]\n",
      "[4661/5006] final loss [0.109660804271698] accuracy[95.31] precision[0.0] recall[0] specificity[95.31] F1 score[0]\n",
      "[4662/5006] final loss [0.14568452537059784] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4663/5006] final loss [0.17513629794120789] accuracy[93.65] precision[0.0] recall[0] specificity[93.65] F1 score[0]\n",
      "[4664/5006] final loss [0.14862743020057678] accuracy[92.47] precision[0.0] recall[0.0] specificity[93.99] F1 score[0]\n",
      "[4665/5006] final loss [0.09396381676197052] accuracy[88.31] precision[14.29] recall[25.0] specificity[91.78] F1 score[0.18]\n",
      "[4666/5006] final loss [0.215569868683815] accuracy[93.75] precision[40.0] recall[40.0] specificity[96.7] F1 score[0.4]\n",
      "[4667/5006] final loss [0.018773483112454414] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4668/5006] final loss [0.29923829436302185] accuracy[74.03] precision[66.67] recall[9.52] specificity[98.21] F1 score[0.17]\n",
      "[4669/5006] final loss [0.12711524963378906] accuracy[95.65] precision[0.0] recall[0] specificity[95.65] F1 score[0]\n",
      "[4670/5006] final loss [0.04430793598294258] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4671/5006] final loss [0.27995565533638] accuracy[91.89] precision[0.0] recall[0.0] specificity[92.9] F1 score[0]\n",
      "[4672/5006] final loss [0.05594466254115105] accuracy[88.33] precision[0.0] recall[0.0] specificity[94.64] F1 score[0]\n",
      "[4673/5006] final loss [0.24587099254131317] accuracy[96.1] precision[0.0] recall[0] specificity[96.1] F1 score[0]\n",
      "[4674/5006] final loss [0.015668367967009544] accuracy[83.91] precision[0.0] recall[0.0] specificity[98.65] F1 score[0]\n",
      "[4675/5006] final loss [0.134863942861557] accuracy[92.73] precision[0.0] recall[0] specificity[92.73] F1 score[0]\n",
      "[4676/5006] final loss [0.06225898489356041] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4677/5006] final loss [0.15276794135570526] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4678/5006] final loss [0.15531671047210693] accuracy[93.88] precision[0.0] recall[0] specificity[93.88] F1 score[0]\n",
      "[4679/5006] final loss [0.15651673078536987] accuracy[90.48] precision[0.0] recall[0.0] specificity[92.68] F1 score[0]\n",
      "[4680/5006] final loss [0.009645978920161724] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4681/5006] final loss [0.06490690261125565] accuracy[93.42] precision[20.0] recall[14.29] specificity[97.24] F1 score[0.17]\n",
      "[4682/5006] final loss [0.3612012565135956] accuracy[93.41] precision[0.0] recall[0] specificity[93.41] F1 score[0]\n",
      "[4683/5006] final loss [0.2237931191921234] accuracy[88.04] precision[0.0] recall[0.0] specificity[95.29] F1 score[0]\n",
      "[4684/5006] final loss [0.1606440544128418] accuracy[95.6] precision[0.0] recall[0] specificity[95.6] F1 score[0]\n",
      "[4685/5006] final loss [0.0501629114151001] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4686/5006] final loss [0.07203813642263412] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4687/5006] final loss [0.06971411406993866] accuracy[93.62] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[4688/5006] final loss [0.030644094571471214] accuracy[97.93] precision[0.0] recall[0] specificity[97.93] F1 score[0]\n",
      "[4689/5006] final loss [0.06309249252080917] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n",
      "[4690/5006] final loss [0.108333520591259] accuracy[94.05] precision[0.0] recall[0] specificity[94.05] F1 score[0]\n",
      "[4691/5006] final loss [0.12744839489459991] accuracy[84.16] precision[8.33] recall[4.55] specificity[93.89] F1 score[0.06]\n",
      "[4692/5006] final loss [0.19326461851596832] accuracy[91.67] precision[16.67] recall[33.33] specificity[93.83] F1 score[0.22]\n",
      "[4693/5006] final loss [0.17847493290901184] accuracy[88.06] precision[30.77] recall[21.05] specificity[95.05] F1 score[0.25]\n",
      "[4694/5006] final loss [0.06204364076256752] accuracy[93.92] precision[11.11] recall[50.0] specificity[94.52] F1 score[0.18]\n",
      "[4695/5006] final loss [0.057634759694337845] accuracy[85.16] precision[42.86] recall[13.64] specificity[96.99] F1 score[0.21]\n",
      "[4696/5006] final loss [0.02678259089589119] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4697/5006] final loss [0.10637137293815613] accuracy[93.27] precision[14.29] recall[50.0] specificity[94.12] F1 score[0.22]\n",
      "[4698/5006] final loss [0.16119952499866486] accuracy[80.85] precision[16.67] recall[7.14] specificity[93.75] F1 score[0.1]\n",
      "[4699/5006] final loss [0.28513431549072266] accuracy[50.0] precision[0.0] recall[0] specificity[50.0] F1 score[0]\n",
      "[4700/5006] final loss [0.08459216356277466] accuracy[87.8] precision[30.0] recall[18.75] specificity[95.27] F1 score[0.23]\n",
      "[4701/5006] final loss [0.11330695450305939] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[4702/5006] final loss [0.012605029158294201] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4703/5006] final loss [0.24126406013965607] accuracy[92.55] precision[18.75] recall[75.0] specificity[92.93] F1 score[0.3]\n",
      "[4704/5006] final loss [0.10447442531585693] accuracy[88.76] precision[15.38] recall[20.0] specificity[93.08] F1 score[0.17]\n",
      "[4705/5006] final loss [0.1885809600353241] accuracy[90.0] precision[20.0] recall[33.33] specificity[92.98] F1 score[0.25]\n",
      "[4706/5006] final loss [0.08459250628948212] accuracy[89.08] precision[12.5] recall[7.69] specificity[95.65] F1 score[0.1]\n",
      "[4707/5006] final loss [0.0988650918006897] accuracy[87.3] precision[7.14] recall[8.33] specificity[92.66] F1 score[0.08]\n",
      "[4708/5006] final loss [0.03908631578087807] accuracy[94.69] precision[33.33] recall[50.0] specificity[96.33] F1 score[0.4]\n",
      "[4709/5006] final loss [0.1552840918302536] accuracy[92.65] precision[0.0] recall[0.0] specificity[94.03] F1 score[0]\n",
      "[4710/5006] final loss [0.11016900092363358] accuracy[93.3] precision[0.0] recall[0.0] specificity[93.82] F1 score[0]\n",
      "[4711/5006] final loss [0.11053238064050674] accuracy[93.02] precision[0.0] recall[0] specificity[93.02] F1 score[0]\n",
      "[4712/5006] final loss [0.17892445623874664] accuracy[93.75] precision[0.0] recall[0.0] specificity[94.59] F1 score[0]\n",
      "[4713/5006] final loss [0.13693764805793762] accuracy[95.21] precision[16.67] recall[33.33] specificity[96.5] F1 score[0.22]\n",
      "[4714/5006] final loss [0.07269290834665298] accuracy[93.48] precision[0.0] recall[0] specificity[93.48] F1 score[0]\n",
      "[4715/5006] final loss [0.12063296139240265] accuracy[84.68] precision[11.11] recall[10.0] specificity[92.08] F1 score[0.11]\n",
      "[4716/5006] final loss [0.01672867126762867] accuracy[85.07] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[4717/5006] final loss [0.20110636949539185] accuracy[89.8] precision[0.0] recall[0.0] specificity[95.65] F1 score[0]\n",
      "[4718/5006] final loss [0.18063268065452576] accuracy[92.98] precision[0.0] recall[0] specificity[92.98] F1 score[0]\n",
      "[4719/5006] final loss [0.12033866345882416] accuracy[92.86] precision[0.0] recall[0.0] specificity[94.08] F1 score[0]\n",
      "[4720/5006] final loss [0.062014125287532806] accuracy[86.67] precision[0.0] recall[0.0] specificity[89.66] F1 score[0]\n",
      "[4721/5006] final loss [0.13138005137443542] accuracy[92.41] precision[0.0] recall[0.0] specificity[94.81] F1 score[0]\n",
      "[4722/5006] final loss [0.06798581033945084] accuracy[92.68] precision[0.0] recall[0] specificity[92.68] F1 score[0]\n",
      "[4723/5006] final loss [0.19592300057411194] accuracy[91.2] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[4724/5006] final loss [0.09096456319093704] accuracy[92.31] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[4725/5006] final loss [0.1413937658071518] accuracy[82.22] precision[16.67] recall[25.0] specificity[87.8] F1 score[0.2]\n",
      "[4726/5006] final loss [0.12587758898735046] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4727/5006] final loss [0.1224314495921135] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[4728/5006] final loss [0.1911594271659851] accuracy[90.91] precision[0.0] recall[0.0] specificity[97.56] F1 score[0]\n",
      "[4729/5006] final loss [0.11022913455963135] accuracy[95.0] precision[50.0] recall[50.0] specificity[97.37] F1 score[0.5]\n",
      "[4730/5006] final loss [0.10040201246738434] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[4731/5006] final loss [0.15785133838653564] accuracy[91.45] precision[28.57] recall[28.57] specificity[95.45] F1 score[0.29]\n",
      "[4732/5006] final loss [0.1682276576757431] accuracy[90.12] precision[7.69] recall[7.69] specificity[94.78] F1 score[0.08]\n",
      "[4733/5006] final loss [0.04500651732087135] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4734/5006] final loss [0.37402620911598206] accuracy[94.17] precision[0.0] recall[0] specificity[94.17] F1 score[0]\n",
      "[4735/5006] final loss [0.16903042793273926] accuracy[90.05] precision[0.0] recall[0.0] specificity[90.75] F1 score[0]\n",
      "[4736/5006] final loss [0.2391924411058426] accuracy[93.49] precision[0.0] recall[0.0] specificity[95.18] F1 score[0]\n",
      "[4737/5006] final loss [0.1934383064508438] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4738/5006] final loss [0.14995138347148895] accuracy[91.18] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[4739/5006] final loss [0.1073744148015976] accuracy[91.81] precision[0.0] recall[0.0] specificity[93.83] F1 score[0]\n",
      "[4740/5006] final loss [0.1051851138472557] accuracy[89.58] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[4741/5006] final loss [0.06600983440876007] accuracy[97.01] precision[33.33] recall[100.0] specificity[96.97] F1 score[0.5]\n",
      "[4742/5006] final loss [0.15303561091423035] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[4743/5006] final loss [0.08526232838630676] accuracy[83.87] precision[45.45] recall[35.71] specificity[92.41] F1 score[0.4]\n",
      "[4744/5006] final loss [0.07200346887111664] accuracy[84.0] precision[0.0] recall[0.0] specificity[94.38] F1 score[0]\n",
      "[4745/5006] final loss [0.0678723007440567] accuracy[91.84] precision[8.33] recall[16.67] specificity[94.21] F1 score[0.11]\n",
      "[4746/5006] final loss [0.010482712648808956] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[4747/5006] final loss [0.13447819650173187] accuracy[90.68] precision[0.0] recall[0.0] specificity[93.86] F1 score[0]\n",
      "[4748/5006] final loss [0.097208172082901] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4749/5006] final loss [0.2272341549396515] accuracy[92.96] precision[0.0] recall[0] specificity[92.96] F1 score[0]\n",
      "[4750/5006] final loss [0.00900679174810648] accuracy[95.69] precision[100.0] recall[16.67] specificity[100.0] F1 score[0.29]\n",
      "[4751/5006] final loss [0.033657968044281006] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4752/5006] final loss [0.09854960441589355] accuracy[83.1] precision[83.33] recall[31.25] specificity[98.18] F1 score[0.45]\n",
      "[4753/5006] final loss [0.03577670082449913] accuracy[85.71] precision[0.0] recall[0.0] specificity[96.0] F1 score[0]\n",
      "[4754/5006] final loss [0.0881519764661789] accuracy[97.78] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4755/5006] final loss [0.0599336214363575] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4756/5006] final loss [0.1852375864982605] accuracy[94.37] precision[25.0] recall[50.0] specificity[95.65] F1 score[0.33]\n",
      "[4757/5006] final loss [0.18767422437667847] accuracy[78.57] precision[40.0] recall[14.29] specificity[94.64] F1 score[0.21]\n",
      "[4758/5006] final loss [0.1695736050605774] accuracy[97.06] precision[0.0] recall[0] specificity[97.06] F1 score[0]\n",
      "[4759/5006] final loss [0.12755697965621948] accuracy[93.18] precision[0.0] recall[0] specificity[93.18] F1 score[0]\n",
      "[4760/5006] final loss [0.04276496544480324] accuracy[94.83] precision[0.0] recall[0] specificity[94.83] F1 score[0]\n",
      "[4761/5006] final loss [0.015312543138861656] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4762/5006] final loss [0.1781778335571289] accuracy[89.29] precision[20.0] recall[16.67] specificity[94.87] F1 score[0.18]\n",
      "[4763/5006] final loss [0.023408789187669754] accuracy[89.36] precision[66.67] recall[33.33] specificity[97.56] F1 score[0.44]\n",
      "[4764/5006] final loss [0.11480508744716644] accuracy[90.48] precision[50.0] recall[25.0] specificity[97.37] F1 score[0.33]\n",
      "[4765/5006] final loss [0.05868501588702202] accuracy[85.38] precision[6.67] recall[16.67] specificity[88.71] F1 score[0.1]\n",
      "[4766/5006] final loss [0.1494015008211136] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4767/5006] final loss [0.31150850653648376] accuracy[94.83] precision[0.0] recall[0] specificity[94.83] F1 score[0]\n",
      "[4768/5006] final loss [0.03152754530310631] accuracy[97.87] precision[0.0] recall[0] specificity[97.87] F1 score[0]\n",
      "[4769/5006] final loss [0.14459110796451569] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[4770/5006] final loss [0.0923016294836998] accuracy[89.41] precision[20.0] recall[16.67] specificity[94.94] F1 score[0.18]\n",
      "[4771/5006] final loss [0.05351928249001503] accuracy[81.94] precision[0.0] recall[0.0] specificity[95.16] F1 score[0]\n",
      "[4772/5006] final loss [0.17710818350315094] accuracy[91.8] precision[33.33] recall[25.0] specificity[96.49] F1 score[0.29]\n",
      "[4773/5006] final loss [0.14247524738311768] accuracy[92.03] precision[11.11] recall[25.0] specificity[94.03] F1 score[0.15]\n",
      "[4774/5006] final loss [0.04877367243170738] accuracy[92.5] precision[100.0] recall[25.0] specificity[100.0] F1 score[0.4]\n",
      "[4775/5006] final loss [0.06486529111862183] accuracy[90.62] precision[50.0] recall[16.67] specificity[98.28] F1 score[0.25]\n",
      "[4776/5006] final loss [0.16457945108413696] accuracy[86.14] precision[25.0] recall[10.53] specificity[95.92] F1 score[0.15]\n",
      "[4777/5006] final loss [0.08627721667289734] accuracy[95.83] precision[0.0] recall[0] specificity[95.83] F1 score[0]\n",
      "[4778/5006] final loss [0.12137901782989502] accuracy[83.78] precision[27.78] recall[17.86] specificity[93.3] F1 score[0.22]\n",
      "[4779/5006] final loss [0.052096519619226456] accuracy[83.05] precision[0.0] recall[0.0] specificity[92.45] F1 score[0]\n",
      "[4780/5006] final loss [0.22918199002742767] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[4781/5006] final loss [0.25874367356300354] accuracy[93.01] precision[5.88] recall[20.0] specificity[94.31] F1 score[0.09]\n",
      "[4782/5006] final loss [0.049557026475667953] accuracy[89.36] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4783/5006] final loss [0.043033480644226074] accuracy[97.22] precision[0.0] recall[0] specificity[97.22] F1 score[0]\n",
      "[4784/5006] final loss [0.22297407686710358] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[4785/5006] final loss [0.25003308057785034] accuracy[83.5] precision[16.67] recall[7.69] specificity[94.44] F1 score[0.11]\n",
      "[4786/5006] final loss [0.22592884302139282] accuracy[90.97] precision[42.86] recall[25.0] specificity[96.97] F1 score[0.32]\n",
      "[4787/5006] final loss [0.09985722601413727] accuracy[92.81] precision[0.0] recall[0.0] specificity[93.42] F1 score[0]\n",
      "[4788/5006] final loss [0.15623688697814941] accuracy[94.08] precision[22.22] recall[50.0] specificity[95.27] F1 score[0.31]\n",
      "[4789/5006] final loss [0.2414163053035736] accuracy[86.18] precision[28.57] recall[24.0] specificity[93.21] F1 score[0.26]\n",
      "[4790/5006] final loss [0.14642804861068726] accuracy[66.67] precision[0.0] recall[0] specificity[66.67] F1 score[0]\n",
      "[4791/5006] final loss [0.09341159462928772] accuracy[91.07] precision[0.0] recall[0.0] specificity[92.73] F1 score[0]\n",
      "[4792/5006] final loss [0.04838896170258522] accuracy[94.04] precision[0.0] recall[0.0] specificity[94.67] F1 score[0]\n",
      "[4793/5006] final loss [0.0210019052028656] accuracy[96.51] precision[0.0] recall[0] specificity[96.51] F1 score[0]\n",
      "[4794/5006] final loss [0.0172829981893301] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4795/5006] final loss [0.16791021823883057] accuracy[93.24] precision[0.0] recall[0.0] specificity[97.18] F1 score[0]\n",
      "[4796/5006] final loss [0.10330839455127716] accuracy[95.19] precision[0.0] recall[0.0] specificity[96.12] F1 score[0]\n",
      "[4797/5006] final loss [0.06993799656629562] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4798/5006] final loss [0.17008987069129944] accuracy[93.14] precision[0.0] recall[0] specificity[93.14] F1 score[0]\n",
      "[4799/5006] final loss [0.1778564304113388] accuracy[89.04] precision[10.53] recall[22.22] specificity[91.9] F1 score[0.14]\n",
      "[4800/5006] final loss [0.11588049679994583] accuracy[88.94] precision[9.09] recall[6.25] specificity[95.24] F1 score[0.07]\n",
      "[4801/5006] final loss [0.056430209428071976] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[4802/5006] final loss [0.14631019532680511] accuracy[91.67] precision[0.0] recall[0] specificity[91.67] F1 score[0]\n",
      "[4803/5006] final loss [0.0744372084736824] accuracy[94.67] precision[25.0] recall[50.0] specificity[95.89] F1 score[0.33]\n",
      "[4804/5006] final loss [0.067798912525177] accuracy[90.8] precision[0.0] recall[0] specificity[90.8] F1 score[0]\n",
      "[4805/5006] final loss [0.08216052502393723] accuracy[93.33] precision[40.0] recall[66.67] specificity[94.74] F1 score[0.5]\n",
      "[4806/5006] final loss [0.20439283549785614] accuracy[74.29] precision[28.57] recall[19.05] specificity[88.1] F1 score[0.23]\n",
      "[4807/5006] final loss [0.10917025059461594] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[4808/5006] final loss [0.20314225554466248] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4809/5006] final loss [0.1914045214653015] accuracy[90.7] precision[16.67] recall[25.0] specificity[93.9] F1 score[0.2]\n",
      "[4810/5006] final loss [0.01559451688081026] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[4811/5006] final loss [0.23555459082126617] accuracy[93.12] precision[0.0] recall[0.0] specificity[95.04] F1 score[0]\n",
      "[4812/5006] final loss [0.027076341211795807] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4813/5006] final loss [0.03058028407394886] accuracy[95.35] precision[0.0] recall[0] specificity[95.35] F1 score[0]\n",
      "[4814/5006] final loss [0.05115988105535507] accuracy[94.59] precision[0.0] recall[0] specificity[94.59] F1 score[0]\n",
      "[4815/5006] final loss [0.08726071566343307] accuracy[94.57] precision[33.33] recall[66.67] specificity[95.51] F1 score[0.44]\n",
      "[4816/5006] final loss [0.3166807293891907] accuracy[91.98] precision[25.0] recall[22.22] specificity[96.08] F1 score[0.24]\n",
      "[4817/5006] final loss [0.2977965772151947] accuracy[100.0] precision[100.0] recall[100.0] specificity[100.0] F1 score[1.0]\n",
      "[4818/5006] final loss [0.20297470688819885] accuracy[88.78] precision[12.5] recall[18.18] specificity[92.78] F1 score[0.15]\n",
      "[4819/5006] final loss [0.051213689148426056] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[4820/5006] final loss [0.1997811496257782] accuracy[92.63] precision[33.33] recall[40.0] specificity[95.56] F1 score[0.36]\n",
      "[4821/5006] final loss [0.10928914695978165] accuracy[85.71] precision[33.33] recall[22.22] specificity[94.12] F1 score[0.27]\n",
      "[4822/5006] final loss [0.13681583106517792] accuracy[94.09] precision[0.0] recall[0.0] specificity[95.6] F1 score[0]\n",
      "[4823/5006] final loss [0.32447606325149536] accuracy[91.46] precision[0.0] recall[0.0] specificity[93.75] F1 score[0]\n",
      "[4824/5006] final loss [0.19524934887886047] accuracy[96.15] precision[0.0] recall[0] specificity[96.15] F1 score[0]\n",
      "[4825/5006] final loss [0.14060603082180023] accuracy[90.74] precision[33.33] recall[25.0] specificity[96.0] F1 score[0.29]\n",
      "[4826/5006] final loss [0.036134377121925354] accuracy[96.49] precision[0.0] recall[0] specificity[96.49] F1 score[0]\n",
      "[4827/5006] final loss [0.18589171767234802] accuracy[91.18] precision[0.0] recall[0.0] specificity[96.88] F1 score[0]\n",
      "[4828/5006] final loss [0.09458225220441818] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[4829/5006] final loss [0.2330985963344574] accuracy[90.62] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[4830/5006] final loss [0.07941804081201553] accuracy[98.51] precision[0.0] recall[0] specificity[98.51] F1 score[0]\n",
      "[4831/5006] final loss [0.1155434399843216] accuracy[93.42] precision[0.0] recall[0.0] specificity[94.67] F1 score[0]\n",
      "[4832/5006] final loss [0.07954683899879456] accuracy[94.74] precision[0.0] recall[0] specificity[94.74] F1 score[0]\n",
      "[4833/5006] final loss [0.07004709541797638] accuracy[94.39] precision[0.0] recall[0] specificity[94.39] F1 score[0]\n",
      "[4834/5006] final loss [0.08749379962682724] accuracy[96.35] precision[0.0] recall[0] specificity[96.35] F1 score[0]\n",
      "[4835/5006] final loss [0.049392182379961014] accuracy[86.67] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4836/5006] final loss [0.16067208349704742] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4837/5006] final loss [0.17263969779014587] accuracy[87.72] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[4838/5006] final loss [0.010370719246566296] accuracy[95.16] precision[0.0] recall[0] specificity[95.16] F1 score[0]\n",
      "[4839/5006] final loss [0.04041355848312378] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4840/5006] final loss [0.06197371333837509] accuracy[92.98] precision[0.0] recall[0.0] specificity[94.64] F1 score[0]\n",
      "[4841/5006] final loss [0.09592493623495102] accuracy[93.53] precision[0.0] recall[0.0] specificity[95.59] F1 score[0]\n",
      "[4842/5006] final loss [0.04018852859735489] accuracy[97.47] precision[0.0] recall[0] specificity[97.47] F1 score[0]\n",
      "[4843/5006] final loss [0.036787524819374084] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[4844/5006] final loss [0.04269661754369736] accuracy[93.18] precision[0.0] recall[0.0] specificity[97.62] F1 score[0]\n",
      "[4845/5006] final loss [0.07336073368787766] accuracy[89.23] precision[0.0] recall[0.0] specificity[90.62] F1 score[0]\n",
      "[4846/5006] final loss [0.19482426345348358] accuracy[89.37] precision[11.76] recall[14.29] specificity[93.75] F1 score[0.13]\n",
      "[4847/5006] final loss [0.09860023111104965] accuracy[83.33] precision[0.0] recall[0.0] specificity[92.11] F1 score[0]\n",
      "[4848/5006] final loss [0.38748645782470703] accuracy[96.77] precision[0.0] recall[0] specificity[96.77] F1 score[0]\n",
      "[4849/5006] final loss [0.17729465663433075] accuracy[89.15] precision[11.11] recall[14.29] specificity[93.44] F1 score[0.13]\n",
      "[4850/5006] final loss [0.32579952478408813] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4851/5006] final loss [0.0197223462164402] accuracy[85.56] precision[0.0] recall[0.0] specificity[93.9] F1 score[0]\n",
      "[4852/5006] final loss [0.10642392933368683] accuracy[96.73] precision[0.0] recall[0] specificity[96.73] F1 score[0]\n",
      "[4853/5006] final loss [0.14882072806358337] accuracy[90.28] precision[16.67] recall[33.33] specificity[92.75] F1 score[0.22]\n",
      "[4854/5006] final loss [0.053440116345882416] accuracy[91.18] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[4855/5006] final loss [0.31499558687210083] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[4856/5006] final loss [0.14322537183761597] accuracy[91.3] precision[11.11] recall[25.0] specificity[93.47] F1 score[0.15]\n",
      "[4857/5006] final loss [0.12527714669704437] accuracy[93.9] precision[0.0] recall[0] specificity[93.9] F1 score[0]\n",
      "[4858/5006] final loss [0.12504041194915771] accuracy[84.46] precision[13.33] recall[16.67] specificity[90.44] F1 score[0.15]\n",
      "[4859/5006] final loss [0.03190605714917183] accuracy[89.47] precision[0.0] recall[0.0] specificity[97.14] F1 score[0]\n",
      "[4860/5006] final loss [0.09765667468309402] accuracy[87.12] precision[7.69] recall[10.0] specificity[92.16] F1 score[0.09]\n",
      "[4861/5006] final loss [0.17473965883255005] accuracy[85.71] precision[13.79] recall[20.0] specificity[90.64] F1 score[0.16]\n",
      "[4862/5006] final loss [0.050998538732528687] accuracy[98.75] precision[0.0] recall[0] specificity[98.75] F1 score[0]\n",
      "[4863/5006] final loss [0.14909575879573822] accuracy[95.24] precision[0.0] recall[0] specificity[95.24] F1 score[0]\n",
      "[4864/5006] final loss [0.19226965308189392] accuracy[94.64] precision[60.0] recall[42.86] specificity[98.1] F1 score[0.5]\n",
      "[4865/5006] final loss [0.5748549103736877] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4866/5006] final loss [0.026878278702497482] accuracy[94.9] precision[0.0] recall[0.0] specificity[95.88] F1 score[0]\n",
      "[4867/5006] final loss [0.2812846601009369] accuracy[60.0] precision[50.0] recall[8.33] specificity[94.44] F1 score[0.14]\n",
      "[4868/5006] final loss [0.19870267808437347] accuracy[87.16] precision[0.0] recall[0.0] specificity[91.35] F1 score[0]\n",
      "[4869/5006] final loss [0.023146260529756546] accuracy[90.0] precision[0.0] recall[0] specificity[90.0] F1 score[0]\n",
      "[4870/5006] final loss [0.09137767553329468] accuracy[97.56] precision[0.0] recall[0] specificity[97.56] F1 score[0]\n",
      "[4871/5006] final loss [0.056468330323696136] accuracy[81.82] precision[0.0] recall[0.0] specificity[90.0] F1 score[0]\n",
      "[4872/5006] final loss [0.034514907747507095] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[4873/5006] final loss [0.015634702518582344] accuracy[93.75] precision[0.0] recall[0] specificity[93.75] F1 score[0]\n",
      "[4874/5006] final loss [0.08869113773107529] accuracy[73.89] precision[37.5] recall[16.22] specificity[91.67] F1 score[0.23]\n",
      "[4875/5006] final loss [0.17212574183940887] accuracy[90.62] precision[0.0] recall[0.0] specificity[92.55] F1 score[0]\n",
      "[4876/5006] final loss [0.09088406711816788] accuracy[97.37] precision[50.0] recall[100.0] specificity[97.3] F1 score[0.67]\n",
      "[[4877/10000]] loop skipped\n",
      "[4878/5007] final loss [0.08833421766757965] accuracy[96.1] precision[0.0] recall[0.0] specificity[97.37] F1 score[0]\n",
      "[4879/5007] final loss [0.099699467420578] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[4880/5007] final loss [0.08719074726104736] accuracy[90.53] precision[0.0] recall[0.0] specificity[92.47] F1 score[0]\n",
      "[4881/5007] final loss [0.041145868599414825] accuracy[97.78] precision[0.0] recall[0] specificity[97.78] F1 score[0]\n",
      "[4882/5007] final loss [0.20907635986804962] accuracy[91.3] precision[33.33] recall[33.33] specificity[95.35] F1 score[0.33]\n",
      "[4883/5007] final loss [0.11727213859558105] accuracy[89.66] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[4884/5007] final loss [0.16846902668476105] accuracy[81.08] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4885/5007] final loss [0.25691908597946167] accuracy[94.34] precision[33.33] recall[50.0] specificity[96.08] F1 score[0.4]\n",
      "[4886/5007] final loss [0.1497199535369873] accuracy[86.47] precision[6.45] recall[22.22] specificity[88.72] F1 score[0.1]\n",
      "[4887/5007] final loss [0.1409742832183838] accuracy[92.28] precision[0.0] recall[0.0] specificity[93.03] F1 score[0]\n",
      "[4888/5007] final loss [0.22613689303398132] accuracy[89.8] precision[16.67] recall[16.67] specificity[94.57] F1 score[0.17]\n",
      "[4889/5007] final loss [0.21933555603027344] accuracy[91.8] precision[0.0] recall[0.0] specificity[96.55] F1 score[0]\n",
      "[4890/5007] final loss [0.144014373421669] accuracy[93.28] precision[0.0] recall[0.0] specificity[94.87] F1 score[0]\n",
      "[4891/5007] final loss [0.12445496022701263] accuracy[87.37] precision[25.0] recall[25.0] specificity[93.1] F1 score[0.25]\n",
      "[4892/5007] final loss [0.1577652096748352] accuracy[91.94] precision[0.0] recall[0] specificity[91.94] F1 score[0]\n",
      "[4893/5007] final loss [0.10227060317993164] accuracy[95.65] precision[50.0] recall[100.0] specificity[95.45] F1 score[0.67]\n",
      "[4894/5007] final loss [0.09508677572011948] accuracy[88.57] precision[0.0] recall[0.0] specificity[93.94] F1 score[0]\n",
      "[4895/5007] final loss [0.004191701300442219] accuracy[92.86] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4896/5007] final loss [0.15708942711353302] accuracy[91.43] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[4897/5007] final loss [0.27378472685813904] accuracy[91.3] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4898/5007] final loss [0.08602900058031082] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4899/5007] final loss [0.12235464155673981] accuracy[93.0] precision[0.0] recall[0] specificity[93.0] F1 score[0]\n",
      "[4900/5007] final loss [0.23171840608119965] accuracy[92.59] precision[0.0] recall[0] specificity[92.59] F1 score[0]\n",
      "[4901/5007] final loss [0.1458795666694641] accuracy[91.45] precision[20.0] recall[14.29] specificity[96.36] F1 score[0.17]\n",
      "[4902/5007] final loss [0.04032272845506668] accuracy[96.0] precision[0.0] recall[0] specificity[96.0] F1 score[0]\n",
      "[4903/5007] final loss [0.1891283392906189] accuracy[89.83] precision[12.5] recall[13.04] specificity[94.47] F1 score[0.13]\n",
      "[4904/5007] final loss [0.043602898716926575] accuracy[97.62] precision[0.0] recall[0] specificity[97.62] F1 score[0]\n",
      "[4905/5007] final loss [0.17445558309555054] accuracy[93.97] precision[0.0] recall[0.0] specificity[94.78] F1 score[0]\n",
      "[4906/5007] final loss [0.2476007044315338] accuracy[92.42] precision[0.0] recall[0] specificity[92.42] F1 score[0]\n",
      "[4907/5007] final loss [0.10888977348804474] accuracy[88.73] precision[0.0] recall[0.0] specificity[93.33] F1 score[0]\n",
      "[4908/5007] final loss [0.17510025203227997] accuracy[94.29] precision[0.0] recall[0] specificity[94.29] F1 score[0]\n",
      "[4909/5007] final loss [0.03908352553844452] accuracy[85.19] precision[0.0] recall[0.0] specificity[92.0] F1 score[0]\n",
      "[4910/5007] final loss [0.16899234056472778] accuracy[92.04] precision[0.0] recall[0.0] specificity[95.41] F1 score[0]\n",
      "[4911/5007] final loss [0.15200337767601013] accuracy[92.68] precision[20.0] recall[33.33] specificity[94.94] F1 score[0.25]\n",
      "[4912/5007] final loss [0.11116449534893036] accuracy[95.24] precision[14.29] recall[100.0] specificity[95.2] F1 score[0.25]\n",
      "[4913/5007] final loss [0.059668488800525665] accuracy[97.3] precision[0.0] recall[0] specificity[97.3] F1 score[0]\n",
      "[4914/5007] final loss [0.1902608722448349] accuracy[96.72] precision[0] recall[0.0] specificity[100.0] F1 score[0]\n",
      "[4915/5007] final loss [0.07006280869245529] accuracy[81.69] precision[8.33] recall[6.25] specificity[91.27] F1 score[0.07]\n",
      "[4916/5007] final loss [0.18850024044513702] accuracy[91.44] precision[17.65] recall[37.5] specificity[93.46] F1 score[0.24]\n",
      "[4917/5007] final loss [0.19714224338531494] accuracy[89.29] precision[20.0] recall[16.67] specificity[94.87] F1 score[0.18]\n",
      "[4918/5007] final loss [0.17883150279521942] accuracy[95.56] precision[0.0] recall[0] specificity[95.56] F1 score[0]\n",
      "[4919/5007] final loss [0.1250174194574356] accuracy[91.53] precision[0.0] recall[0.0] specificity[93.91] F1 score[0]\n",
      "[4920/5007] final loss [0.1378866285085678] accuracy[82.89] precision[18.18] recall[33.33] specificity[87.14] F1 score[0.24]\n",
      "[4921/5007] final loss [0.16929294168949127] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4922/5007] final loss [0.09205424785614014] accuracy[91.67] precision[0.0] recall[0.0] specificity[94.29] F1 score[0]\n",
      "[4923/5007] final loss [0.1459682285785675] accuracy[85.71] precision[0.0] recall[0] specificity[85.71] F1 score[0]\n",
      "[4924/5007] final loss [0.032254502177238464] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4925/5007] final loss [0.10080384463071823] accuracy[87.9] precision[12.5] recall[7.69] specificity[95.14] F1 score[0.1]\n",
      "[4926/5007] final loss [0.0013983197277411819] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4927/5007] final loss [0.020505519583821297] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[4928/5007] final loss [0.024418113753199577] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4929/5007] final loss [0.08205205947160721] accuracy[97.4] precision[0.0] recall[0.0] specificity[98.68] F1 score[0]\n",
      "[4930/5007] final loss [0.11157629638910294] accuracy[86.0] precision[0.0] recall[0.0] specificity[93.48] F1 score[0]\n",
      "[4931/5007] final loss [0.1307879090309143] accuracy[88.65] precision[36.36] recall[30.77] specificity[94.53] F1 score[0.33]\n",
      "[4932/5007] final loss [0.17278312146663666] accuracy[94.44] precision[0.0] recall[0] specificity[94.44] F1 score[0]\n",
      "[4933/5007] final loss [0.04810259863734245] accuracy[89.47] precision[33.33] recall[33.33] specificity[94.29] F1 score[0.33]\n",
      "[4934/5007] final loss [0.11480524390935898] accuracy[93.63] precision[10.0] recall[50.0] specificity[94.19] F1 score[0.17]\n",
      "[4935/5007] final loss [0.11711481213569641] accuracy[88.24] precision[50.0] recall[16.67] specificity[97.78] F1 score[0.25]\n",
      "[4936/5007] final loss [0.1220923438668251] accuracy[91.52] precision[18.18] recall[28.57] specificity[94.3] F1 score[0.22]\n",
      "[4937/5007] final loss [0.3015635907649994] accuracy[93.33] precision[0.0] recall[0] specificity[93.33] F1 score[0]\n",
      "[4938/5007] final loss [0.11965294927358627] accuracy[90.74] precision[0.0] recall[0.0] specificity[91.59] F1 score[0]\n",
      "[4939/5007] final loss [0.09136759489774704] accuracy[93.26] precision[0.0] recall[0] specificity[93.26] F1 score[0]\n",
      "[4940/5007] final loss [0.32340747117996216] accuracy[95.0] precision[0.0] recall[0] specificity[95.0] F1 score[0]\n",
      "[4941/5007] final loss [0.11449356377124786] accuracy[92.55] precision[0.0] recall[0.0] specificity[93.55] F1 score[0]\n",
      "[4942/5007] final loss [0.04206447675824165] accuracy[91.53] precision[11.11] recall[11.11] specificity[95.56] F1 score[0.11]\n",
      "[4943/5007] final loss [0.2267199158668518] accuracy[88.89] precision[0.0] recall[0] specificity[88.89] F1 score[0]\n",
      "[4944/5007] final loss [0.16640521585941315] accuracy[96.3] precision[0.0] recall[0] specificity[96.3] F1 score[0]\n",
      "[4945/5007] final loss [0.12055671960115433] accuracy[92.44] precision[0.0] recall[0.0] specificity[94.83] F1 score[0]\n",
      "[4946/5007] final loss [0.15140056610107422] accuracy[93.94] precision[50.0] recall[50.0] specificity[96.77] F1 score[0.5]\n",
      "[4947/5007] final loss [0.1219012588262558] accuracy[91.51] precision[0.0] recall[0.0] specificity[93.27] F1 score[0]\n",
      "[4948/5007] final loss [0.07880755513906479] accuracy[87.98] precision[15.38] recall[15.38] specificity[93.53] F1 score[0.15]\n",
      "[4949/5007] final loss [0.2666926980018616] accuracy[93.62] precision[0.0] recall[0] specificity[93.62] F1 score[0]\n",
      "[4950/5007] final loss [0.20101827383041382] accuracy[94.97] precision[0.0] recall[0] specificity[94.97] F1 score[0]\n",
      "[4951/5007] final loss [0.09177680313587189] accuracy[94.06] precision[0.0] recall[0.0] specificity[95.0] F1 score[0]\n",
      "[4952/5007] final loss [0.1067085713148117] accuracy[94.06] precision[0.0] recall[0.0] specificity[95.96] F1 score[0]\n",
      "[4953/5007] final loss [0.10761579871177673] accuracy[90.51] precision[8.33] recall[33.33] specificity[91.79] F1 score[0.13]\n",
      "[4954/5007] final loss [0.07673589885234833] accuracy[86.96] precision[0.0] recall[0.0] specificity[90.91] F1 score[0]\n",
      "[4955/5007] final loss [0.016596030443906784] accuracy[93.9] precision[0.0] recall[0] specificity[93.9] F1 score[0]\n",
      "[4956/5007] final loss [0.08716167509555817] accuracy[93.55] precision[0.0] recall[0] specificity[93.55] F1 score[0]\n",
      "[4957/5007] final loss [0.06335218250751495] accuracy[94.12] precision[25.0] recall[100.0] specificity[94.0] F1 score[0.4]\n",
      "[4958/5007] final loss [0.1262006163597107] accuracy[91.86] precision[0.0] recall[0.0] specificity[94.05] F1 score[0]\n",
      "[4959/5007] final loss [0.14054101705551147] accuracy[92.77] precision[20.0] recall[33.33] specificity[95.0] F1 score[0.25]\n",
      "[4960/5007] final loss [0.15800391137599945] accuracy[94.78] precision[50.0] recall[50.0] specificity[97.25] F1 score[0.5]\n",
      "[4961/5007] final loss [0.3165675401687622] accuracy[88.89] precision[10.0] recall[20.0] specificity[91.96] F1 score[0.13]\n",
      "[4962/5007] final loss [0.07532051205635071] accuracy[88.64] precision[0.0] recall[0.0] specificity[90.7] F1 score[0]\n",
      "[4963/5007] final loss [0.12766170501708984] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4964/5007] final loss [0.15852834284305573] accuracy[93.42] precision[0.0] recall[0] specificity[93.42] F1 score[0]\n",
      "[4965/5007] final loss [0.11845044791698456] accuracy[94.12] precision[0.0] recall[0.0] specificity[94.43] F1 score[0]\n",
      "[4966/5007] final loss [0.11034549027681351] accuracy[88.89] precision[0.0] recall[0.0] specificity[90.57] F1 score[0]\n",
      "[4967/5007] final loss [0.09953691810369492] accuracy[89.66] precision[0.0] recall[0.0] specificity[94.55] F1 score[0]\n",
      "[4968/5007] final loss [0.12674854695796967] accuracy[91.94] precision[5.26] recall[33.33] specificity[92.65] F1 score[0.09]\n",
      "[4969/5007] final loss [0.32197803258895874] accuracy[93.43] precision[0.0] recall[0.0] specificity[94.12] F1 score[0]\n",
      "[4970/5007] final loss [0.21289238333702087] accuracy[93.1] precision[0.0] recall[0] specificity[93.1] F1 score[0]\n",
      "[4971/5007] final loss [0.32579290866851807] accuracy[86.36] precision[0.0] recall[0.0] specificity[96.2] F1 score[0]\n",
      "[4972/5007] final loss [0.01708541251718998] accuracy[92.86] precision[0.0] recall[0] specificity[92.86] F1 score[0]\n",
      "[4973/5007] final loss [0.06191793084144592] accuracy[91.55] precision[0.0] recall[0.0] specificity[92.86] F1 score[0]\n",
      "[4974/5007] final loss [0.12154993414878845] accuracy[82.99] precision[45.0] recall[39.13] specificity[91.13] F1 score[0.42]\n",
      "[4975/5007] final loss [0.03535471856594086] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[4976/5007] final loss [0.16675660014152527] accuracy[86.8] precision[25.0] recall[15.0] specificity[94.92] F1 score[0.19]\n",
      "[4977/5007] final loss [0.1291825920343399] accuracy[84.62] precision[100.0] recall[33.33] specificity[100.0] F1 score[0.5]\n",
      "[4978/5007] final loss [0.1668911576271057] accuracy[97.14] precision[0.0] recall[0] specificity[97.14] F1 score[0]\n",
      "[4979/5007] final loss [0.009512065909802914] accuracy[85.39] precision[0.0] recall[0.0] specificity[98.7] F1 score[0]\n",
      "[4980/5007] final loss [0.17756745219230652] accuracy[86.79] precision[25.0] recall[20.0] specificity[93.75] F1 score[0.22]\n",
      "[4981/5007] final loss [0.15383704006671906] accuracy[89.47] precision[16.67] recall[16.67] specificity[94.38] F1 score[0.17]\n",
      "[4982/5007] final loss [0.1290379762649536] accuracy[93.1] precision[0.0] recall[0.0] specificity[94.74] F1 score[0]\n",
      "[4983/5007] final loss [0.037103790789842606] accuracy[93.43] precision[0.0] recall[0.0] specificity[96.24] F1 score[0]\n",
      "[4984/5007] final loss [0.048925142735242844] accuracy[96.72] precision[0.0] recall[0] specificity[96.72] F1 score[0]\n",
      "[4985/5007] final loss [0.01456727646291256] accuracy[97.87] precision[0.0] recall[0] specificity[97.87] F1 score[0]\n",
      "[4986/5007] final loss [0.153950035572052] accuracy[84.55] precision[0.0] recall[0.0] specificity[93.69] F1 score[0]\n",
      "[4987/5007] final loss [0.3382708728313446] accuracy[92.31] precision[0.0] recall[0] specificity[92.31] F1 score[0]\n",
      "[4988/5007] final loss [0.10886132717132568] accuracy[89.26] precision[7.69] recall[50.0] specificity[89.92] F1 score[0.13]\n",
      "[4989/5007] final loss [0.18174117803573608] accuracy[81.18] precision[6.67] recall[5.26] specificity[90.73] F1 score[0.06]\n",
      "[4990/5007] final loss [0.17642152309417725] accuracy[90.91] precision[0.0] recall[0] specificity[90.91] F1 score[0]\n",
      "[4991/5007] final loss [0.1722693145275116] accuracy[95.37] precision[0.0] recall[0] specificity[95.37] F1 score[0]\n",
      "[4992/5007] final loss [0.07852678000926971] accuracy[84.62] precision[25.0] recall[11.11] specificity[95.2] F1 score[0.15]\n",
      "[4993/5007] final loss [0.1976993978023529] accuracy[95.45] precision[0.0] recall[0] specificity[95.45] F1 score[0]\n",
      "[4994/5007] final loss [0.14394070208072662] accuracy[87.79] precision[25.0] recall[16.67] specificity[94.96] F1 score[0.2]\n",
      "[4995/5007] final loss [0.16620728373527527] accuracy[92.35] precision[0.0] recall[0.0] specificity[94.09] F1 score[0]\n",
      "[4996/5007] final loss [0.08487161248922348] accuracy[89.29] precision[0.0] recall[0.0] specificity[92.59] F1 score[0]\n",
      "[4997/5007] final loss [0.04041558504104614] accuracy[80.49] precision[16.67] recall[8.33] specificity[92.86] F1 score[0.11]\n",
      "[4998/5007] final loss [0.13646216690540314] accuracy[95.48] precision[0.0] recall[0] specificity[95.48] F1 score[0]\n",
      "[4999/5007] final loss [0.17392167448997498] accuracy[85.94] precision[12.5] recall[8.33] specificity[93.97] F1 score[0.1]\n",
      "[5000/5007] final loss [0.15656830370426178] accuracy[96.3] precision[50.0] recall[100.0] specificity[96.15] F1 score[0.67]\n",
      "[5001/5007] final loss [0.046372316777706146] accuracy[96.55] precision[0.0] recall[0] specificity[96.55] F1 score[0]\n",
      "[5002/5007] final loss [0.1189420074224472] accuracy[100.0] precision[0] recall[0] specificity[100.0] F1 score[0]\n",
      "[5003/5007] final loss [0.05000315606594086] accuracy[94.39] precision[0.0] recall[0] specificity[94.39] F1 score[0]\n",
      "[5004/5007] final loss [0.16357369720935822] accuracy[90.4] precision[15.15] recall[33.33] specificity[92.65] F1 score[0.21]\n",
      "[5005/5007] final loss [0.22988097369670868] accuracy[89.32] precision[4.17] recall[5.88] specificity[93.39] F1 score[0.05]\n",
      "[5006/5007] final loss [0.25802937150001526] accuracy[94.74] precision[25.0] recall[50.0] specificity[95.95] F1 score[0.33]\n",
      "[5007/5007] final loss [0.025779230520129204] accuracy[94.12] precision[0.0] recall[0] specificity[94.12] F1 score[0]\n"
     ]
    }
   ],
   "source": [
    "# 循环遍历每个用户的商品-时间矩阵\n",
    "cur = 0\n",
    "avg_loss = 0\n",
    "avg_acc = 0\n",
    "avg_pre = 0\n",
    "avg_rec = 0\n",
    "avg_spec = 0\n",
    "avg_f1 = 0\n",
    "\n",
    "for data in iterator:\n",
    "    # 清理无用数据\n",
    "    data = pd.DataFrame(data)\n",
    "    data = data.loc[~(data == 0).all(axis=1)].T # 清除空行，并转置矩阵\n",
    "\n",
    "    # 数据处理\n",
    "    try:\n",
    "        cat, seq, item_u, data_out = preprocessing(data) # 在读取大量数据时，有时data会出错，因此catch错误并跳过出错的数据\n",
    "    except ValueError:\n",
    "        print(f'[[{cur+1}/10000]] loop skipped')\n",
    "        cur += 1\n",
    "        para.batch += 1\n",
    "        continue\n",
    "    para.input_size = cat\n",
    "    para.output_size = cat\n",
    "\n",
    "    # 划分数据集\n",
    "    # 训练用户集前30天的兴趣分，预测用户在第31天的兴趣分，从而计算模型准确率\n",
    "    # 训练前20天，测试后11天\n",
    "    train_x, train_y, test_x, test_y = separate(data_out, 20)\n",
    "\n",
    "    model = train(train_x, train_y, para)\n",
    "\n",
    "    # 得到用户最后一天实际交互了的商品集\n",
    "    last_day = list()\n",
    "    for row in interact.itertuples():\n",
    "        if row.userId == userId[cur]:\n",
    "            last_day.append(itemCat.index(row.itemCat))\n",
    "    \n",
    "    loss, accuracy, precision, recall, specificity, f1 = test(test_x, test_y, last_day, para, item_u, N[cur], cat)\n",
    "\n",
    "    print(f'[{cur+1}/{para.batch}] final loss [{loss}] accuracy[{accuracy}] precision[{precision}] recall[{recall}] specificity[{specificity}] F1 score[{f1}]')\n",
    "\n",
    "    avg_loss += loss\n",
    "    avg_acc += accuracy\n",
    "    avg_pre += precision\n",
    "    avg_rec += recall\n",
    "    avg_spec += specificity\n",
    "    avg_f1 += f1\n",
    "    \n",
    "    cur += 1 # 用户记录\n",
    "\n",
    "    if cur == para.batch:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5db0cb3f-4f06-447d-abe7-20a9637c087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "avg_loss /= para.batch\n",
    "avg_acc /= para.batch\n",
    "avg_pre /= para.batch\n",
    "avg_rec /= para.batch\n",
    "avg_spec /= para.batch\n",
    "avg_f1 /= para.batch\n",
    "avg_time = time.time() - start\n",
    "avg_time /= para.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7e42479d-1151-415f-bce2-053d31fe74a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[0.12462495267391205]\n",
      "accuracy[91.60157779109181]\n",
      "precision[8.140631116437012]\n",
      "recall[9.926315158777735]\n",
      "specificity[94.3477411623725]\n",
      "f1 score[0.07620131815458374]\n",
      "average time[0.1982944823558968]\n"
     ]
    }
   ],
   "source": [
    "# 输出结果\n",
    "print(f'loss[{avg_loss}]\\naccuracy[{avg_acc}]\\nprecision[{avg_pre}]\\nrecall[{avg_rec}]\\nspecificity[{avg_spec}]\\nf1 score[{avg_f1}]\\naverage time[{avg_time}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25ab5e-ddd6-478b-a9e7-cc480e1d915f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
